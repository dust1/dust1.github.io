[{"title":"[五大常用算法]贪心算法","url":"/2020/03/22/五大常用算法-贪心算法/","content":"贪心算法又叫贪婪算法，是一种通过解决越来越大的子问题来逐步建立起针对大问题的解决方案。从这个角度它与动态规划(Dynamic Programming)相似，但不同的是它针对小问题主要在解决部分方案而不会跟踪所以多个解决方案。这是一种理想化的思路，通常使用场景不会很多，但是当它起作用的时候比动态规划简单得多。\n\n几个例子：\n### 贪婪加权子集\n我有一组对象的集合S，其中他们每个对象的权重已知。我想从总子集P最小(最大)的允许类中找到S的子集A。即我想从一个设定好条件的S的子集P中找到我想要的子集A，这使得A的权重只和最大(最小)。\n* 我想抓取k个物体，从而使得权重只和最大。允许的子集P恰好是大小为k的子集。\n* 当我抓取第i个对象的时候要花费Ci元，我想要在花费小于等于b元的情况下尽可能地使得最终的权重只和最大化。\n* 这些对象是已连接的无向图的边缘，我想要找到一个子集，该子集恰好包含图中权重只和最小的两个任意节点之间的一条路径，现在，允许的子集是生成树，连接了所有节点的无环子图。\n> 连接两个点可以走一遍图中的所有点。\n\n在每种情况下都有一种自然的贪婪算法：\n* 从空子集开始，每一步的选择中都选择最佳的(权重最大或最小)未使用元素,该元素仍然会留下一些集合的子集，当我们无法再往集合中添加元素后停止操作。\n\n这样的思路在第一个我们想抓取k个元素并使得权重和最大(最小)的时候是有效的，因为它只会抓取权重最大的前k个元素。当我们想抓取适合预算的物体时它会失败，这个就是背包问题(KnapsackProblem)。\n\n#### 背包问题（KnapsackProblem）\n有一个背包，最大只能装150kg的物品。我有一组物品，需要从中选择一部分使得能装进背包时总价值最大。\n\n物品|重量|价值\n---|:--:|---:\na|35|10\nb|30|40\nc|60|30\nd|50|50\ne|40|35\nf|10|40\ng|25|30\n\n目标：总价值最大<br>\n约束：总重量不能超过150kg<br>\n根据贪心策略可以有下面三种思路：\n* 每次挑选价值最大的物品\n* 每次挑选所占重量最小的物品\n* 每次挑选单位重量价值最大的物品\n\n在使用贪心算法前需要证明最终的结果是由贪心策略所提出的子问题的最优解所构成，如果成立则问题将会简单化。\n\n**每次挑选价值最大的物品**\n\n最大重量为40，物品如下\n\n物品|重量|价值\n---|:--:|---:\na|35|35\nb|10|20\nc|10|20\n\n根据策略得到的子集为`[a]`而此时`[b, c]`明显是更好的选择。\n\n**每次挑选所占重量最小的物品**\n\n最大重量为40，物品如下\n\n物品|重量|价值\n---|:--:|---:\na|35|45\nb|30|20\nc|10|20\n\n根据策略得到的子集为`[b, c]`而此时`[a]`明显是更好的选择。\n\n**每次挑选单位重量价值最大的物品**\n\n最大重量为30，物品如下\n\n物品|重量|价值\n---|:--:|---:\na|28|28\nb|20|20\nc|10|10\n\n此时三者的单位价值都一样，无法判断。\n\n### 最小权重生成树---Kruskal算法\nKruskal算法简单来说是现将图中的所有边按从小到大排列，然后从小的边开始，每次往边的集合中添加不会形成循环的图。当我们获得连接所有节点的图后停止。此时该图就是原先图的最小权重生成树。\n\n这其中关键的一点是如何检查在往树中添加一条边时是否会创建循环。当我们加入一条连接两个节点u和v的边时，我们只要检查在当前树中是否还有另外一条路径连接着u和v，当且仅当u和v存在另外一条路径时，存在循环。\n\n我们可以使用UnionFind数据结构跟踪连接的组件中的连接信息。其中识别节点的组件需要O(1)时间，n个顶点的所有并集的总时间为O(n log n)。因此循环测试将O(V log V)时间添加到算法中。<br>\n该算法的其余部分仅包括对边进行排序(以O(E log E)时间)，然后一次通过一条边(O(E)时间，不计算联合操作成本)。因此，总时间O(E log E)。这不如Prim算法(O(E log V))，优化方向是在边的排序方面。\n\n现在来证明一下该算法的有效性。\n\n在每个步骤中，T表示到目前为止构建的局部树。设最优解所得到的最小生成树为T*。则最终要是的T等于T*。<br>\n**证明**<br>\n若T=T*，则在第i步获得的树T(i)，令T(i + 1) = T(i) + e，其中e是两个节点u-v之间最小的边，并且添加到T(i)时不会产生循环，若T(i + 1)是T\\*的子集，则操作成立。相反我们考虑T\\*中的u-v两点的路径，该路径是不在T(i)中但是权重和e相等的边e'，现在考虑边集T* - e' + e。它的权重不会比T\\*重，由于这是一棵最小生成树，因此删除e'会将T\\*分为两个部分，而添加e只是将他们重新连接在一起。在这棵树中，因为在T\\*中经过e'的任何路径都可以修改为通过e进行路由。而且最重要的是它包含T(i + 1)。因此T(i + 1)包含在最少生成树T\\* - e' + e中。","tags":["算法"]},{"title":"关于Spring MVC编写Service时的一点想法","url":"/2020/03/01/关于Spring-MVC编写Service时的一点想法/","content":"在使用Spring编写Web后端的时候我们对项目的划分主要为：\n```bash\n---Controller\n|\n|\n---Service\n  ---ServiceImpl\n|\n|\n...\n```\n这里我就提`Controller`和`Service`，因为这篇文章的主题就是关于这个。\n\n在编写Web后台的时候，我们通常对`Service`进行编写的时候会先编写一个`XXXService`接口，然后用`XXXServiceImpl`类去实现它，然后在Controller对它进行调用的时候通过`@Autowired`注解标注`XXXService`接口去使用它。\n\n这是`Controller`对`Service`层的调用，但是遇到`Service`之间的调用该怎么办呢？我之前对此的做法是在`Service`接口中添加方法然后去实现，但是这样一来在`Controller`层对它的调用方法中也会出现这个方法，这可不优雅。代码写的好坏一个重要的评判标准就是是否依照`高内聚，低耦合`这个思路进行编写。在MVC中对其的分层便是按照这个思路来的。但是我们在Service层之间的调用又暴露给Controller这不就适得其反了吗？\n\n在Java中`Interface`的作用类似于标记，即该接口能干什么不能干什么。那么按照这个规范我在Service层之间进行调用的方法也新建一个接口即可。这样`Serivce`接口对外提供服务给Controller，对内则用专门的接口，这样对于调用方来说不会有任何歧义。而`!Autowired`注解也能在进行依赖注入的时候通过接口类型以及参数名称从容器中获取对象。由于这些提供各方服务的接口不会有多个实现，因此它的实现类可以直接用`@Service`进行标注。\n\n\n","tags":["Spring MVC"]},{"title":"深度优先搜索(dfs)与广度优先搜索(bfs)","url":"/2020/02/23/深度优先搜索-dfs-与广度优先搜索-bfs/","content":"今天刷LeetCode的时候居然一时间写不出bfs了，难受。现在在这里重新将这两个算法复习一下，防止彻底忘记。\n\n## 深度优先搜索（Depth-First-Search，DFS）\n首先是wiki上对dfs的介绍\n> 这是一种用于遍历或搜索树或图的算法。沿着树的深度遍历树的节点，尽可能深的搜索树的分支。当节点v的所在边都己被探寻过，搜索将回溯到发现节点v的那条边的起始节点。这一过程一直进行到已发现从源节点可达的所有节点为止。如果还存在未被发现的节点，则选择其中一个作为源节点并重复以上过程，整个进程反复进行直到所有节点都被访问为止。属于盲目搜索。\n\n深度优先搜索的实现可以用栈(Stack)实现，但我用的最多的是递归，这个就看个人习惯了。\n\n### 实现方法\n1. 首先将跟节点放入stack中\n2. 从stack取出节点，并检验它是否是目标\n    - 如果是目标，则结束搜索并返回结果\n    - 否则将它尚未验证过的某一子节点放入stack中\n3. 重复步骤2\n4. 如果不存在未检测过的子节点，将上一级节点加入stack中，重复步骤2\n5. 重复步骤4\n6. 若stack为空，表示整张表都检查过了结果为空\n\n我们用下图举例子，在下图中我们要查询点`G`，在搜索时按左子节点优先进行搜索：\n\n![](/img/20200223/tree.png)\n\n然后我们记录stack中的元素变化来：\n\n1. 首先将跟节点放入stack中,栈中的元素为`A`\n2. 取出A后便利它的子节点，并将所有没有标记过的子节点放入stack中，此时stack中元素为`B,C`\n3. 重复步骤2得到`D,E,C`\n4. 此时`D`已经是叶子节点，所以不会压入新的节点\n5. 重复步骤2`E,C` -> `C`\n6. 此时`C`存在子节点，将其压入`F,G`\n7. 重复2`G`\n\n从上我们可以发现dfs常用于对树的搜索。并且我个人编写dfs的时候通常使用递归，这一般看个人习惯把。\n\n### 代码\nJava实现上述例子如下：\n\n- 栈实现：\n```java\n/**\n * 树的节点\n */\nclass Node {\n\n    private String key;\n\n    private Object value;\n\n    private Node left;\n\n    private Node right;\n\n    /*\n     getter,setter省略\n    */\n}\n\npubic class Dfs {\n\n    /**\n     * dfs搜索\n     */\n    public Optional<Node> dfs(Node root, String key) {\n        if (Objects.isNull(root)) {\n            return Optional.empty();\n        }\n\n        //用散列值快速比较节点是否被标记\n        Set<String> mark = new HashSet<>();\n\n        Stack<Node> stack = new Stack<>();\n        stack.add(root);\n        while (!stack.isEmpty()) {\n            Node node = stack.poll();\n            mark.add(node.getKey());\n            if (node.getKey() == key) {     //在目前的java版本中，值相同的字符串共用同一个内存地址，这是为了方式key以及节点中的key为null\n                return Optional.of(node);\n            }\n\n            if (Objects.notNull(node.getLeft()) && !mark.contians(node.getLeft().getKey())) {\n                stack.add(node.getLeft());\n            }\n            \n            if (Objects.notNull(node.getRight()) && !mark.contians(node.getRight().getKey())) {\n                stack.add(node.getRight());\n            }\n            \n        }\n\n        return Optional.empty();\n    }\n\n}\n```\n\n- 递归实现\n```java\npublic class Dfs {\n\n    public Optional<Node> dfs(Node root, String key) {\n        Set<String> mark = new HashSet<>();\n        Node node = dfs(root, key, mark);\n        return Optional.ofNullable(node);\n    }\n\n    private Node dfs(Node node, String key, Set<String> mark) {\n        if (Objects.isNull(node)) {\n            return null;\n        }\n\n        if (node.getKey() == key) {\n            return node;\n        }\n        mark.add(node.getKey());\n\n        Node result = null;\n        if (Objects.notNull(node.getLeft()) && !mark.contians(node.getLeft().getKey())) {\n            result = dfs(node.getLeft())\n        }\n        \n        if (Objects.notNull(result)) {\n            return result;\n        }\n\n        if (Objects.notNull(node.getRight()) && !mark.contians(node.getRight().getKey())) {\n            result = dfs(node.getRight());\n        }\n\n        return result;\n    }\n\n}\n```\n\n## 广度优先搜索（Breadth-First-Search，BFS）\n> 是一种图形搜索算法。简单的说，BFS是从根节点开始，沿着树的宽度遍历树的节点。如果所有节点均被访问，则算法中止。广度优先搜索的实现一般采用open-closed表。\n\n>从算法的观点，所有因为展开节点而得到的子节点都会被加进一个先进先出的队列中。一般的实现里，其邻居节点尚未被检验过的节点会被放置在一个被称为 open 的容器中（例如队列或是链表），而被检验过的节点则被放置在被称为 closed 的容器中。\n### 实现方法\n1. 首先将根节点放入队列中\n2. 从队列中取出第一个节点，并检验它是否是目标\n    - 如果是目标，则返回结果\n    - 否则将它所有尚未检验过的子节点加入队列\n3. 若队列为空，则表示找不到目标\n4. 重复步骤2\n\n我们通过下面的图进行举例\n\n![](/img/20200223/tu.png)\n\n假设出发点是`A`,我们要搜索点`F`。在进行搜索时队列中元素的变化如下：<br>\n1. `A`\n2. `B,C`\n3. `C,D,E`\n4. `D,E,G`\n5. `E,G`\n6. `G`\n7. `F`\n\n我们通过作图可以看到bfs搜索范围如下：\n\n![](/img/20200223/tu1.png)\n\n然后对比dfs搜索路径变化：\n\n![](/img/20200223/tree1.png)\n\n我们可以看到bfs的搜索就像是在水面投入石子一样以入口为中心向四周进行一圈又一圈的搜索。\n\n### 代码\n\n```java\npublic class Dfs {\n\n    pubic Optional<Node> dfs(Node root, String key) {\n        Queue<Node> queue = new LinkedList();\n        if (Objects.isNull(root)) {\n            return Optional.empty();\n        }\n\n        if (root.getKey() == key) {\n            return Optional.of(root);\n        }\n\n        queue.add(root);\n        Set<String> mark = new HashSet<>();\n        while (!queue.isEmpty()) {\n            Node node = queue.poll();\n            mark.add(node.getKey());\n\n            if (node.getKey() == key) {\n                return Optional.of(node);\n            }\n\n            if (Objects.notNull(node.getLeft()) && mark.contians(node.getLeft().getKey())) {\n                queue.add(node.getLeft());\n            }\n\n            if (Objects.notNull(node.getRight()) && mark.contians(node.getRight().getKey())) {\n                queue.add(node.getRight());\n            }\n        }\n\n        return Optional.empty();\n    }\n\n}\n```\n\n### 应用\n**查找连接组件**\n\n由起点开始，运行广度优先搜索算法后所经过的所有节点，即为包含起点的一个连接组件。\n\n**测试是否二分图**\n\nBFS可以用以测试二分图。从任一节点开始搜索，并在搜索过程中给节点不同的标签。例如，给开始点标签0，开始点的所有邻居标签1，开始点所有邻居的邻居标签0……以此类推。若在搜索过程中，任一节点有跟其相同标签的邻居，则此图就不是二分图。若搜索结束时这种情形未发生，则此图为一二分图。\n\n**应用于电脑游戏中平面网格**\n\nBFS可用来解决电脑游戏（例如即时策略游戏）中找寻路径的问题。在这个应用中，使用平面网格来代替图形，而一个格子即是图中的一个节点。所有节点都与它的邻居（上、下、左、右、左上、右上、左下、右下）相接。\n\n值得一提的是，当这样使用BFS算法时，首先要先检验上、下、左、右的邻居节点，再检验左上、右上、左下、右下的邻居节点。这是因为BFS趋向于先查找斜向邻居节点，而不是四方的邻居节点，因此找到的路径将不正确。BFS应该先查找四方邻居节点，接着才查找斜向邻居节点1。\n\n## 参考资料\n[广度优先搜索](https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)\n\n[深度优先搜索](https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)\n","tags":["杂谈"]},{"title":"我们使用磁力的时候发生了什么？","url":"/2020/02/17/我们使用磁力的时候发生了什么？/","content":"前段时间使用磁力链接的时候突然想了解一下磁力链接是怎么工作的，于是查询了一下相关信息并在这里做一个记录。\n## 磁力的诞生\n>这个标准的草稿出现于2002年，是为了对eDonkey2000的“ed2k:”和Freenet的“freenet:”两个URI格式进行“厂商与项目中立化”（vendor- and project-neutral generalization）而制定的。同时这个标准也尝试紧密地跟进IETF官方的URI标准。<br>\n[维基百科](https://zh.wikipedia.org/wiki/%E7%A3%81%E5%8A%9B%E9%93%BE%E6%8E%A5#%E5%8E%86%E5%8F%B2)\n## 第一步 获取种子\n我们使用的磁力链接实际上是一个唯一的文件识别符类似于图书领域的ISBN，在计算机中通常叫做对应文件的散列值或者叫哈希值(Hash)。该字符指向一个唯一的文件，通常是种子文件。\n\n我们在相关程序中输入磁力链接后，目标程序会从它们自己的种子库中搜索对应的种子。这是最常用的方法，但是还有一种方法就是启用DHT(Distributed Hash Table,分布式哈希表)这种方法效率就不太高了。客户端会从几个DHT的节点出发，根据磁力的散列值在表中查找种子文件。\n>DHT:分布式哈希表，是一种分布式存储方法。每个客户端维护一部分路由表并存储一部分数据，其中保存的是其他节点的网络信息，包括IP以及端口。我们只要从部分哈希表节点出发就能遍历整个分布式网络。这部分节点称之为bootstrap node。现在网络上有各种个样的磁力客户端，不难想象这个网络有多大了。\n\n### 种子中有什么？\n种子中保存着Tracker信息和文件信息。\n\nTracker信息就是我们在下载中请求的下载服务器IP和相关配置。\n\n文件信息就是根据目标文件的计算生成的，计算结果根据BitTorrent协议内的Bencode规则进行编码。它的主要原理是需要把提供下载的文件虚拟分成大小相等的块，块大小必须为2k的整数次方（由于是虚拟分块，硬盘上并不产生各个块文件），并把每个块的索引信息和Hash验证码写入种子文件中；所以，种子文件就是被下载文件的“索引”。 \n\n## 第二步 开始下载\n\n>当我们准备下载的时候首先要解析种子文件，然后使用BT客户端软件进行下载。 下载时，BT客户端首先解析种子文件得到Tracker地址，然后连接Tracker服务器。Tracker服务器回应下载者的请求，提供下载者其他下载者（包括发布者）的IP。下载者再连接其他下载者，根据种子文件，两者分别告知对方自己已经有的块，然后交换对方所没有的数据。此时不需要其他服务器参与，分散了单个线路上的数据流量，因此减轻了服务器负担。 下载者每得到一个块，需要算出下载块的Hash验证码与种子文件中的对比，如果一样则说明块正确，不一样则需要重新下载这个块。这种规定是为了解决下载内容准确性的问题。 一般的HTTP/FTP下载，发布文件仅在某个或某几个服务器，下载的人太多，服务器的带宽很易不胜负荷，变得很慢。而BitTorrent协议下载的特点是，下载的人越多，提供的带宽也越多，下载速度就越快。同时，拥有完整文件的用户也会越来越多，使文件的“寿命”不断延长。<br>[维基百科](https://zh.wikipedia.org/wiki/BitTorrent_(%E5%8D%8F%E8%AE%AE))\n\n这里在进行下载的时候实际上还要经过Tracker服务器，这样容易出现单点问题。于是DHT网络孕育而生。根据DHT规范网络中的每个DHT节点由peer和节点本身组成。\n>peer：是一个在TCP上监听的客户端/服务端，它实现了BT协议。\n>\n>节点：是一个在UDP上监听的客户端/服务端，它实现了分布式哈希表协议。并存储了peer的信息。\n\n当使用DHT进行下载时，我们从几个bootstrap node出发，此时他们的节点通过自身的路由表联系其他节点并获取其他节点的peer位置然后才能通过BT协议进行下载。\n\n## 相关信息\n\n### 磁力链接\n\n磁力链接类似与URL，根URL开头的HTTP/HTTPS一样，磁力链接的开头是 `magnet:?`。但是由于参数 `xt (\"exact topic\"的缩写)` 必须存在，所以也会写成 `magnet:?xt=`。\n\n#### 参数\n* xt(exact topic) - 包含文件散列值的URN。\n* dn(显示名称) - 文件名\n* xl(绝对长度) - 文件的字节数\n* as(可接受来源) - 在线文件的网络链接\n* xs(绝对资源) - P2P链接\n* kt(关键字) - 用于搜索的关键字\n* mt(文件列表) - 链接到一个包含磁力链接的元文件 (MAGMA - [MAGnet MAnifest](http://rakjar.de/gnuticles/MAGMA-Specsv22.txt)）\n* tr(Tracker地址) - BT下载的Tracker URL\n\n详情见[磁力链接](https://zh.wikipedia.org/wiki/%E7%A3%81%E5%8A%9B%E9%93%BE%E6%8E%A5)\n\n#### DHT\nDistributed Hash Table,分布式哈希表的缩写。是一种分布式存储技术。网络中的每个节点负责维护一个路由表，路由表保存部分有效的DHT节点，用户从某个或者某些节点出发就可以遍历完整个节点，并能够利用整个DHT网络的资源。\n\n和数据结构中的图类似，其中的路由表就是图之间关联的线。\n\n详情见[DHT协议](https://max.book118.com/html/2015/1002/26541787.shtm)\n\n#### Tracker\n保存着文件的下载服务器地址与相关配置。可以追踪某文件同时被多少人在下载。\n\n## 参考\n[磁力链接是如何下载的](https://www.aneasystone.com/archives/2015/05/how-does-magnet-link-work.html)\n\n[DHT协议规范](https://max.book118.com/html/2015/1002/26541787.shtm)\n","tags":["杂谈"]},{"title":"[LeetCode]388.文件的最长绝对路径","url":"/2020/02/15/LeetCode-388-文件的最长绝对路径/","content":"## 题目\n假设我们以下述方式将我们的文件系统抽象成一个字符串:\n\n字符串 `\"dir\\n\\tsubdir1\\n\\tsubdir2\\n\\t\\tfile.ext\"` 表示:\n\n```\ndir\n    subdir1\n    subdir2\n        file.ext\n```\n目录 `dir` 包含一个空的子目录 `subdir1` 和一个包含一个文件 `file.ext` 的子目录 `subdir2` 。\n\n字符串 `\"dir\\n\\tsubdir1\\n\\t\\tfile1.ext\\n\\t\\tsubsubdir1\\n\\tsubdir2\\n\\t\\tsubsubdir2\\n\\t\\t\\tfile2.ext\"` 表示:\n\n```\ndir\n    subdir1\n        file1.ext\n        subsubdir1\n    subdir2\n        subsubdir2\n            file2.ext\n```\n目录 `dir` 包含两个子目录 `subdir1` 和 `subdir2`。 `subdir1` 包含一个文件 `file1.ext` 和一个空的二级子目录 `subsubdir1`。`subdir2` 包含一个二级子目录 `subsubdir2` ，其中包含一个文件 `file2.ext`。\n\n我们致力于寻找我们文件系统中文件的最长 (按字符的数量统计) 绝对路径。例如，在上述的第二个例子中，最长路径为 `\"dir/subdir2/subsubdir2/file2.ext\"`，其长度为 32 (不包含双引号)。\n\n给定一个以上述格式表示文件系统的字符串，返回文件系统中文件的最长绝对路径的长度。 如果系统中没有文件，返回 0。\n\n说明:\n\n文件名至少存在一个 `.` 和一个扩展名。\n目录或者子目录的名字不能包含 .。\n要求时间复杂度为 `O(n)` ，其中 `n` 是输入字符串的大小。\n\n请注意，如果存在路径 `aaaaaaaaaaaaaaaaaaaaa/sth.png` 的话，那么  `a/aa/aaa/file1.txt` 就不是一个最长的路径。\n\n## 相关概念\n\n* \\n：换行\n* \\t：tab键\n\n## 思路\n\n从例子中给出来的文件系统我们可以看到是分层的。那么我们在计算的时候也可以根据层次来进行判断。\n\n例如；\n```\ndir\n    subdir1\n    subdir2\n        file.ext\n```\n* 第一层：dir\n* 第二层：subdir1，subdir2\n* 第三层：file.ext\n\n我们在遍历的时候遇到存在 `.` 的文件名时结束一次遍历并进行比较。这样我们需要保留上一层到根目录的文件路径的长度。而且不需要保留全部的上一层，只要保留当前的上一层即可，就算之前有上一层的文件夹名称大于当前文件的上一层文件夹名称，我们还有最终的绝对路径长度进行比较。而保留上一层的绝对路径长度的话我们可以用数组。\n\n而且我们通过分析例子中的字符串发现层次结构只要根据文件名前存在的 `\\t` 个数就可以进行判断。\n\n因此我们的解题方法就出来了\n> 创建数组用于保存对应层数时的绝对路径长度，将字符串根据 `\\n` 进行分组，遍历数组判断当前字符串属于哪一层，如果文件名包含 `.` 则将上一层路径长度加上当前文件名长度去和当前最大的绝对路径长度进行比较并保留最大值。如果是文件夹则将当前路径长度存入。\n\n## 解\n```java\n    public int lengthLongestPath(String input) {\n        int res = 0;\n        int[] sum = new int[input.length() + 1];\n\n        for (String s : input.split(\"\\n\")) {\n            //层数，从1开始\n            int level = s.lastIndexOf(\"\\t\") + 2;\n            //这行字符串的长度\n            int len = s.length() - level + 1;\n            \n            if (s.contains(\".\")) {\n                //已经到达文件末尾\n                res = Math.max(res, sum[level - 1] + len);\n            } else {\n                sum[level] = sum[level - 1] + len + 1;\n            }\n        }\n        return res;\n    }\n\n```\n","tags":["LeetCode算法题"]},{"title":"[LeetCode]389.字典序排数","url":"/2020/02/15/LeetCode-389-字典序排数/","content":"## 题目\n>给定一个整数 n, 返回从 1 到 n 的字典顺序。<br>\n例如，\n<br>给定 n =1 3，返回 [1,10,11,12,13,2,3,4,5,6,7,8,9] 。\n<br>请尽可能的优化算法的时间复杂度和空间复杂度。 输入的数据 n 小于等于 5,000,000。\n\n## 相关概念\n* 字典序:在数学中，字典或词典顺序（也称为词汇顺序，字典顺序，字母顺序或词典顺序）是基于字母顺序排列的单词按字母顺序排列的方法。 这种泛化主要在于定义有序完全有序集合（通常称为字母表）的元素的序列（通常称为计算机科学中的单词）的总顺序。\n\n## 思路\n首先我们将例子中的数字重新进行排版得到\n* 1,10,11,12,13\n* 2\n* 3\n* 4\n* 5\n* 6\n* 7\n* 8\n* 9\n\n很清晰，这里首先是有一个对数字1-9的遍历。然后看数字`1,10,11,12,13`这个例子可能不是很清楚，我们换一个`n=101`的例子`1,10,100,101,11,12,13,14,15,16,17,18,19`这里我们看到首先是对数字`1`的乘法运算，然后进行加法运算，我们将其进行拆分\n* 1,10,100\n* 100,101\n* 10,11,12,13,14,15,16,17,18,19\n\n我们可以发现这是一个典型的深度优先搜索算法，那么具体的思路如下\n>先遍历1-9获取数字的开头，然后根据给定的数字先计算乘以10之后的数字是否符合要求，如果符合要求则继续乘以10，如果不符合要求则后退到先前的结果并进行加法运算。\n\n而且进行加法运算的时候不会超过10。\n\n## 解\n```java\n    public List<Integer> lexicalOrder(int n) {\n        List<Integer> list = new ArrayList<>();\n\n        for (int i = 1; i < 10; i++) {\n            if (i <= n) {\n                list.add(i);\n            }\n            mul(i, n, list);\n        }\n\n        return list;\n    }\n\n    private void mul(int num, int n, List<Integer> list) {\n        int m = num * 10;\n        if (m <= n) {\n            list.add(m);\n            mul(m, n, list);\n        }\n\n        for (int i = 1; i < 10; i++) {\n            int sum = m + i;\n            if (sum <= n) {\n                list.add(sum);\n                mul(sum, n, list);\n            } else {\n                break;\n            }\n        }\n    }\n```","tags":["LeetCode算法题"]},{"title":"初识Vert.x","url":"/2020/02/11/初识Vert-x/","content":"\nVert.x是Eclipes公司所研发的用于在JVM上构建响应式应用程序的工具包。正如该描述所表示的一样，Vert.x并不是一个框架而是一个工具包。\n\n优点：\n* **基于事件驱动且非阻塞。**\n* **多语言支持。包括Java，JavaScript，Groovy，Ruby，Ceylon，Scala和Kotlin**\n* **轻巧。Vert.x内核约为650KB**\n* **非应用程序服务器。你可以将Vert.x运行在任何需要的地方。**\n\n缺点：\n* **难上手。异步编程跟一般的编程有许多不同。**\n\n让我们先来看一个简单的demo\n\n```java\npublic class MyVerticle extends AbstractVerticle {\n\n    @Override\n    public void start() throws Exception {\n        vertx.createHttpServer()\n                .requestHandler(req -> {\n                    req.response().end(\"hello\");\n                })\n                .listen(8080);\n    }\n}\n```\n\n```java\npublic class Start {\n    public static void main(String[] args){\n        Vertx vertx = Vertx.vertx();\n\n        vertx.deployVerticle(MyVerticle.class.getName());\n    }\n}\n```\n在运行之后会在8080端口开启一个web服务，并且会返回`\"hello\"`字符。\n\n现在让我们从这个demo开始了解Vert.x。\n\n## Vert.x部分概念\n这只是一个初步认识的文章，因此只会讲解几个常用的概念，更多的可以前往[官方文档](https://vertx.io/docs/)进行了解。当然也有翻译好的[中文文档](http://vertxchina.github.io/vertx-translation-chinese/)。\n\n### Vertx实例\nVertx实例是Vertx的控制中心，如果我们没有vertx实例的话许多事情都做不了。它是一切事物的基础，包括创建客户端和服务器、获取事件总线的引用、设置定时器等等。<br>\n\n#### Vertx创建\nvertx实例的创建也是非常简单\n```java\nVertx vertx = Vertx.vertx();\n```\n#### 配置Vertx\n我们也可以在创建vertx实例的时候指定配置项\n```java\nVertx vertx = Vertx.vertx(new VertxOptions().setWorkerPoolSize(40));\n```\nVertxOptions有很多配置，包括集群、高可用、池大小等。可以在[Javadoc](https://vertx.io/docs/apidocs/io/vertx/core/VertxOptions.html)中了解相关细节。\n\n### Event Loop\nVertx使用被称之为Event Loop的线程调用我们的处理器，正如前面所说的Vertx是基于事件驱动的非阻塞工具。我们在将主要的业务逻辑通过Handler编写完成后，就是通过Event Loop进行调用。由于Vertx或我们的应用程序中没有阻塞块，因此Event Loop可以快速的将各个事件分发给对应的处理器，从而在短时间内处理大量的事件。\n>据官方所说，一个Event Loop可以在短时间内处理上千个HTTP请求。\n\n一个Event Loop只能在任意时刻运行在一个核上，如果我们希望充分利用CPU资源的话，可以对Vertx进行相关配置，使得一个Vertx实例维护多个Event Loop线程，这种方式称之**Multi-Reactor 模式**，而维护一个Event Loop线程的方式称之为**Reactor 模式**。实现Multi-Reactor 模式也非常简单\n```java\npublic class Start {\n    public static void main(String[] args){\n        Vertx vertx = Vertx.vertx(new VertxOptions()\n                .setEventLoopPoolSize(Runtime.getRuntime().availableProcessors() + 1));\n        vertx.deployVerticle(FirstVerticle.class.getName());\n    }\n}\n```\n`setEventLoopPoolSize(int)`方法即设置Event Loop线程个数。\n>线程个数为处理器个数+1的原因是当一个线程出现问题时可以有一个备用线程可以及时补上。当然也可以直接设置为处理器的个数。\n\n### Handler\n这是我们使用Vertx的时候接触最多的组件，几乎所有的业务逻辑都是编写在处理器中并让Event Loop进行调用。处理器用于处理各个相关的事件，并且是线程安全的，永远不会被并发执行。\n>可以说我们整个应用程序的逻辑都是用一个又一个处理器所组成的。而连接各个处理器的就是事件。\n\n通过前面的demo我们可以看到，程序的入口是一个继承了`AbstractVerticle`抽象类的对象，这样就使得我们所有的业务代码都处于Vertx的掌控之中，这样还有一个好处就是方便Vertx诊断你的代码执行时间，在Vertx中，如果你的某部分代码执行时间过长它会在日志中打印警告信息。就像下面这样\n```bash\n警告: Thread Thread[vert.x-eventloop-thread-0,5,main]=Thread[vert.x-eventloop-thread-0,5,main] has been blocked for 2858 ms, time limit is 2000 ms\n```\n在Vertx中方法或者说处理器的执行时间通常在2s以内属于正常范围。超过了它会给你警告方便我们排查优化。\n\n","tags":["Java"]}]