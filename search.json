[{"title":"分布式存储笔记笔记3-3 分布式键值系统（Amazon Dynamo & Tair）","url":"/2021/03/19/分布式存储笔记3-3-分布式键值系统（Amazon-Dynamo-Tair）/","content":"<hr>\n这是一篇在阅读《大规模分布式存储系统：原理解析与架构实战》时的阅读笔记，由于长时间碎片阅读的关系导致在做这种读书笔记的时候接近复制粘贴。虽然其中会有一小部分自己的想法但都十分零碎，希望后续能改进。\n<hr>\n\n分布式键值模型可以看成是分布式表格模型的一种特例。由于它只支持针对单个key-value的增删改查（随机查找）操作，因此适用哈希分布算法。\n\n学习Dynamo的设计对学习分布式系统理念很有帮助。但是这个系统的主要价值在学术层面，从工程的角度来看，它牺牲了一致性，却没有换来什么好处。\n\n# Amazon Dynamo\nDynamo以很简单的键值方式存储数据，不支持复杂的查询。Dynamo存储的是数据的原始形式，不解析数据的具体内容。Dynamo是一个P2P结构的分布式存储模型，而不是常用的中心节点模型。\n<img src=\"/img/202103/018.png\" width=\"50%\" height=\"50%\">\n\n## 数据分布\nDynamo采用一致性哈希算法将数据分布到多个存储节点中。\n\n考虑到节点的异构性，不同节点之间处理能力的差别会很大，Dynamo使用了改进的一致性哈希算法：每个物理节点根据其性能的差异分配多个token，这样，性能高的节点他的哈希选中率也会提高。\n<img src=\"/img/202103/019.png\" width=\"50%\" height=\"50%\">\n如果新增了存储节点，只需要将对应的token分配到该节点上即可。\n\n为了找到数据所属的节点，要求每个节点维护一定的集群信息用于定位。Dynamo系统中每个节点维护整个集群你的信息。\n> 因为是P2P结构，所以要求一个节点必要时能够和其他所有节点通信。\n\n所有节点每隔固定时间（比如1s）通过Gossip协议的方式从其他节点中任选一个与之通信的节点。如果连接成功，双方交换各自保存的节点信息。\n\n[Gossip协议](https://zhuanlan.zhihu.com/p/41228196)用于P2P系统中自治的节点协调对整个集群的认知，比如集群的节点状态、负载情况。\n* A告诉B其管理的所有节点的版本（包括Down状态和Up状态的节点）\n* B告诉A那些节点的版本比较旧了，哪些版本它有最新的，然后把最新的节点状态发给A（处于Down状态的节点由于版本没有发生更新则不会被关注）\n* A将B中比较旧的节点告诉B，同时将B发送来的最新节点信息在本地更新\n* B收到A发来的最新节点后更新本地的元数据\n\n>  双方各自比较对方的节点版本并用对方的新版本替换自身的旧版本。\n\n由于种子节点的存在，新节点的加入可以做的比较简单。新节点加入时首先与种子节点交换集群信息，从而对集群有了认识。DHT（一致性哈希表）环中原有的其他节点也会定期和种子节点交换集群信息，从而发现新节点的加入。\n\n> 这样看来种子节点起到了一个类似中心的作用，不过它的功能不在于完成存储业务，而是负责节点集群之间信息的交互。\n\n每个节点需要定期通过Gossip协议同其他节点交换集群信息，如果发现某个节点很长时间状态都没有更新，则认为该节点已经下线了。\n\n> 这里对于节点的存活与否依赖于其他节点的检查，而不是与种子节点建立心跳通信。这样的好处就是减少了种子节点的业务复杂度与网络压力。\n\n## 一致性与复制\n为了处理节点失效的情况（DHT环中删除节点），需要对节点的数据进行复制。\n> 这种需要中心节点处理的流程也是交给存储节点吗？还是交给种子节点？\n\n假设数据存储N份，DHT定位到的数据所属节点为K，则数据存储在节点K，K+1，…，K + N上。如果第K + i（0 ≤ i ≤ N-1）台机器宕机，则往后找一台机器K+N临时替代。如果第K+i台机器重启，临时替代的机器K+N能够功过Gossip协议发现，他会将这些临时数据归还K+i，这个过程在Dynamo中叫做数据回传。\n> 这里一个问题就是“临时数据”属于什么数据？当第K + N台机器接入的时候，它本身是没有数据的，因此除非接入的时候就进行一次数据的复制工作，否则机器K+N的缓存无法命中，如果不进行数据复制，那么这里的数据将会是后续新添加的缓存，但是既然数据已经分多台机器存储备份，那么当K+i号机器重新上线后也可以直接从临近的机器上同步数据。\n\n在这台机器下线的时间段内，所有的读写均落入到机器[K, K + i - 1]和[K + i + 1, K + N]中，如果机器K + i永久失效，机器K+N需要进行数据同步操作。这个过程通过Merkle树对机器的数据文件进行快速同步。\n\nNWR是Dunamo中的一个亮点，其中N表示复制的备份数，R指成功读操作的最少节点数，W指成功写操作的最少节点数。只要满足W + R > N，就可以保证当存在不超过一台机器故障的的时候，至少能够读到一份有效数据。\n> 像什么？多数派写！当写数量 + 读数量 > 节点总数量则能够保证一定有一次成功的写入被读取到。但是这里的数据必须要有一个版本号或者携带时间戳用于区分数据的新旧。\n\n在P2P这样的集群中，由于每个节点存储的集群信息有所不同，可能出现同一条记录被多个节点同时更新的情况，无法保证多个节点之间的更新顺序，为此Dynamo引入向量时钟（Vector Clock）的技术手段来尝试解决冲突。\n<img src=\"/img/202103/020.png\" width=\"50%\" height=\"50%\">\nDynamo中的向量时钟用一个[nodes, counter]对表示。其中nodes表示节点，counter是一个计数器，初始为0，节点每次更新操作加1。\n\n**例如：**\n首先，Sx对某一个对象进行一次写操作，产生一个对象版本D1([Sx, 1])，接着Sx再次操作，counter值更新为2，产生第二个版本D2（[Sx， 2]）；之后，Sy和Sz同时对该对象进行写操作，Sy将自身的信息加入向量时钟产生了新的版本D3（[Sx，2]，[Sy，1]），Sz同样产生了新的版本信息D4（[Sx，2]，[Sz，1]），这时系统中就有了两个冲突的版本。最常见的冲突解决方法有两个：一种是通过客户端逻辑来解决，比如购物车应用；另外一种常见的策略是“last write wins”，即选择时间戳最新的副班，然而这个策略以来集群内节点之间的时钟同步算法，不能完全保证准确性。\n> 对每一个线程对同一个对象的操作都生成一个独立的版本，这样就会导致N个线程同时写入就会有N个版本。这里就跟paxos不一样了，在paxos中，如果要执行写入的rnd小于last_rnd，那么就拒绝写入，而在Dynamo中都是先写入后执行解决冲突策略。\n\n> 存储节点之间的时钟必然会有误差，如果误差过大比如超过5秒，那么一致性就很难保证。\n\n向量时钟不能完美解决冲突，即使N + W > R，Dynamo也只能保证每个读取操作能读到所有的更新版本，这些版本可能冲突，需要进行版本合并。Dynamo只保证最终一致性，如果多个节点之间的更新顺序不一致，客户端可能读取不到期望的结果。这个不一致的问题影响到了应用程序的设计和对整个系统的测试工作。\n\n> 从上面会产生版本冲突的问题来看，在Dynamo中，一个数据被分布到多个节点上，并不会使得某一个节点成为主节点用于提供服务，而是所有的节点都会提供对这个数据的增删改服务，这能够极大程度增加系统承压能力，但是也导致了同一条数据多个不同节点之间数据的不一致性。\n\n## 容错\nDynamo把异常分为两种类型：临时性的异常和永久性异常。\n\n这种分类是依据异常的持续时间划分，比如机器假死属于临时性异常；硬盘报修或者机器报废就是永久性异常。\n\n### 数据回传\n同上文，当下线的机器恢复后第K+N台机器会通过Gossip协议发现并启动传输任务将暂存的数据回传给机器K+i。\n\n### Merkle树同步\n如果超过了时间T机器K+i还是处于宕机状态，这种异常被认为是永久性的。这时需要借助Merkle树机制从其他副本进行数据同步。\n> 应该要从多台机器中获取备份并将冲突解决后作为自身的最终数据，因为Dynamo无法保证强一致性，因此同一份数据不同备份之间可能不一致，所以K+N在获取备份的时候应该要“货比三家”。\n\nMerkle树中每个非叶子结点对应多个文件，为其所有子节点组合以后的哈希值；叶子结点对应单个数据文件，为文件内容的哈希值。这样，任何一个数据文件不匹配都将导致从该文件对应的叶子结点到根结点的所有节点值不同。每台机器对每一段范围的数据维护一颗Merkle树，机器同步时首先传输Merkle树信息，并且只需要同步从根到叶子的所有节点值均不相同的文件。\n> 即，每个非叶子结点的哈希值都是它下属所有文件组合后的哈希值，每个叶子结点都是其对应的文件内容的哈希值。这样，当某个文件不同步时，必然会有一条从根结点到叶子结点的树与其他Merkle树不一致，此时只需要同步这条路径上的哈希值与叶子结点的文件即可。\n> 这种方法在于能够高效快速地筛选出两颗Merkle之间的不同，但是如何同步，或者说当两条路径不一致时该选用哪一条路径为主就需要另外的解决冲突逻辑。通常如同上文说的一样可以由客户端代码实现，也可以选用最新修改的数据。\n\n### 读取修复\n假设N=3，W=2，R=2，机器K宕机，可能有部分写操作已经返回客户端成功了但是没有完全同步到所有副本，如果机器K出现永久性异常，导致三个副本之间的数据不一致。客户端的读取操作如果发现了某些副本版本太老，则启动异步的读取修复任务。该任务会合并多个副本的数据，并使用合并后的结果更新过期的副本，从而使得副本之间保持一致。\n> 也就是上文所说，Dyamo无法保证所有节点中同一数据的一致性，但是能保证最新的数据必定已被写入成功，因此当R+W>N时，会读取到多个不同版本的数据，这时候需要合并冲突并得到最终最新的值，并将这个值更新到所有机器中。相当于一个保底机制：第一次写入没有一致的情况下，在第一次读取的时候会进行冲突合并，并重新写入，保证数据不会在多次读取后还是处于不一致的状态。\n\n## 负载均衡\nDynamo的负载均衡取决于如何给每台机器分配虚拟结点号，即token。由于集群环境的异构性，每台物理机器包含多个虚拟结点。一般有以下两种分配方式：\n<img src=\"/img/202103/021.png\" width=\"50%\" height=\"50%\">\n\n> 随机分配导致token分布零散，体现在Merkle树中就是同一台机器的不同token位于不同非叶子结点下（或者说，一台机器拥有的token在Merkle树中的路径十分宽大）使得新节点加入/离开系统时需要对Merkle树中的大量节点进行修改。且由于是随机分布没有规律，也无法将数据进行归档/备份。\n数据范围等分+随机分配：先将数据等分，然后按顺序将token分配给不同的结点，这样就使得当节点新增/下线时对Merkle树的影响最小，且由于的顺序分配，使得归档/备份变得容易许多。\n\n由于Dynamo中同步操作、写操作重试等后台任务比较多。为了不影响正常读写服务，需要对后台任务能够使用的资源做出限制。\n\nDynamo维护一个资源授权系统。该系统将整个机器的资源切分成多个片，监控60秒内的磁盘读写响应时间，事务超时时间及锁冲突情况，根据监控信息算出机器负载从而动态调整分配给后台任务的资源片个数。\n\n## 读写流程\n<img src=\"/img/202103/022.png\" width=\"50%\" height=\"50%\">\n> 这里W就是表示“大部分”，即不需要等所有副本都返回写入成功，只要大部分副本都写入成功就认为这次写入是成功的。就是多数派写。\n\n由于没有中心节点，因此客户端会从所有存储节点中选出一个作为协调者，这个协调者就起到了主存储节点的作用。客户端只需要把写入请求发给协调者即可，后续的所有节点的写入与同步问题都交给协调者处理。\n\n在读取时也是一样，根据一致性哈希算法计算出所有副本存储的节点，并选出其中一个作为协调者，通过协调者读取所有（实际上不需要所有，只需要根据负载均衡策略计算出的R个副本即可）存储副本以及自身的数据，汇总之后返回给客户端。这里可能会产生冲突，默认情况下是使用最新的数据，用户也可以自定义冲突解决策略。在将最终的数据返回给客户端后，协调者还会异步地将最终数据返回给所有副本用于更新最新结果，用于修复错误副本。\n<img src=\"/img/202103/023.png\" width=\"50%\" height=\"50%\">\n\n## 单机实现\nDynamo的存储节点包含三个组件：请求协调、成员和故障检测、存储引擎。\n\nDynamo设计支持可插拔的存储引擎，比如BerkerlyDB（BDB），Mysql InnoDB等。\n\n> 也就是说Dynamo类似于一个分布式存储的上层解决方案，而最终将数据持久化的任务交给其他存储引擎？\n\n请求协调组建采用基于事件驱动的设计，每个客户端的读写请求对应一个状态机，系统根据发生的事件及状态机中的状态决定下一步的操作。比如读取操作对应的状态包括：\n* 协调者发送读请求到其他节点\n* 等待其他节点返回读取结果，最少需要R-1个（加上协调者自己就是R个）\n* 如果请求其他节点返回失败，需要按照一定的策略重试\n* 如果到达时间限制成功的节点仍然小于R-1个，返回客户端请求超过\n\n合并协调者及其他R-1个节点的读取结果，并返回客户端，合并的结果可能包含多个冲突版本；如果设置了冲突解决方法 ，协调者还需要解决冲突。\n\n读操作返回客户端后状态机不会立刻被销毁，而是会等待一段时间，等待其他节点将过期的数据返回，并将最新的数据更新到这些节点。\n\n> 这样来看R只是一个阈值。实际请求的时候应该是请求所有的节点，然后当R-1个节点返回时候就判断读取成功执行后续的合并与返回操作，但是后续还有一些返回的节点只需要更新到最新的值即可。\n\n## 讨论\nDynamo采用无中心节点的P2P设计，增加了系统的可扩展性，但同时带来了一致性问题，影响上层应用。\n\n> 这里就差不多可以总结出中心节点的优劣了：好处是由于所有元数据都交给/都经过中心节点，可以最大程度上保证数据的一致性，就算暂时不一致，在后续存储节点与中心节点的通信中也可以被中心节点检测出来并及时修正；缺点是扩展性不如P2P结构，在P2P结构中，新加入节点只需要通知一下种子节点然后通过Gossip协议对接上其他存储节点即可，而中心节点架构需要联系上中心节点并通过修改元数据与负载均衡来让新节点加入。\n\nDynamo在Amazon的使用场景优先，主流的分布式系统一般都带有中心节点，这样能够简化设计且中心节点只需要维护少量的元数据，一般不会称为性能瓶颈。\n\nDynamo及其开源实现Cassandra在实践中受到的关注逐渐减小，但是它应用了各种分布式技术，在实践过程中也可以借鉴。\n\n# 淘宝Tair\nTair分为持久化和非持久化两种使用方式：非持久化可以看成是一个分布式缓存，持久化的Tair将数据存放于磁盘中。持久化的容错机制与现有的分布式存储备份机制一样。\n\n## 系统架构\n<img src=\"/img/202103/024.png\" width=\"50%\" height=\"50%\">\nTair作为一个分布式系统，是由一个中心控制节点和若干服务节点组成。其中，中心控制节点被称为Config Server，服务节点称为Data Server。Data Server以心跳的方式将自身状况汇报给Config Server。\n\n> 实际上心跳与租约两者并无冲突，心跳可以检测系统是否时常在线，租约负责下放权限。\n\n## 关键问题\n### 数据分布\n根据数据的主键计算哈希值后，分布到Q个桶中，桶是负载均衡和数据迁移的基本单位。Config Server按照一定的策略把每个桶指派到不同的Data Server上。因为数据按照主键计算哈希值，所以可以认为每个桶中的数据基本是平衡的，只要保证桶分布的均衡性，就能够保证数据分布的均衡性。根据Dynamo论文中的实验结论，Q取值需要远大于集群的物理机器数，例如Q取10240.\n\n> 桶分布的均衡性不是平均分配，而是考虑每台机器的硬件配置与运行情况进行的一种非均匀分配，使得每台机器的压力趋于平衡。那么这里的桶可以当作一组token的集合\n\n### 容错\n当某台Data Server故障不可用时，Config Server能够检测到。每个哈希桶在Tair中存储多个副本，如果是备副本，那么Config Server会重新为其指定一台DataServer，如果是持久化存储，还将复制数据到新的Data Server上。如果是主副本，则第一时间启用其他备副本用于提供服务，然后再选择另外一台Data Server称为备副本，确保数据的备份数。\n\n> 通过主备副本的方式来实现容错，并保证数据的一致性。但针对请求的吞吐量弱于Dynamo。\n\n### 数据迁移\n机器加入或者负载不均衡可能导致桶迁移，迁移的过程中需要保证对外服务。某个Data Server中存放三个副本A、B、C，如果A尚未迁移完成，B还在迁移当中，C已经迁移完成。当请求读写A的时候，依旧是原有Data Server提供服务，当请求读写B的时候，原有Data Server提供服务，并将修改操作记录到日志中，当迁移完成时将日志也同步过去使得新的节点能够重现迁移期间进行的修改操作，当读写C的时候直接讲请求转到新的Data Server上。\n> 这样看来，迁移的时候会复制一份新的数据，原有的数据继续对外提供服务，新复制的数据连同期间的修改日志一同迁移到新的机器并通过日志与原有数据进行同步。\n\n### Config Server\n客户端缓存路由表，大多数情况下，客户端不需要访问Config Server，Config Server宕机也不影响客户端正常访问。每次路由的变更，Config Server都会将新的配置信息推给Data Server。在客户端访问Data Server的时候，会发送客户端缓存的路由表版本号。如果Data Server发现客户端的版本号过旧，则会通知客户端去Config Server获取一份新的路由表。如果客户端访问某台Data Server发生了不可达的情况，客户端也会主动去Config Server获取新的路由表。\n> 当主Config Server宕机的情况下如何继续提供服务：通常来说中心节点都是一主一备的配置，如果主Config Server宕机，且备Config Server还没上上线的情况下，客户端通过读取自身缓存的路由表可以在一定程度上减少对Config Server的依赖，为Config Server切换主备提供时间，并在此时间内能够正常对外服务。\n\n> 当路由表发生改变时客户端才会往Config Server请求新的路由表。当Config Server检测到路由表发生改变的时候并不会直接通知客户端，而是将最新的版本号发送给所有Data Server，当客户端用旧的路由表请求DataServer的时候由DataServer通知客户端往Config Server请求新的路由表；或者当客户端请求Data Server失败的时候表示现有的路由表不是完全准确的了，因此也会主动请求新的路由表。这样的设计最大程度减少了Config Server的压力，使得Config Server不会成为性能的瓶颈。\n\n> 如果Data Server一个一个依次下线/上线，那么就会导致Config Server频繁更新路由表，这或许会使得Config Server达到性能瓶颈。\n\n### Data Server\nData Server负责数据的存储，并根据Config Server的要求完成数据的复制和迁移工作。Data Server具备抽象的存储引擎层，可以很方便地添加新的存储引擎。Data Server还有一个插件容器，可以动态加载/卸载插件\n<img src=\"/img/202103/025.png\" width=\"50%\" height=\"50%\">\nTair存储引擎有一个抽象层，只要满足存储引擎需要的接口，就可以很方便地替换Tair底层的存储引擎。Tair默认包含两个存储引擎：Mdb和Fdb，另外还支持Berkerly BD、Tokyo Cabinet、Inno DB、Level DB等各种存储引擎。\n\n## 讨论\nDynamo采用P2P架构，而在Tair中引入了中心节点Config Server，这种方式很容易处理数据的一致性问题，因为所有的数据都要经过中心节点方便管理。\n> P2P相关技术：向量时钟、数据回传、Merkle树、冲突处理\n\n由于Tair的复制是异步的，所以当有DataServer发生故障时，客户端有可能在一定时间内读不到最新的数据，甚至发生最新修改的数据丢失的情况。\n> 比如数据在迁移过程中主Data Server永久性异常了，那么节点在迁移期间内的所有修改操作全部丢失，因为此时数据还是保存在主Data Server的操作日志中，并没有备份。而同步过去的数据只是该节点在迁移前某个时间点的快照。\n\n","tags":["存储"]},{"title":"分布式存储笔记3-2 分布式文件系统（TFS&FH）","url":"/2021/03/09/分布式存储笔记3-2-分布式文件系统（TFS-FH）/","content":"<hr>\n这是一篇在阅读《大规模分布式存储系统：原理解析与架构实战》时的阅读笔记，由于长时间碎片阅读的关系导致在做这种读书笔记的时候接近复制粘贴。虽然其中会有一小部分自己的想法但都十分零碎，希望后续能改进。\n<hr>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TFS = Taobao File System\n\nFH = Facebook Haystack\n\nBlob文件系统的特点是数据写入后基本都是只读，很少出现更新操作。\n\n# Taobao File System\nTFS架构设计时需要考虑如下两个问题：\n<img src=\"/img/202103/001.png\" width=\"50%\" height=\"50%\">\n因此TFS的设计思路是：多个逻辑图片共享一个物理文件\n\n## 系统架构\nTFS于GFS的不同点：\n* TFS内部不维护文件目录树，每个小文件使用一个64位的编号表示；\n* TFS是一个读多写少的应用，相比GFS，他的写流程可以做的更加简单高效\n<img src=\"/img/202103/002.png\" width=\"50%\" height=\"50%\">\n一个TFS集群由两个NameServer和多个DataServer节点组成，NameServer通过心跳对DataServer的状态进行检测。\n\n> 不是租约，说明不需要对DataServer下放写权限?\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 答：当要写入的DataServer宕机时，Client告知NameServer，由NameServer重新进行分配。因为TFS读多写少，不需要支持并发写，因此不会有同一个文件对多个DataServer同时写入的情况。\n\n当主NameServer宕机的时候，可以被心跳守护检测出来并将服务切换到备NameServer。\n\n每个DataServer上会运行多个dsp进程，一个dsp对应一个挂载点，这个挂载点一般对应一个独立磁盘，从而管理多块磁盘。\n\n在TFS中，将大量的小文件合并成一个大文件，这个大文件称为块（Block），每个Block拥有在集群内唯一的编号（块ID），通过<块ID，块偏移>这样的映射关系，可以唯一确定一个文件。\n\n与GFS相同，每个块的大小约为64MB，并默认保存三份。且在客户端也缓存NameServer的元数据信息。\n\n## 追加流程\nGFS为了减少对Master的压力，引入了租约机制，从而将修改权限下放到主ChunkServer。TFS是读多写少，且写多是追加写而不是修改。（浏览用户多，商户修改不频繁），因此每次写操作都需要经过NameServer，从而减少系统复杂度。\n\nTFS也不需要支持多客户端并发写，同一时刻每个Block只能有一个写操作，多个客户端的写操作会被串行化\n> 是因为进行写操作的多是商家/管理人员，而这些用户对响应的要求比浏览商品的客户要低很多\n\n<img src=\"/img/202103/003.png\" width=\"50%\" height=\"50%\">\n\n> 与GFS不同的地方在于：写入操作只有一种，即写入一个文件，而GFS有追加写和大文件写入这两种情况；NameServer参与度比GFS要高很多，在GFS中，在ChunkServer写入完成后chunk的变化不会立刻同步到master，而是在chunkserver定时发往master的信息中携带。但在TFS中写入完成后需要立刻通知NameServer元数据的修改。这应该是要考虑到商家上传好图片之类的信息后需要立马生效看到效果这样实际的业务需求来设计的。即读多写少的情况，这种情况下会有客户端还没有收到写入成功的消息但是其他用户就能够看到这张图片了，用最快的速度提高图片的生效时间。\n\n在写入完成后DataServer会返回客户端两个信息：小文件在TFS中的block编号以及在block中的偏移。引用系统在读取图片的时候能保证在所有block中他的偏移量都是有效的。\n\n> 这里的一致性要求就比GFS高了，GFS只是保证数据至少有一次写入，且就算是同一个chunk的不同备份，数据的偏移量都可能不一致，因为他们对每一个chunk块都维护了一个元数据结构。而TFS则为了保证应用层面的简单，强制要求任何一个block备份块都能使用同一个小文件的偏移量。即主备block之间所有字节都一致。\n\n## NameServer\n<img src=\"/img/202103/004.png\" width=\"50%\" height=\"50%\">\n\n> 之所以不需要维护文件与Block之间的映射关系是因为block与文件的关联关系已经返回给客户端另行保存了。\n\nDataServer掉线以及新加入的操作都跟GFS一样。\n\n## 讨论\n图片应用有几个问题：\n* 图片去重\n* 图片更新与删除\n<img src=\"/img/202103/005.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202103/006.png\" width=\"50%\" height=\"50%\">\n\n> 保证每个block都能使用同一个物理偏移带来架构简化的同时也意味着无法随便对block做垃圾回收、合并等操作。\n\n# Facebook Haystack\nFacebook相册后端早期采用基于NAS的存储，通过NFS挂载NAS中的照片文件来提供服务。后台出于性能考虑，自主研发了Facebook Haystack。\n\n## 系统架构\n<img src=\"/img/202103/007.png\" width=\"50%\" height=\"50%\">\nFH的思路与TFS类似，也是多个逻辑文件共享一个物理文件。\n\nHaystack系统包括三个部分：目录、存储、缓存。\n\nHaystack存储是物理节点，以物理卷轴（physical volume）的形式组织存储空间，每个物理卷轴一般都很大（100GB），这样10TB的数据也只需要100个物理卷轴。\n\n每个物理卷轴对应一个物理文件，因此，每个存储节点上的物理文件元数据都很小。\n> 将基础的数据块变大了，相应的对块的管理就减少了\n\n多个物理存储节点上的物理卷轴组成一个逻辑卷轴，用于备份。\n\nHaystack目录存放逻辑卷轴和物理卷轴的对应关系，以及照片id到逻辑卷轴之间的映射关系。\n\nHaystack缓存主要用于解决对CDN提供商过于依赖的问题，提供最近增加的照片缓存服务。\n<img src=\"/img/202103/008.png\" width=\"50%\" height=\"50%\">\n\n## 写流程\n<img src=\"/img/202103/009.png\" width=\"50%\" height=\"50%\">\n\n> 这样的话存储端需要跟Haystack目录有一个通信过程，这样才能保证目录的准确性，且相关的元数据位于Hatstack目录。这里的Web服务器就承担了GFS与TFS中的客户端的功能：他先从Haystsck目录中寻找有效的逻辑目录以及对应的物理存储信息，然后将生成id的图片写入存储端。\n\nHaystack的一致性模型只保证写操作成功，逻辑卷轴对应的所有物理卷轴都存在一个有效的照片文件，但有效照片文件在不同物理卷轴中的偏移量可能不同。\n> 这个就类似GFS的一致性模型，即保证数据被写入，但不能保证写入的地方是一致的。这样就不能用TFS一样一个文件ID查询所有副本，需要在另外维护一个文件ID与数据在各个块中的偏移量信息的映射结构。\n\nHaystack只能追加不能更改照片，如果有修改，则新增一条照片ID并将旧的ID替换。如果新的照片和原有照片不在同一个逻辑卷轴，Haystack目录的元数据会更新为最新的逻辑卷轴；如果新增照片和原有的照片在相同的逻辑卷轴，Haystack存储会以偏移更大的照片文件为准。\n\n> 按照用户-逻辑卷轴-物理卷轴。这样的分层结构，对照片修改后如果在同一个逻辑卷轴内，则只需要修改用户-逻辑卷轴部分对于<图片id, 逻辑卷轴>这个映射关系即可。如果不在同一个逻辑卷轴内，则需要修改整体的元数据结构。 ？\n\n### 容错处理\nHaystack存储节点容错：\n<img src=\"/img/202103/010.png\" width=\"50%\" height=\"50%\">\n\nHaystack目录容错：\n<img src=\"/img/202103/011.png\" width=\"50%\" height=\"50%\">\n也就是说Haystack实际上是将元数据持久化到数据库中，将保证元数据写入磁盘的工作交给了数据库。\n\n## Haystack存储\nHaystack存储保存物理卷轴，每个物理卷轴对应文件系统中的一个物理文件，每个物理文件格式如下：\n<img src=\"/img/202103/012.png\" width=\"50%\" height=\"50%\">\n\n多个照片存放在一个物理卷轴中，每个照片文件是一个Needle，包含实际数据以及逻辑照片文件的元数据。部分元数据需要装载到内存中用于照片查找，包括Key（照片ID，8字节），Alternate Key（照片规格，4字节），照片在物理卷轴的偏移Offset（4字节），照片的大小（4字节），每张照片的信息需要占用20字节空间。假设每张照片大小为80KB。则一台可用磁盘为8TB的机器可以保存8TB/80KB=1亿张照片，占用内存1亿x20字节=2GB。\n> 这样的存储设计是基于机器的硬件而生，以硬件上的物理卷轴为基本块用于存储信息。好处是数据集中且由于写入都是在一块物理卷轴中写入，不会有磁盘指针跨磁道的开销，写入快速。\n\n存储节点宕机时，需要恢复内存中的逻辑照片查找表，扫描整个物理卷轴耗时太长，因此对每个物理卷轴维护了一个索引文件，保存每个Needle查找相关的元数据。\n> 这部分元数据既持久化到Needle中和图片数据放一起，又单独持久化为一个索引文件。说明元数据的维护可能并不需要Haystack目录保存到自己本地，只需要等待存储节点将自身的物理卷轴元数据加载到内存中后发送给Haystack目录即可。\n\n由于更新索引文件的操作是异步的，所以可能出现索引文件和物理卷轴文件不一致的情况，不过由于对物理卷轴文件和索引文件的操作都是追加操作，只需要扫描物理卷轴文件最后写入的几个Needle，然后补全索引文件即可，这只能在只有追加写入的系统中才能使用，也很常用。\n> 系统保证会将文件写入，并在写入完成后修改索引文件，但这一步就已经属于异步操作，所以只会出现索引文件缺失而不是索引文件中存在，但是物理卷轴中没有的情况。索引文件缺失的这部分通过对操作日志的重现可以恢复。\n\n<img src=\"/img/202103/013.png\" width=\"50%\" height=\"50%\">\n\n> 既然不需要跟TFS一样保证一个ID都能从所有副本中得到一样的数据，那么就一定会有一个文件ID与物理卷轴偏移量的映射数据结构，这样就可以对存储节点采用垃圾回收策略。而他的策略和其他系统一样都是删除已删除的和重复的数据\n\n## 讨论\nHaystack与TFS最大的不同就在与他可以进行垃圾回收。\n\nHaystack使用RAID6，并且底层文件系统使用性能更好的XFS，TFS不使用RAID机制，文件系统使用Ext3，由应用程序负责管理多个磁盘。\n\n> 看起来就像Facebook不差钱一样，无论是GFS还是TFS都是考虑系统建立在不稳定廉价的硬件基础上，因此他们对于存储节点出现故障的频率是考虑很高的，所以在对文件块的设计上，偏向于小巧轻便，这样当存储节点宕机无法恢复的时候可以快速地对其他副本进行复制备份，且不会对现有业务造成影响 。而Haystack的大块设计，既简化了元数据与磁盘管理开销，但同时增加了磁盘成本与维护成本，每当存储节点宕机切无法恢复时，数据迁移备份的时间会长很多。\n\n# 内容分发网络(CDN)\n<img src=\"/img/202103/014.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202103/015.png\" width=\"50%\" height=\"50%\">\n\n## CDN架构\n<img src=\"/img/202103/016.png\" width=\"50%\" height=\"50%\">\n\n图片存储在后台的TFS集群中，CDN系统将这些图片缓存到离用户最近的边缘节点。\n\nCDN采用两级Cache：L1-Cache以及L2-Cache。\n\n用户访问淘宝网的图片时，通过全局调度系统调度到某个L1-Cache节点。如果L1-Cache节点命中，那么直接讲图片数据返回用户；否则，请求L2-Cache节点，并将返回的图片数据缓存到L1-Cache节点；否则，请求源服务器的图片服务器集群。\n\n每台图片服务器是一个运行着Nginx的Web服务器，他还会在本地缓存图片，只有当本地缓存也不命中时才会请求后端的TFS集群。\n\n对于每个CDN节点，其架构如图所示:\n<img src=\"/img/202103/017.png\" width=\"50%\" height=\"50%\">\n\n每个CDN节点内部通过LVS+Haproxy的方式进行负载均衡。\n\n* [LVS](https://blog.csdn.net/weixin_40470303/article/details/80541639)：该项目在Linux内核中实现了基于IP的数据请求负载均衡调度方案。\n\n* [HAProxy](http://www.ttlsa.com/linux/haproxy-study-tutorial/)：是一个提供高可用性、负载均衡，以及基于TCP和HTTP的应用程序代理。\n\n其中LVS是四层负载均衡软件，性能好；Haproxy是七层负载均衡软件，能够支持更加灵活的负载均衡策略。通过有机结合两者，可以将不同的图片请求调度到不同的Squid服务器。\n\nSquid服务器用来缓存Blob图片呢数据。用户的请求按照一定的策略发送给某台Squid服务器，如果缓存命中则直接返回；否则Squid服务器首先会请求源服务器获取图片缓存到本地，接着再将图片数据返回给用户。\n\n相比起分布式存储系统，分布式缓存系统的实现要容易得多，这是因为缓存系统不需要考虑数据持久化，如果缓存服务器出现故障，只需要简单地将其从集群中删除即可。\n\n## 分级存储\n\n分级存储是淘宝CDN架构的一个很大创新。\n\n由于缓存数据有较高的局部性，在Squid服务器上使用SSD+SAS+SATA混合存储，图片随着热点变化而迁移，最热门的部署到SSD，中等热门的部署到SAS，轻度热门的存储到SATA。\n> 结合数据的访问频繁程度与存储介质的访问速度分多级存储，能够加快数据访问速度。\n\n## 低功耗服务器定制\n淘宝CDN架构的另一个亮点是低功耗服务器定制。\n\nCDN缓存服务是IO密集型服务而不是CPU密集型，因此可以选用CPU功耗相对较低的服务器。\n\n## 讨论\nBlob存储系统读访问量大，更新和删除很少，特别适合通过CDN技术分发到离用户最近的节点。\n\nCDN也是一种缓存，需要考虑与源服务器之间的一致性。如果源服务器删除了Blob数据，需要能够比较实时地推送到CDN缓存节点，否则只能等待缓存节点中的对象被自然淘汰，但是对象的有效期往往很长，热门对象很难被淘汰。\n\n> 可以专门维护一个专门用于接收这种修改与删除操作的程序。但是如果边缘节点很多的情况，光修改一次图片就要使得TFS应用或者上层的应用通知每一个squid服务器，这些工作量会很耗时且浪费资源。或许可以采用GFS中的那种串行化设计，TFS只需要通知离他最近的几台squid服务器，然后让这几台squid服务器继续往外分发修改事件，缓存系统也不需要担心重复删除/修改等问题。\n\n随着硬件技术的发展，SSD价格的下降，新上线的CDN可以全部配制成SSD。","tags":["存储"]},{"title":"Paxos Made Simple笔记","url":"/2021/03/04/Paxos-Made-Simple笔记/","content":"原文：[Paxos Made Simple](https://www.microsoft.com/en-us/research/uploads/prod/2016/12/paxos-simple-Copy.pdf) 翻译：[点击查看](https://www.cnblogs.com/j-well/p/7056951.html)\n\n一致性算法需要在一组服务器节点或者进程中保证一个提案能够在最终结果上达成一致。这里的提案可以是对一次操作的认定，也可以衍生为对一个值的最终结果。\n\npaxos算法中，由三个角色组成：Proposers(提议者)、Acceptors(接受者)、Learners(学习者)。在一个实现中，单个进程可以充当多个角色。\n\n通常在节点之间的通信采用异步模型。\n* 每个参与者（Proposer,Acceptor,Learner）都有可能因为不同的原因导致执行失败、进程停止。当一个提案被选定后，如果所有参与者都同时下线并重启，必须要保证提案结果能被恢复，即需要将结果持久化到各个参与者的磁盘中。\n* 参与者之间传递的信息可能会超时、丢失，但不会被修改也允许被修改\n\n从安全角度来说：\n* 只有从提案发起者发起的提案才能被选定是否通过\n* 在最终结果没有出来前，任何节点/进程不能假设某个提案已经通过或者某个提案会有很大概率通过\n\n一个分布式算法，有两个重要属性：Safety和Liveness\n* Safety：指那些需要保证永远都不会发生的事\n* Liveness：指哪些最终一定会发生的事情\n\n## 提案的选择：\n选定提案最简单的方式就是只有一个Acceptor存在，这样不会存在多个不同的提案情况，但是一旦唯一的Acceptor宕机，则整个系统不可用。\n\n对上一种问题唯一的解决办法就是增加多个Acceptor。此时Proposer向一个Acceptor集合发送提案，某个Acceptor可能会通过这个提案。当有足够多的Acceptor通过它时，我们就认为这个提案被选定了。\n\n这里一个重要问题就是如何判断“足够多”是多少个Acceptor？为了保证数量，这个集合需要包含所有Acceptor成员。\n\n因为集合中任意取两个“大多数”子集，他们一定会存在交集，即用于判断提案是否通过的Acceptor数量至少要超过集合的一半，这就是多数派读写一致性要求。\n\n再要求所有Acceptor只能通过一个提案，那么就可以保证至少有一个提案会被通过。\n\n但是上面并没有考虑实际使用过程中节点不可用的情况。而这种情况在实际问题中往往无可避免，属于Liveness。\n\n在假设没有Acceptor下线的情况下，我们可以设置如下需求：\n> P1：一个Acceptor必须通过它收到的第一个提案\n\n上面所有的假设都在只有一个Proposer的情况下。如果当有多个Proposer同时提出不同的提案，那么可能会发生所有提案都无法满足“足够多”的情况。\n\n* 由于网络延时等原因，提案送达的时间会有先后，可能会出现两个提案各自通过的Acceptor数量相等的情况。但这种情况可以用奇数个数量的Acceptor节点修复。\n* 但是考虑到实际情况中会出现的Accptor下线等问题，会有5个Acceptor节点，其中2个通过提案A，3个通过提案B。当他们要将结果返回给Proposer时，有一个通过提案B的节点下线了，此时Proposer收到的有2个节点通过提案A，两个节点通过提案B。\n\n上面的问题，暗示了一个Accpetor必须要能够通过不止一个提案。\n\n通过对每一个提案分配一个编号来记录一个Acceptor通过的那些提案，于是一个提案就包含一个提案编号以及他的value值。为了不产生混淆，需要保证不同的提案具有不同的编号。当一个具有value值的提案被多数Acceptor通过后，我们就认为该value被选定了。\n\nWe can allow multiple proposals to be chosen, but we must guarantee that all chosen proposals have the same value.  这句无法理解，允许通过多个提案，但是必须保证所有的提案都具有相同的值？\n> P2：如果具有value值v的提案被选定了，那么所有比它编号高的提案的value值也必须是v。\n\n也就是说，如果有两个存在先后顺序的提案同时发出，当最先发出的提案通过并确定好值后，后判断的提案上的值必须时上一步已经确定好的值。\n\n一个提案能否被选定，至少需要有一个Acceptor通过。\n> P2a：如果一个具有value值v的提案被选定了，那么被Acceptor通过的所有编号比他高的提案的value值也必须时v。\n\n即，Acceptor需要保存上一次通过的提案，这个通过的提案不是单个Acceptor通过的提案，而是经过一次paxos流程后最终选定的这个提案。那样的话在一个提案通过后Proposer需要将通过的提案重新传回给Acceptor并让其留档，当同样的提案再次被发送过来的时候可以根据Acceptor保存的上一个提案来对当前要通过的提案执行判断。\n\n由于通信是异步的，一个提案可能会在某个Acceptor c还没收到任何提案的时候就被选定了。此时有另一个Proposer提出了一个具有不同value值的更高编号的提案，根据P1，需要c通过这个提案，但是这样又与P2a矛盾，因为对整个集群来说提案已经通过了，但是对于c来说这个提案根本没有发给他。因此需要对P2进行强化：\n> P2b：如果具有value值v的提案被选定了，那么所有比他编号更高的被Proposer提出的提案value值也必须是v\n\n### 如何证明P2b成立：\n假设某个具有编号m和value值v的提案被选定了，需要证明任意具有编号n（n > m）的提案都具有value值v。我们可以通过对n使用数学归纳法来简化证明，在额外的假设下：即编号在[m, n-1]之间的提案具有value值v，来证明编号为n的提案具有value值v，其中[i, j]表示从i到j的集合。因为编号为m的提案已经被选定了，这就意味着存在一个多数Acceptor组成的集合C，C中的每个成员都通过了这个提案。结合归纳的假设，m被选定意味着C中的每个Acceptor都通过了一个编号在[m, n - 1]之间的提案，并且每个编号在[m, n-1]之间的被Acceptor通过的提案都具有value值v。\n\n由于任何包含多数Acceptor的集合S都至少包含一个c中的成员，我们可以通过保持如下不变性来确保编号为n的提案具有value值v：\n* P2c:对于任意v和n，如果一个编号为n，value值为v的提案被提出，那么肯定存在一个由多数Acceptor组成的集合S满足以下条件中的一个：\n   * S中不存在任何Acceptor通过了编号小于n的提案\n   * v是S中所有Acceptor已经通过的编号小于n的具有最大编号的提案的value值\n\n只要维护P2c的不变性就可以满足P2b了。\n\n当一个提案被通过后，所有通过改提案的Acceptor都要保存这个提案到本地，这样，在所有Acceptor集合中，必然存在一个表示“大多数”的集合，这个集合中一定存在有通过了之前提案的Acceptor。但是这个Acceptor不一定在这个“大多数”集合中占据大多数。比如100和Acceptor，第一次提案时有60台通过了提案，然后进行第二次提案，此时这个新的集合中包含60个Acceptor，但是其中只有10台属于上次通过了提案的Acceptor。此时其他50台的相同提案的编号肯定小于那10台，因此这里又产生一个约束条件：保证当提案通过后在新的提案到达时如果有两种不同编号的同一种提案，则采取编号最新的提案的value。\n\n这种情况下，当一个Proposer在提出一个编号为n的提案时，如果存在一个将要或者已经被多数Acceptor通过的编号小于n的最大编号提案，Proposer需要知道他的信息。在将提案发往Acceptor的时候需要由Acceptor判断出当前自身以通过或者正在执行的小于n的最大编号提案，如果存在则将这个信息发给Proposer。\n单单返回已经通过的提案很简单，但是那种正在执行判断的很难预测它是否会被通过（虽然大部分情况下都是accept的），为了避免陷入预测未来这种困境，Proposer通过提出承诺不会有那样的通过情况来控制它。换句话说，Proposer会请求哪些Acceptor不要再通过任何编号小于n的提案了。即如果某个小于n的提案正在执行中，此时Proposer发送编号为n的提案给Acceptor，Acceptor会保证这个小于n的提案必定不会被通过。\n这就导致了如下提案生成算法：\n\t1. Proposer选择一个新的提案编号n，然后向某个Acceptor集合中的成员发送请求，要求他做出如下回应：\n\t\ta. 保证不再通过任何编号小于n的提案\n\t\tb. 返回它当前已经通过的编号小于n的最大编号提案，如果存在的话\n\t我们把这样的请求称为编号n的prepare请求。\n\t2. 如果Proposer收到来自集合中多数成员的响应结果，那么它可以提出编号为n，value值为v的提案，\n    这里v时所有响应中最大编号提案的value值，如果响应中不包含任何提案，那么这个值就由Proposer自由决定。\n\nProposer通过向某个Acceptor集合发送需要被通过的提案请求来产生一个提案（这里的Acceptor集合不一定是响应前一个请求的集合）。这个过程叫做accept请求。\n\n## Acceptor\nAcceptor会收到两种请求：prepare、accept。Acceptor可以忽略任意请求而不用担心破环算法的安全性。\n它可以再任何时候响应prepare请求，也可以再不违反现有承诺的情况下响应accept请求。\n   * P1a:一个Accepter可以通过一个编号为n的提案，只要它还未响应任何编号大于n的prepare请求\n\n假设一个Acceptor收到了一个编号为n的prepare请求，但是它已经对编号大于n的prepare请求作出了相应，因此它肯定不会再通过任何新的编号为n的提案，于是我们会让Acceptor忽略这样的prepare请求，我们也会让他忽略那些他已经通过的提案的prepare请求。\n\n通过这个优化，Acceptor只需要记住它已经通过的提案的最大编号以及它已经响应过prepare请求的提案的最大编号。因为必须要在出错的情况下也保证P2c的不变性，所以Acceptor要在故障和重启的情况下也能记住这些信息。\n\nProposer可以随时丢弃提案以及它的所有信息，只要它可以保证不会提出具有相同编号的提案即可。\n\n把Proposer和Acceptor的行为结合起来，我们就能得到算法的两阶段执行过程：\n\n    Phase 1:\n        • Proposer选择一个提案编号n，然后向Acceptor的多数集发送编号为n的prepare请求。\n        • 如果一个Acceptor收到一个编号为n的prepare请示，且n大于它所有已经响应的请求的编号，那么他就会保证不会再通过任意编号小于n的提案，同时将它已经通过的最大编号提案（如果存在的话）一并作为响应。\n    Phase 2:\n        • 如果Proposer收到多数Acceptor对他的prepare请求（编号为n）的响应，那么它就会发送一个编号为n，value值为v的提案的acceptor请求给每个Acceptor，这里v是收到的响应中最大编号提案的值，如果响应中不包含任何提案，那么他就可以是任意值。\n        • 如果acceptor收到一个编号为n的提案的accept请求，只要它还未对编号大于n的prepare作出响应，他就可以通过这个提案\n\n**优化：如果一个Acceptor已经收到一个大于n的prepare请求，那么他应该通知给出编号n提案的Proposer，使得Proposer放弃编号为n的提案。**\n\n### 获取被选定的提案值：\n这里会跟Learner有关，Learner必须要能够知道一个提案已经被多数Acceptor通过了，最直观的算法是，让每个Acceptor再通过一个提案时就通知所有Leaner。但这需要让每个Acceptor与每个Leaner通信，通信次数是二者的乘积。\n\n更一般地，Acceptor可以将信息发送给一个特写的Learner集合，他们中的任何一个都可以在某个value被选定后通知所有Learner。这个集合中的Learner越多，可靠性越好，通信复杂度越高。\n\n如果只通知一次Learner的话消息可能会丢失，Learner可以向Acceptor询问他们通过了那些提案，但是任一Acceptor出错，都有可能导致无法分辨是否有多个Acceptor通过了某个提案。在这种情况下Learner可以由Proposer扮演，Proposer之间负责维持通信。\n\n当一个新的提案被选定时，Learner才能发现被选定的value。如果一个Learner想知道是否已经选定一个value，他可以让Proposer利用上面的算法提出一个提案。\n\n### 进展性：\n会有这种情况，两个Proposer轮流发起prepaer请求，但是永远没有一个Proposer进入plase2阶段。\n为了保证进度，必须选择一个特定的Proposer作为唯一的提案提出者。如果这个Proposer可以和多数Acceptor进行通信，并且可以使用比已用编号更大的编号进行提案的话，那么它提出的提案就可以成功被通过。如果知道有某些编号更高的请求，他可以通过舍弃当前的提案并重新开始，这个Proposer最终一定会选到一个足够大的提案编号。这个Proposer叫做Leader。\n文中是说通过选举得到一个Leader，但是具体如何选呢？\n\n即在所有Proposer中选择一个特殊的Proposer，他可以在accept阶段被拒绝后重新获取一个新的编号并发起提案，而其他的Proposer在accept阶段被拒绝后将无法重新获取新编号，除非最外逻辑重新发起一轮新的提案。\n\n## 实现：\nPaxos算法假设了一组进程网络。在他的一致性算法中，每个进程都扮演着Proposer，Acceptor，以及Learner的角色。\n该算法选择了一个Leader来扮演那个特定的Proposer和Learner。Paxos一致性算法就是上面描述的那样，请求和响应都以普通消息的方式发送（响应消息通过对应的提案编号来标识以免混淆）。使用可靠的存储设备存储Acceptor需要记住的信息来防止出错。\nAcceptor在真正发送响应之前，会将它记录到可靠的存储设备中。\n\n不同的Proposer从不相交的编号集合中选择自己的编号，这样任何两个Proposer就不会用到相同的编号。每个Proposer都记录它使用过的最大编号，然后用这个比这更大的编号的提案开始Phase 1\n\n> 本来后面还有一章状态机的，但是我看不太懂就没放。","tags":["分布式"]},{"title":"分布式存储笔记3-1 分布式文件系统（GFS）","url":"/2021/02/28/分布式存储笔记3-1-分布式文件系统（GFS）/","content":"<hr>\n这是一篇在阅读《大规模分布式存储系统：原理解析与架构实战》时的阅读笔记，由于长时间碎片阅读的关系导致在做这种读书笔记的时候接近复制粘贴。虽然其中会有一小部分自己的想法但都十分零碎，希望后续能改进。\n<hr>\n\n分布式文件系统的主要功能有两个：\n1. 存储文档、图像、视频之类的Blob类型数据\n2. 作为分布式表格系统的持久化层\n\n<img src=\"/img/202102/063.png\" width=\"50%\" height=\"50%\">\n\n# Google文件系统（GFS）\n<img src=\"/img/202102/064.png\" width=\"50%\" height=\"50%\">\n\n## 系统架构\n<img src=\"/img/202102/065.png\" width=\"50%\" height=\"50%\">\n\nGFS可分为三种角色：GFS Master（主控服务器）、GFS ChunkServer（CS，数据块服务器）、GFS客户端。\n\nGFS的文件被划分为固定大小的文件块，并拥有一个全局唯一的64位chunk句柄（类似于uuid），chunk被以普通linux文件形式保存在服务器中，并在不同机器中复制多份，默认为三份。\n\n主控服务器中维护了系统的元数据（包括文件及chunk命名空间、文件到chunk之间的映射、chunk位置信息）。它也负责整个系统的全局控制（如chunk租约管理、垃圾回收无用chunk、chunk复制等）。主控服务器会定期与CS通过心跳的方式交换信息。\n> 既然是通过租约实现对chunk server的存活检测，那这个心跳应该都是chunk server发往master.\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PS:找了一下论文果然如此，chunk server定时往master发送自身chunk相关信息。这样这部分数据就不需要让master持久化到自身，而是可以通过与chunk server的通信从提交的信息中构建\n\n客户端是提供给应用程序的访问接口，他是一组专用接口，不遵循POSIX规范，以库文件的形式提供。客户端访问GFS时先从master获取对应文件的句柄与chunk的字节范围。然后client与chunk server直接通信。最大程度减少master的负担。\n\nGFS不缓存文件数据，只缓存元数据信息。这是由GFS应用的特点决定的：MapReduce与Bigtable。\n* MapReduce：GFS客户端使用方式为顺序读写，没有缓存文件数据的必要\n* Bigtable：Bigtable作为分布式表格系统，内部已经实现了一套缓存机制。\n\n如何维护客户端缓存与实际数据之间的一致性是一个及其复杂的问题。\n\n## 关键问题\n### 租约机制\nGFS数据追加以记录为单位，每个记录的大小为几十KB到几MB不等，如果每次记录追加都需要请求Master，那么Master显然会成为系统的性能瓶颈，因此，GFS系统中通过租约（lease）机制将chunk写操作授权给ChunkServer。拥有租约授权的ChunkServer称为主ChunkServer，其他副本所在的ChunkServer称为备ChunkServer。\n\n租约授权针对单个chunk，在租约有效期内，对该chunk的写操作都由ChunkServer负责，从而减轻Master的负载。\n\n> Q:如果主ChunkServer在租约有效期内下线该怎么办?\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1: 客户端如果多次请求ChunkServer失败，则重新往Master申请这个文件块的新的ChunkServer，如果Master确认在租约有效期内原先的主ChunkServer依旧无法上线，则在现有备份ChunkServer中要么直接选择要么通过选举的方式重新赋予一个备ChunkServer权限使其对Client服务。\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2: ~~客户端判断在租约有效期内依旧无法联系上ChunkServer，那么在此之前，Master返回文件命名空间以及chunk相关信息的时候顺便携带chunk的备份服务器信息，那么就让Client发起选举~~（如果由Client直接选择，那么如果有多台Client同时读写同一个数据块，那么将会出现复数个Proposer）【这个操作不行，只能有一个Proposer，否则这是没意义的】\n\n一般来说，由于涉及文件读写，所以租约有效期比较长为60秒所有。\n<img src=\"/img/202102/066.png\" width=\"50%\" height=\"50%\">\n> 直接删除并重新备份，减少了运行期间chunk数据重新保持一致的工作量，过于复杂会使得出问题的几率增加。且同步数据的工程量比直接复制要大。\n\n### 一致性模型\nGFS主要是为了追加写（append）而不是改写（overwrite）而设计的，一方面改写的需求比较少，或者可以通过追加来实现，比如可以只使用GFS的追加功能构建分布式表格系统Bigtable；另一方面是因为追加的一致性模型相比改写要更加简单有效。\n<img src=\"/img/202102/067.png\" width=\"50%\" height=\"50%\">\n\n追加写时，如果成功那万事大吉。如果有些chunkserver写入成功而有些写入失败，失败的副本可能会出现一些可识别的填充（padding）记录。GFS客户端追加失败将重试，只要返回用户追加成功，说明在所有副本中都至少追加成功了一次，也有可能一个chunk被追加了多次，即重复记录；也可能出现一些可识别的填充记录，需要在应用层处理这些问题。\n\n> GFS只负责写入数据成功，但不能保证写入数据的完整性以及物理层面的一致性。即它能确保chunk的所有副本都已经被写入数据，但不能确保所有的数据都一致（这里的一致是指所有的数据都是完整一条。有的chunkserver成功写入数据但是会有重复记录，有些chunkserver写入一些可识别的填充记录。）\n\n> 如果要保证强一致性，那么当某个chunkserver长时间无法响应的时候，client的整个写入都会被阻塞，此时应该添加一个超时机制，如果长时间没有响应，则client重新发起写入请求，这种情况下就容易产生重复数据。\n\n<img src=\"/img/202102/068.png\" width=\"50%\" height=\"50%\">\n\n> 但是每次写入都会返回这部分文件位于chunk的那一部分，需要读取的时候只需要根据这些文件偏移量信息读取即可，而且在chunkserver的写入过程中需要保证原子性，即每个请求的写入不能被打断，但是同一client的写入请求可以被打断。\n\n<img src=\"/img/202102/069.png\" width=\"50%\" height=\"50%\">\n\n### 追加流程\n<img src=\"/img/202102/070.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/071.png\" width=\"50%\" height=\"50%\">\n\n> client在给主chunkserver发送写请求的时候，其他备chunkserver数据还缓存在内存中，如果同时有多个写操作将数据缓存在一台chunkserver服务器中或者client没有发送写请求给主chunkserver或者主chunkserver没有发送写请求给备chunkserver，就会出现内存溢出等问题。\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;解决办法就是在chunkserver中维护一条LRU，如果某段数据长时间没有被写入则会排到队列末尾并被移除。\n\n> 客户端这里并没有在写入完成后将修改元数据的请求发往Master，这部分修改是在ChunkServer定时发往Master的信息中携带的。也就是说master的元数据变更会比chunk server实际文件变更延后一段时间。\n\n> 如果在发送写请求的时候备ChunkServer宕机了该怎么办？\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这时候主ChunkServer发起写入请求会失败，则通知Master将下线的ChunkServer中的数据进行垃圾回收，并将其中的数据重新备份。\n\n> 如果在发送写请求的时候是主ChunkServer宕机了该怎么办？\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Client应该通知Master在超过租约时限后重新在备ChunkServer中选出主ChunkServer并重新开始写入流程。\n\n<img src=\"/img/202102/072.png\" width=\"50%\" height=\"50%\">\n> 这样的要求ChunkServer自身需要维护其chunk的所有备份信息。\n<img src=\"/img/202102/073.png\" width=\"50%\" height=\"50%\">\n\n> 如果在追加过程中主ChunkServer租约过期而失去chunk修改操作的权限改怎么办？\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;主ChunkServer应该要向Master续租，如果续租失败，为了保证流程规范，此次写入应该判定为失败，并让客户端重新向Master请求，由Master选举出新的主ChunkServer。\n\n> 这里说的是写入主ChunkServer，但是前面又说写入最近的ChunkServer并由最近的ChunkServer转发给其他ChunkServer。他们的区别是什么呢？\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：可能是数据量的不同，如果是追加流程且数据量较小的情况下，只需要由客户端发送给最近的ChunkServer并由他进行转发，或者发送给所有的ChunkServer，并将写入命令发给主ChunkServer即可。如果是大文件写入，则需要按照上述流程进行大文件转发。[相关链接](https://zhuanlan.zhihu.com/p/185619042)\n> 2020-03-15追加：就是数据量的不同，最开始的那种数据流与控制流分离的做法适用于数据量大的情况，这可以减少数据传输对整个系统的影响，但会使得写入流程变得更加复杂\n\n### 容错机制\n#### Master容错\nMaster容错与传统方法类似，通过操作日志加checkpoint的方式进行，并且有一台被称为“Shadow Master”的实时热备。\n<img src=\"/img/202102/074.png\" width=\"50%\" height=\"50%\">\n\nMaster需要持久化前两种元数据。对于第三种元数据，可以交给ChunkServer维护，当ChunkServer上线的时候将这些信息发送给Master。\n\nGFS Master的修改操作总是先记录操作日志，然后修改内存。当Master发生故障时，可以通过磁盘中的操作日志恢复内存数据结构。\n\n为了减少Master宕机恢复时间，Master会定期将内存中的数据以checkpoint文件的形式转储到磁盘中，从而减少回放的日志量。\n\nMaster的任何修改元数据的操作都必须在实时热备中完成后才能生效。Shadow Master通过日志的形式接收Master的操作步骤，并在自己的内存中回放这些元数据操作。\n\n为了保证同一时刻只有一台Master工作，是否为主Master需要通过选举得到。\n\n> 如果热备服务器宕机了导致Master始终无法写入成功该怎么办？\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果允许也可以部署两台热备服务器。另一种方法就是Master将日志同步记录保存下来，当热备服务器上线后将之前的操作重新发给热备服务器。\n\n#### ChunkServer容错\nGFS采取复制多个副本的方式实现ChunkServer的容错，每个chunk由多个存储副本，分别存储在不同的ChunkServer上。\n\n对于每个chunk，必须都要写入成功才算整个写入流程成功。如果相关副本丢失或者服务器下线的情况，Master会将其上的副本重新复制，并且当这台服务器重新上线的时候他的数据会被垃圾回收，因为此时它上面的数据都有可能与其他副本不一致。\n<img src=\"/img/202102/075.png\" width=\"50%\" height=\"50%\">\n> 这部分数据也将会被视为垃圾，并在合适的时候进行回收。\n\n> 这样来看chunk中会存储很多垃圾数据：重复写入的数据、可读取的填充数据、错误数据、已删除的数据。如果放任这些数据积累，可能会造成空间的浪费，GFS是否有类似于Bitcask的垃圾回收机制或者LevelDB的SSTable合并机制用于清理垃圾？\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：有，GFS采用惰性回收的方式进行垃圾回收。在删除文件的时候会将文件的元数据做一个标记，master会在合适的时候扫描所有chunk的namespace并重新整理chunk。这里就应该会将已删除的数据、重复写入的数据、可读取的填充数据、错误数据清除。\n\n> 看文章说的都是已删除数据，其他垃圾数据不知道会不会清楚，不过我想应该会的吧，毕竟成本放那里，能省一点是一点。\n\n### Master设计\n#### Master内存占用\n内存是Master的稀有资源。chunnk的原信息包括全局唯一的ID、版本号、每个副本所在的chunkserver等。\n<img src=\"/img/202102/076.png\" width=\"50%\" height=\"50%\">\n\n#### 负载均衡\n<img src=\"/img/202102/077.png\" width=\"50%\" height=\"50%\">\n系统中需要创建chunk副本的情况有三种：chunk创建、chunk复制、负载均衡。\n<img src=\"/img/202102/078.png\" width=\"50%\" height=\"50%\">\n> 第二点就是为了后续的文件写入预留出空间，否则都用来存储chunk而没有空间写入，就使得添加新的服务器对分布式存储系统的性能毫无提升。\n\n当chunk的数量低于一定的数量以后，Master会尝试重新复制一个chunk副本。可能的原因包括：ChunkServer宕机、ChunkServer报告Chunk副本损坏，ChunkServer磁盘故障等。\n\n每个chunk复制任务都有优先级，按照优先级从高到低在Master队列排队等待执行。\n\n> 这个优先级应该是按照chunk的热度与数量来划分的，如果某个chunk的数据访问量高，那么为了保证后续的写操作，则优先将其备份。或者某一个chunk只剩一个副本，为了保证数据不丢失，则也要优先将其备份。而热度与数量之间我认为以数量为优先。因为chunk整块丢失是无法自动化恢复的，且无法保证完全恢复，而热度方面还有其他备用块分担压力。\n\n当client要写入到一个只有一个副本的chunk块的时候，GFS将会阻塞其操作，并规定必须要有两个副本才可以，此时chunkserver会将这个情况报告给master用于提高这个chunk块的复制优先级。\n\n> 就跟我上面猜想的一样，一个副本的时候已经很危险了，为了防止操作对现有chunk块造成不可逆的影响，需要优先保证副本的数量。\n\nMaster会定期扫描当前副本的分布情况，如果发现磁盘使用量或者机器负载不均衡，将会执行重新负载均衡操作。\n\n> 这个操作应该就是将磁盘压力大的chunk复制到磁盘使用量少的服务器上，并将原来的chunk删除。\n\n<img src=\"/img/202102/079.png\" width=\"50%\" height=\"50%\">\n\n#### 垃圾回收\n<img src=\"/img/202102/080.png\" width=\"50%\" height=\"50%\">\n\n对于那些下线后的没有执行删除的chunkserver，master会维护一个递增的版本号，当检测到版本号过期时一样会将chunk的空间内释放。\n\n#### 快照（Snapshot）\n快照操作是对源文件 / 目录进行一个“快照操作”，生成该时刻源文件根目录的一个瞬间状态存放于目标文件根目录中。\n\nGFS采用标准的写时复制技术，“快照”只是增加GFS中chunk引用计数，表示这个chunk被快照文件引用 了，等到客户端修改这个chunk时，才需要在chunkserver中拷贝chunk的数据生成新的chunnk，后续的修改操作落到新生成的chunk上。\n\n> 也就是说这里的快照不仅仅是对master元数据的快照，还是对当前目录下所有文件做的快照，当快照完成后后续的读写工作都将会在新的chunk中执行。类似于做了一个完整的目录下的所有文件备份工作。\n<img src=\"/img/202102/081.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/082.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/083.png\" width=\"50%\" height=\"50%\">\n\n> 快照相当于给所有chunk做一个标记（体现在引用计数大于1），并当gfs需要对这个chunk进行操作的时候再复制该chunk进行备份，这里可能会有一个情况就是后续只写入C3，那么foo的chunk将会有C1、C2、C3、C3’这四种。此时如果C1丢失，那么快照也随之失效了。\n\n### ChunkServer设计\n<img src=\"/img/202102/084.png\" width=\"50%\" height=\"50%\">\n\n> 新建的之后直接在旧的chunk上覆盖写即可。这样也就解决了上面提到的如何回收除了删除文件之外的那种重复数据、填充数据、错误数据等办法。不需要将其做具体区分，只需要按chunk进行整块删除，并在后续新数据写入的时候直接覆盖即可。\n\n<img src=\"/img/202102/085.png\" width=\"50%\" height=\"50%\">\n\n## 总结\n谷歌用GFS证明了单总控节点在面对现代数据处理的情况下是可行的，既保证了原子性又容易实现。这里的原子性属于“保证至少有一次写入/记录至少原子性追加一次”，即一次写入数据可能会有重复写入的问题，但这个问题交给应用层面解决，浪费的空间在当chunk块删除的时候会被直接覆盖。\n\n通过租约的方式将对chunk的修改授权下放到ChunkServer从而减少了Master的负载，通过流水线的方式复制多个副本以减少延时，追加流程复杂繁琐。需要设计高效简介的元数据模型，并且要支持快照操作。支持写时复制的B数能够满足Master日常管理元数据所需，这里的实现相当复杂。\n","tags":["存储"]},{"title":"分布式存储笔记3 总揽","url":"/2021/02/24/分布式存储笔记3-总揽/","content":"<hr>\n这是一篇在阅读《大规模分布式存储系统：原理解析与架构实战》时的阅读笔记，由于长时间碎片阅读的关系导致在做这种读书笔记的时候接近复制粘贴。虽然其中会有一小部分自己的想法但都十分零碎，希望后续能改进。\n<hr>\n\n架构设计之初需要估算系统的性能从而权衡不同的设计方法\n> 我感觉最难的就是估算性能与权衡不同的设计方法了。估算性能需要对系统的业务与公司的用户群体有一个清晰的认识，权衡不同的设计方法则需要大量的技术积累，毕竟量多了才能选\n\n接下来首先会有分布式系统相关的基础概念和性能估算方法。接着才是分布式系统的基础理论知识，包括数据分布、复制、一致性、容错等。最后就是常见的分布式协议。\n\n## 主要协议：##\n* paxos协议：paxos选举协议用于多个节点之间达成一致，往往用于实现总控结点选举\n* 两阶段提交协议：用于保证跨多个结点操作的原子性\n\n## 基本概念：\n### 异常：\n\n在分布式存储系统中，往往将一台服务器或者服务器上运行的一个进程称为一个节点。\n\n大规模分布式存储系统的一个核心问题在于自动容错，由于网络与硬件往往是不可靠的，因此会出现各种异常情况。\n\n#### 异常类型：\n1. 服务器宕机\n可能原因：内存错误、服务器停电\n服务器宕机可能随时发生，此时节点无法正常工作，称为不可用（unavailable），服务器重启后节点失去所有内存信息。需要读取持久化介质中你数据来恢复内存信息，从而快速恢复到宕机前的某个一致状态。进行退出同理。\n> 所以需要在节点重启/启动的时候快速构建内存信息，通常可以通过持久化内存信息作为索引文件来实现\n\n2. 网络异常\n可能原因：消息丢失、消息乱序（如果采用UDP通信）、网络包数据错误、数据分区（通常是不同网络服务商之间无法正常通信的现象）\n设计时就要假定网络永远不可靠，只有收到接收方确认消息后才能认定这条消息发送成功。\n\n3. 磁盘故障\n可能原因：磁盘损坏、磁盘数据报错\n磁盘损坏会导致数据丢失，因此需要将数据备份到多台服务器上，如果出现损坏则快速地从其他服务器恢复数据。\n磁盘数据错误可以采用校验和（checksum）机制来解决，这个机制既可以在OS层面上实现，也可以在应用程序层面实现\n\n#### 超时：\n在分布式系统调用中，通过RPC对远端服务器函数进行调用会有三种状态：成功、失败、超时。与本地调用的两种状态相比（成功、失败）多了一个超时，这是因为网络延时/故障等原因引起。这三个状态也称为分布式存储系统的三态。\n<img src=\"/img/202102/025.png\" width=\"50%\" height=\"50%\">\n\n> 之所以将“超时”独立与失败，是因为调用方无法确定是在发起请求的时候网络异常还是在调用成功后响应时网络异常。\n\n当超时的时候客户端不能简单地认为服务器端处理失败。通常这种情况可以将服务端暴露出来的接口设计为冥等，这样当出现失败/超时的时候客户端可以一直用相同的参数发起请求，直到成功。\n\n### 一致性：\n由于异常的存在，分布式存储系统设计时往往会将数据冗余存储多份，每一份称为一个副本，当某一个节点出现故障时可以从其他副本读取数据。\t\n\n副本是分布式存储系统容错技术的唯一手段。\n\n而由于多个副本的存在，如何保证多个副本间数据的一致性就是整个分布式系统理论的核心。\n\n两个方面理解一致性：\n* 从客户的角度：客户的读写时对他们来说数据是否一致\n* 从服务端的角度：整个存储系统中所有副本是否一致，更新顺序是否相同\n\n> 两个不同的角度对于一致性的要求也不一样。如果从客户端角度出发，只要求客户端在读写数据的时候保证一致性，那么在存储系统中这个数据的某些副本可能并不处于一致状态，只不过在客户端读的过程中会将这些副本给排除掉；从服务端的角度出发则要求整个存储系统的副本达成高度的统一。\n\n定义场景\n<img src=\"/img/202102/026.png\" width=\"50%\" height=\"50%\">\n从客户端的角度出发一致性包含三种情况：\n<img src=\"/img/202102/027.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/028.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/029.png\" width=\"50%\" height=\"50%\">\n> 最终一致性，需要等待一段时间达成一致性。通常来说分布式存储系统采用的都是强一致性和最终一致性。而具体要用哪一个需要看业务的具体需要，如果是读取频率高的场景则要保证强一致性，如果类似于分布式文件系统的场景则可以采用最终一致性\n\n最终一致性具有其他变体：\n<img src=\"/img/202102/030.png\" width=\"50%\" height=\"50%\">\n> 读写一致性通常需要等待数据在存储系统中同步完成；会话一致性可能是为了提高吞吐量从而将一部分写入数据保存在内存中，类似于LevelDB的方式，这样当一个失效的时候可能会丢失内存中的数据，导致新创建的会话无法读取这部分数据；\n\n### 衡量指标：\n#### 性能：\n常见的性能指标有：系统的吞吐能力、系统的响应时间\n\n这两个指标往往是矛盾的，追求高吞吐的系统呢往往很难做到低延迟；追求低延迟的系统，吞吐量也会受限制。\n> 前文讲过，分布式存储系统是在保证低延迟的基础上提高吞吐量\n\n##### 可用性：\n系统可用性指系统在面对各种异常时可以提供正常服务的能力。可用性可以用系统停服务的时间与正常服务的时间的比例来衡量。\n* 某个系统的可用性为4个9（99.99%），他的允许停服务时间最大不能超过365 x 24 x 60 / 10000 = 52.56分钟。\n\n##### 一致性：\n前文有过说明，一般来说，越是强的一致性模型，用户使用起来越简单。\n\n大部分存储系统都倾向强一致性\n> 因为如最终一致模型，对用户来说可能无法区分是同步失败还是在等待同步当中\n\n##### 可扩展性：\n指分布式存储系统通过扩展集群服务器规模来提高系统存储容量、计算量和性能的能力。\n\n良好的分布式存储系统的扩展性体现在系统性能与服务器数量呈线性关系。\n\n#### 性能分析：\n需要在系统设计之初就估算存储系统的性能。\n\n系统设计之初通过性能分析来确定设计目标，防止出现重大设计失误。等系统运行后通过性能优化方法找到系统的瓶颈点并消除。\n\n性能分析的结果是不精准的，但是不会相差一个大的数量级。\n\n设计之初需要分析整体架构，然后重点分析可能成为瓶颈的单机模块。系统的资源（CPU、内存、磁盘、网络）是有限的，性能分析就是需要找出可能出现的资源瓶颈。\n\n##### 分析实例：\n\n**Q:生成一张有30张缩略图（假设图片原始大小为256KB）的页面需要多少时间？** \n<img src=\"/img/202102/031.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/032.png\" width=\"50%\" height=\"50%\">\n\n**Q:1GB的4字节证书，执行一次快速排序需要多少时间？**\n<img src=\"/img/202102/033.png\" width=\"50%\" height=\"50%\">\n\n**BigTable系统性能分析**\n<img src=\"/img/202102/034.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/035.png\" width=\"50%\" height=\"50%\">\n\n> 还是要在实践中积累经验\n\n### 数据分布：\n数据分布的方式有两种：哈希分布、顺序分布\n\n数据分散到多台机器后，需要尽量保证多台机器之间的负载时比较均衡的。衡量机器负载均衡的因素很多：机器Load值、CPU、内存、磁盘、网络等资源的使用情况；读写请求数及请求量等。\n\n分布式存储系统需要能自动识别负载高的节点，当某台机器的负载较高时，将它服务的部分数据迁移到其他机器，实现自动负载均衡。\n\n> Q:为什么不将流量转移到其他的备份机器中呢？\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A:GFS的备份最多不会超过10台，如果流量大到10台机器都满了那就没地方迁移了，而直接将热点数据转移到其他空闲的服务器可以保证扩容的灵活性，在流量继续增加的情况下还可以添加新的服务器并将热点数据转移到这台服务器上。\n\n分布式存储系统的一个基本要求就是透明性，包括数据分布透明性、数据迁移透明性、数据复制透明性、故障处理透明性。\n\n#### 哈希分布：\n通常根据数据主键（hash(key) % N）或者数据所属的用户id（hash(user_id) % N）计算哈希值来决定将数据映射到哪台服务器。\n\n哈希分布的难点在于如何找到一个好的散列特性。\n* 如果按数据主键分布，会使得一个用户下的数据分布到多台服务器，当要操作同一个用户下的多条数据的时候要同时修改多台服务器的数据十分困难，此时大量的网络开销就是性能瓶颈。\n* 如果按照用户id分布，容易出现呢“数据倾斜”的问题，即某些大用户的数据量很大，无论集群的规模多大，这些用户始终由一台服务器处理。\n\n处理大用户问题一般有两种方式：手动拆分、自动拆分\n* 自动拆分：根据数据分布算法实现动态调整，自动就爱哪个大用户的数据拆分到多台服务器上。\n* 手动拆分：线下标记系统中的大用户（例如运行一次MapReduce作业），并根据这些大用户的数据量将其拆分到多台服务器。\n\n传统的哈希还有一个问题，当系统中的服务器上线下线的时候N值发生变化，数据映射被完全打乱，几乎所有数据都需要重新排布，这将带来大量数据迁移。\n\n**解决办法：**\n<img src=\"/img/202102/036.png\" width=\"50%\" height=\"50%\">\n> 但这样又需要一台新的服务器用于保存哈希值与服务器的对应关系，同时必须要保证这个模块高可用，这将提高整个系统的复杂性\n\n<img src=\"/img/202102/037.png\" width=\"50%\" height=\"50%\">\n> 这只是缓解了数据重新排布的情况，不能完全避免，依旧会有数据要重新排布。\n\n<img src=\"/img/202102/038.png\" width=\"50%\" height=\"50%\">\n加入node-5后只影响了node-3的数据分布。但node-3需要迁移的数据如果过多，整个集群的负载也会不均衡。一种方法是将需要迁移的数据分散到各个集群当中，没台服务器只需要迁移1/N的数据量，为此引入了虚拟节点的概念。\n\n#### 顺序分布：\n哈希散列破坏了数据的有效性，只支持随机读，不支持顺序扫描。\n> 不过如果按照之前说的添加一台哈希-元数据服务器的话可以通过这台服务器进行扫描。\n\n一种方法是按用户id进行哈希分布，这样就保证一个用户的数据位于同一节点下，可以进行顺序扫描。但是也会带来数据倾斜的问题，无法发挥分布式存储系统的多机并行处理能力。\n\n因此，顺序分布常用于分布式表格系统。将大表按顺序划分为连续的范围，每个范围成为一个子表，总控服务器负责将这些子表按照一定的策略分配到存储节点上。\n<img src=\"/img/202102/039.png\" width=\"50%\" height=\"50%\">\nRoot用来维护数据的分布情况。\n\n随着子表数据插入与删除，有些子表会变得很大，某些变得很小，数据分布不均匀。如果采用顺序分布，在设计时就需要考虑子表的分裂与合并，这将会增大系统的复杂度。\n\n* 子表分裂：当一个子表太大超过一定阈值的时候，需要分裂为两个子表，从而有机会通过系统的负载均衡机制分散到多个存储节点。\n* 子表合并：一般由数据删除引起。当相邻的两个子表都很小时，可以合并为一个子表。\n\n一般来说，单个服务节点能够服务的子表数量是有限的，比如4000～10000个，子表合并的目的是为了防止系统中出现过多太小的子表，减少系统中的元数据\n> 减少Root的维护成本\n\n#### 负载均衡：\n分布式存储系统中的每个集群一般有一个总控节点，其他节点为工作节点你，由总控节点根据全部负载信息进行整体调度。\n\n工作节点刚上线时，总控节点需要将数据迁移到该节点\n> 采用数据迁移而不是直接追加写的原因可能是为了防止大量的写入请求冲击这台服务器。\n\n系统运行过程中也要随时不断的进行数据迁移，将数据从负载较高的工作节点迁移到负载较低的工作节点。\n\n工作节点通过心跳包将节点负载相关信息（CPU、内存、磁盘、网络等资源利用率，读写次数以及读写数据量）发送给主控节点。主控节点计算出工作节点的负载以及需要迁移的数据量。生成迁移任务放入迁移队列中等待执行。\n\n负载均衡需要掌握节奏，如果新加入一台机器，主控节点立刻将大量的数据同时迁移到这台新的机器，整个系统在新增机器的过程中服务能力就会大幅降低。一般来说，从新增机器加入到集群负载达到比较均衡的状态需要较长一段时间，比如30分钟到一个小时，\n\n> 可以将负载量大的工作节点中的数据优先迁移，即根据负载量进行排序，最高的几台工作节点优先迁移数据。\n\n工作节点的数据往往会有多个副本，对外提供服务的称为主副本。当发生数据迁移的时候，可以将服务切换到其他副本然后进行迁移，这种无缝操作对用户来说完全透明。\n<img src=\"/img/202102/040.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/041.png\" width=\"50%\" height=\"50%\">\n\n#### 复制：\n数据备份了多份，但通常只会有一份用于提供服务，当无法提供服务时，主控系统会自动切换到备份，这个操作称为自动容错。\n\n数据的副本有两种：主副本（Primary）、备副本（Backup）\n\n复制协议分为两种：强同步复制、异步复制\n* 强同步复制：可以保证主备副本之间的一致性，但是当备副本出现故障时，也可能阻塞存储系统的正常写服务。影响系统整体可用性。\n* 异步复制：可用性相对较好，但是一致性得不到保障，主副本出现故障时还有数据丢失的可能。\n\n两者的区别在于用的鞋请求是否需要同步到备副本才可以返回成功。加入备副本不止一个，复制协议还会要求写请求至少需要同步到几个备副本。\n> 不管是强同步还是异步，都要求主副本写入完成后才可以返回，即保证了主副本数据完整。但是这里难道说异步复制连主副本是否需要写入完成都不需要判断了吗？\n\n##### 复制的概述：\n复制常见的做法是将数据写给主副本，由主副本确定操作的顺序并复制到其他副本。\n<img src=\"/img/202102/042.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/043.png\" width=\"50%\" height=\"50%\">\n> 备副本阻塞无法返回的情况下可以参考多数派写方法，当超过一半的备副本返回写入成功响应后就视本次写入成功。（超过一半 => 至少1个）\n<img src=\"/img/202102/044.png\" width=\"50%\" height=\"50%\">\n> 本地写入完成并且还没备份到其他服务器的时候，如果发生不可恢复的故障会导致本次写入数据完全丢失，而对于客户端来说本次写入是已经完成了的。\n\n强同步复制和异步复制都是将主副本的数据以某种形式发送到其他副本，这种复制协议称为基于主副本的复制协议（Primary-based protocol）。这种方法要求在任何时刻只能由一个副本作为主副本，由它来确定写操作之间的顺序，如果主副本出现故障，需要选举一个备副本称为新的主副本，这步操作称为选举，经典的选举协议为paxos协议。\n\n主备副本之间的复制一般通过操作日志实现。\n\n为了利用好磁盘的顺序读写特性，将客户端的写操作先顺序写入到磁盘中，然后应用到内存中，由此内存是随机读写设备，可以很容易通过各种数据结构有效组织起来。当服务器宕机时，只需要回放操作日志就可以恢复内存状态。为了提高并发能力，系统往往会用成组提交技术写入数据。\n\n> 如果是写入大文件根据HDFS的EditsLog来看也是直接记录数据内容的，然后通过定期合并/删除等方式减少操作日志的大小。\n<img src=\"/img/202102/045.png\" width=\"50%\" height=\"50%\">\n> 跟前面第一次遇到检查点概念的时候我的理解一样，检查点持久化后只需要恢复这个检查点之后的数据即可。\n\n除了给予主副本的复制协议，分布式存储系统中还可能使用给予写多个存储节点的复制协议（Replicated-write protocol）。比如Dynamo系统中的NWR复制协议，其中N为副本数量，W为写操作的副本数，R为度操作的副本数。\n\nNWR协议中多个副本不再区分主副，客户端根据一定的策略往其中的W个副本写入数据，读取其中的R个副本。只要W+ R > N，可以保证读到的副本中至少有一个包含了最新的更新。\n\n但是，这种协议的问题在于不同副本的操作顺序可能不一致，从多个副本读取时可能出现冲突。（不建议使用）\n\n> R或者W设置的越大也会导致整个响应越长，因为最终的响应时间是根据最慢的响应来的。在读取到数据的时候还需要判断哪些数据是最新的，这时就需要向量时钟来配合。\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;只要W + R > N，就能保证读的节点一定会和写的节点产生交集。这样才能保证系统的强一致性。\n\n### 一致性与可用性：\nCAP理论：一致性（Consistency）、可用性（Availability）、分区可容忍性（Tolerance of network Partition）三者不能同时满足。\n<img src=\"/img/202102/046.png\" width=\"50%\" height=\"50%\">\n其中，分区可容忍性是一定要满足的，因此只能从一致性与可用性中权衡利弊。\n<img src=\"/img/202102/047.png\" width=\"50%\" height=\"50%\">\n具体如何采用需要根据系统的业务来权衡。\n\n### 容错：\n容错是分布式存储系统设计的重要目标，只有实现了自动化容错，才能减少人工运维成本呢，实现呢分布式存储的规模效应。\n\n分布式存储系统需要能够检测到机器故障，故障检测往往通过租约（Lease）协议实现。然后需要能够将服务复制或者迁移到集群哪种呢的其他正常的存储节点。\n\n最常出现的故障就是单机故障（通过备份解决），然后是机架故障（备份到其他机架）等\n\n#### 故障检测：\n心跳是一种很自然很常见的故障检测方法。\n\n但是当主从服务器之间的网络出现延时，或者副节点过于繁忙导致长时间无法及时响应心跳等原因，会使得副节点没有宕机，但主节点就开始对他所保存数据开始复制，这会出现多台服务器（原先的副节点与新备份的节点）同时服务同一份数据从而导致数据不一致。\n\n这里的重心是接收心跳方在何种情况下应该被认为已发生故障并停止服务。\n\n> 如果在主控节点那边做判断，一旦副节点无法及时响应心跳并开始转移它数据的服务，那么在逻辑层面将这台服务器下线，后续如果继续上线则将其认定为一台全新的服务器。\n\n由于机器之间会进行时钟同步，且相差不大（比如不会超过0.5秒），那么，我们可以通过租约（Lease）机制进行故障检测。\n\n#### 租约机制：\n租约机制是一种带有超时时间的授权。\n\n假设机器A需要检测机器B是否发生故障，机器A可以给机器B发放租约，机器B持有的租约在有效期内才允许提供服务，否则主动停止服务。机器B的租约快要到期时向机器A主动申请租约。\n\n正常情况下，机器B通过不断申请租约来延长有效期，当机器B出现故障或者与机器A之间的网络发生故障时，机器B的租约将国旗，从而机器A能够确保机器B不再提供服务，机器B的服务也会被迁移到其他服务器。\n\n> 在什么情况下机器A才会认定机器B的服务出现故障呢？如果机器B出现故障，那么机器A是无法检测到的，只能等服务请求机器B的数据的时候才会出现异常，那这种情况应该就是服务请求B的数据的时候如果出现异常则向机器A报告，并由机器A将B的服务迁移到其他服务器中。若是迁移完成后机器B又恢复了服务且他的租约尚未过期，那A不过不在逻辑层面将B下线的话不一样还是会有多台机器对同一份数据提供服务吗？\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上述问题答案：租约加上提前量，假设租约10秒过期，则A需要等到11秒后才能认定B无法提供服务，这样就能保证将B的服务迁移后就能保证B如果在后面恢复之后不会继续提供服务。\n\n#### 故障恢复：\n常见的分布式存储系统分为两种结构：单层结构和双层结构。\n* 单层结构：在系统中对每个数据分片维护多个副本；\n* 双层结构：类似于BigTable系统，将存储和服务分为两层，存储层对曾哥数据分片维护多个副本，服务层只有一个副本提供服务。（服务就是Bigtable，存储依托于GFS）\n<img src=\"/img/202102/048.png\" width=\"50%\" height=\"50%\">\n\n单层结构：当节点1出现故障时，会启用节点2对外提供服务。此时节点1会有两种情况：临时故障、永久故障\n* 临时故障：当节点1重新上线后，会将节点2的数据同步到节点1，此时节点1作为备份节点。\n* 永久故障：当一段时间后节点1还是无法上线则将其认定为永久故障，此时需要对节点1的数据进行复制。\n\n双层结构：数据块不会在服务节点中做备份，当一个服务节点发生故障的时候，系统会从分布式文件系统中重新获取这个节点中的数据块，并将其放置在其他正常的节点并提供服务（这里可以将数据直接加载到内存中）。\n\n节点故障会影响系统服务，在故障检测以及故障恢复的过程中不能提供些服务及强一致性读服务。\n> 为什么？提供写服务，并在后续节点上线后将数据同步过去不可以吗？\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;后续节点上线后其中的数据已经不一致，但是该节点可以参与后续的服务工作，这样会使得客户端读取到过期数据。而且实现也复杂。\n\n故障检测时间分为两种：故障检测时间、故障恢复时间\n\n单层结构的备副本和主副本之间保持实时同步，切换为主副本的时间很短。\n\n两层结构故障恢复往往实现成本只需要将数据的索引重新加载到内存中即可。\n\t\n总控节点也会出现故障，因此也需要总控节点的副节点以及通过实时同步保证数据的一致性。\n\n当故障发生时，通过外部服务器选举某台副本作为新的总控节点，而这个外部服务也得是高可用的，为了进行选主或者维护系统中的重要信息，可以维护一套通过Paxos协议实现的分布式锁服务，比如Chubby或者Zookeeper。\n\n### 可扩展性：\n主流的分布式存储系统大多都带有主控节点，理论上P2P架构更有优势，但实际上主控节点依旧能够满足大部分业务所需。\n\n传统数据库可以通过分库分表进行水平扩展。\n\n分布式存储系统的可扩展性不能简单地通过系统是否为P2P架构或者是否能够将数据分布到多个存储节点来衡量，而应该综合考虑节点故障后的恢复时间，扩容的自动化程度，扩容的灵活性等。\n\n### 总控节点：\n总控节点用于恢复数据分布信息，执行工作机管理，数据定位，故障检测和恢复，负载均衡等全局调度工作。\n\n总控节点使得系统的设计更加简单，并且更加容易做到强一致性，对用户友好。\n\n* 分布式文件系统的总控节点除了执行全局调度，还需要维护文件系统目录树，此时内存容量可能会成为瓶颈。\n* 总控节点只需要维护数据分片的位置信息，这时内存一般不会成为瓶颈。\n<img src=\"/img/202102/049.png\" width=\"50%\" height=\"50%\">\n如果总控节点成为瓶颈，可以在总控机与工作机之间增加一层元数据节点，每个元数据节点只维护一部分而不是整个分布式文件系统的元数据。而总控节点只需要维护少量元数据节点数据即可。\n\n### 数据库扩容：\n数据库可扩展性实现的手段包括：通过主从复制提高系统的读取能力，通过垂直拆分和水平拆分将数据分布到多个存储节点，通过主从复制将系统扩展到多个数据中心。\n<img src=\"/img/202102/050.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/051.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/052.png\" width=\"50%\" height=\"50%\">\n\n### 异构系统：\n#### 同构系统：\n<img src=\"/img/202102/053.png\" width=\"50%\" height=\"50%\">\n> 这就有点像GFS的设计，读写部分由客户端直接与存储节点交互\n\n将存储节点分为若干组，每个组内的节点服务完全相同的数据，其中一个节点为主节点，其他节点为备节点。同一组存储节点服务相同的数据，这样的存储系统成为同构系统。\n\n缺点：增加副本需要迁移的数据量太大（如果要增加副本，则要将主节点中的数据全部拷贝到副本节点，假设主节点数据量为1T，节点之间带宽为20MB/s,则完全备份需要1TB/20MB/s=50000s，耗时长且容易出错）\n* 大规模分布式存储系统要求具有线性可扩展性，即随时加入或者删除一个或者多个存储节点，系统的处理能力与存储节点的个数成线性关系。\n\n#### 异构系统：\n异构系统与同构系统的区别在于对数据的划分，同构系统将数据全部放置在同一个节点中，这样会使得数据的备份十分耗时。而异构系统将数据划分为多个数据块，并将这些数据块分布到整个集群中的不同节点当中，当一个存储节点出现问题的时候，将由整个集群来恢复数据服务而不是固定的几台服务器，这样能提高数据的可用性，且备份的时候传输数据块的效率比一个完整的数据要高很多。\n<img src=\"/img/202102/054.png\" width=\"50%\" height=\"50%\">\n当节点1宕机的时候其中的数据服务将由节点2、节点3来支撑，并由其他节点5、节点4来重新备份，这样可以将备份的网络开销与提供服务的网络开销隔离开使得效率更高，且恢复时间短，当集群规模越大的时候，优势越明显。\n\n### 分布式协议：\n\n分布式协议有很多，例如：租约、复制协议、一致性协议。其中两阶段提交协议与Paxos协议最有代表性。\n\n两阶段提交协议用于保证跨多个节点操作的原子性。\n\nPaxos协议用于确保多个节点对某个投票（例如哪个节点为主节点）达成一致。\n\n#### 两阶段提交协议（2PC）：\n常用来实现分布式事务。\n\n在2PC中，系统一般包含两类节点：一类为协调者（coordinator），通常一个系统中只有一个；另一类为事务参与者（participants，cohorts或workers），一般包含多个。\n\n协议中假设每个节点都会记录操作日志并持久化到非易失性存储介质，及时节点发生故障日志也不会丢失。两个阶段如下：\n<img src=\"/img/202102/055.png\" width=\"50%\" height=\"50%\">\n> 如果当一个参与者长时间没有回复，就会导致整个协议过程阻塞。或者协调者通知完参与者后下线了且数据没有做保存，那么也会导致该流程失败。不过可以引入事务超时机制来避免此问题。\n<img src=\"/img/202102/056.png\" width=\"50%\" height=\"50%\">\n\n上面的两个故障总结如下：\n* 事务参与者发生故障。给每个事务设置一个超时时间，如果某个事务参与者一直不响应，到达超时时间后整个事务失败。\n* 协调者发生故障。协调者需要将事务相信信息记录到操作日志并同步到备用协调者，加入协调者发生故障，备用协调者可以接替他完成后续的工作。如果没有备用协调者，协调者又发生了永久性故障，事务参与者将无法完成事务而一直等待下去。\n\t两阶段提交协议是阻塞协议，执行过程中需要锁住其他更新，且不能容错，通常大部分分布式存储系统都会放弃分布式事务的支持。\n\n#### Paxos协议：\nPaxos协议用于解决多个节点之间的一致性问题。\n\n多个节点之间通过操作日志同步数据，如果只有一个节点为主节点，那么很容易确保多个节点之间操作日志的一致性。当主节点出现故障的时候，系统需要选举出新的主节点。\n\n只要保证多个节点之间操作日志的一致性，就能够在这些节点上构建高可用的全局服务，例如分布式锁服务，全局命名和配置服务等。\n> 分布式系统一致性的核心就是保证多个节点之间的操作日志一致性。\n\n当主节点出现故障，备节点会提议自己成为主节点。这里的问题在于：网络分区的时候，可能会有多个备节点提议（Proposer，提议者）自己成为主节点。\n\nPaxos协议执行步骤如下：\n<img src=\"/img/202102/057.png\" width=\"50%\" height=\"50%\">\n如果Proposer第一次发器的accept请求没有被accepter中的多数派批准，即与其他的proposer冲突。则完整执行一轮Paxos协议：\n<img src=\"/img/202102/058.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/059.png\" width=\"50%\" height=\"50%\">\n> 跟之前那篇paxos文章不同，上一篇通过Paxos保证了多个节点之间数据的一致性。而这里的Paxos协议则是通过在Proposer保证了多个节点之间记录的最后哪个成功修改结果并成为主节点信息一致。\n\n#### Paxos与2PC：\nPaxos协议有两种用法：\n1. 用它来实现全局的锁服务或者命名和配置服务，例如：Chubby、Zookeeper\n2. 用它来将用户数据复制到多个数据中心，例如：Megastore、Spanner\n\n2PC协议最大的缺陷在于无法处理协调者宕机问题，如果协调者宕机，那么2PC协议中的每个参与者都可能不知道事务应该提交还是回滚，整个协议备阻塞。\n\n常见的做法是将Paxos与2PC组合起来，通过2PC保证多个数据分片上的操作的原子性，通过Paxos协议实现同一个数据分片的多个副本之间的一致性。\n\n通过Paxos协议解决2PC协议中协调者宕机问题，当协调者宕机时，通过Paxos协议选举出新的协调者继续提供服务。\n> 这里也可以衍生为当主控节点与其备份节点全部宕机的时候该怎么办？答：通过选举从存储节点中选举出新的主控节点。\n\n### 跨机房部署：\n\n在分布式系统中跨机房是个大问题，机房之间网络延时比较大，且不稳定。\n\n问题主要包含两个方面：数据同步以及服务切换。\n\n跨机房部署方案有三个：集群整体切换、单个集群跨机房、Paxos选主副本\n\n#### 集群整体切换：\n<img src=\"/img/202102/060.png\" width=\"50%\" height=\"50%\">\n\n两个机房的主控节点与数据节点完全相同。并且其中机房1是主机房，机房2是备机房。机房之间的数据同步方式可能为强同步或者异步。如果采用异步模式，那么备机房的数据总是落后于主机房。\n\n当主机房整体出现故障时，有两种选择：\n1. 将服务切换到备机房，忍受数据丢失的风险\n2. 停止服务，直到主机房恢复服务\n\n如果数据同步是异步，那么主备机房切换往往是手工的，允许用户根据业务的特点选择“丢失数据”或者“停止服务”。\n\n如果采取强同步的方式，那么除了手动切换外还可以采取自动切换的方式，通过分布式锁服务检测主机房的服务，当主机房出现故障时，自动将备机房切换为主机房。\n\n#### 单个集群跨机房：\n<img src=\"/img/202102/061.png\" width=\"50%\" height=\"50%\">\n\n跟集群整体切换不同，单个集群跨机房将数据备份分布在两个机房中，总控节点也是跨机房分布，当主总控节点运行中时，他需要跟两个机房的存储节点保持通信。当总控节点出现故障时，由分布式锁服务切换总控节点。\n\n这种方式需要在数据备份的时候尽可能地将副本分布在多个不同的机房。\n\n> 总控节点与其他机房存储节点的通信不包含服务部分，即总控节点只需要维持其他机房存储节点的元数据即可。这样与主服务之间关系不大，可以专门开辟一个线程用于维持链接，不会阻塞服务。\n\n#### Paxos选主副本：\n前两种方法中，总控节点与工作节点之间需要保持租约以维持通信。\n<img src=\"/img/202102/062.png\" width=\"50%\" height=\"50%\">\n\n如果采用Paxos协议选主副本，那么每个数据分片的多个副本构成一个Paxos复制组。\n\n当B1出现故障时，其他副本将尝试切换为主副本，他的优点在于对总控节点的依赖低，缺点则是工程复杂度太高，很难线下模拟所有的异常情况。谷歌的Gegastore和Spanner都采用这种方式。\n> 这里如果出现整个机房故障的话应该和整体切换一样。那么这种方式和上述两种可以结合。将提供服务的基础单位由存储节点细化为数据块。","tags":["存储"]},{"title":"分布式存储笔记2-2 数据库相关","url":"/2021/02/22/分布式存储笔记2-2-数据库相关/","content":"<hr>\n这是一篇在阅读《大规模分布式存储系统：原理解析与架构实战》时的阅读笔记，由于长时间碎片阅读的关系导致在做这种读书笔记的时候接近复制粘贴。虽然其中会有一小部分自己的想法但都十分零碎，希望后续能改进。\n<hr>\n\nNoSQL=Not Only SQL\n\n关系数据库在海量数据场景面临以下挑战：\n* 事务：关系模型要求多个SQL操作满足ACID特性，但是在分布式系统中，如果要满足该特性，需要用到两段提交协议，这个协议性能很低，且不能容忍服务器故障。\n* 连表：传统数据库设计需要满足范式需求，第三范式规定两张关联的表中除了主键外不允许出现其他冗余字段，但是随着表数据增加，连表的开销也就随之增大。为了避免这个问题往往采用数据冗余的方法。\n* 性能：关系数据库采用B/B+树存储引擎，更新操作的性能不如LSM树这样的存储引擎（在更新了磁盘上数据的同时也要根据新的数据更新索引树,在大量数据的情况下对索引的更新开销会很大），对基于主键的增删改查操作性能不如定制的K-V存储系统\n\nNoSQL系统面临的问题：\n* 缺少统一标准：关系数据库有SQL语言这样的业界标准，并拥有完整的生态链，而NoSQL系统使用方法不同，切换成本高，很难通用。\n* 使用以及运维复杂：NoSQL的使用需要理解系统的实现，关系数据库有完整的运维工具与大量经验丰富的运维人员。\n\n着重理解关系数据库的原理与NoSQL的高可扩展性。\n\n##### 事务与并发控制：\n事务拥有ACID属性，最理想的状态就是每个事务互不干扰，按顺序执行，这被称为可串行化。但可串行化效率低下，商业数据库通常有多种不同的隔离级别。\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;事务的并发控制通过锁机制来实现，锁会有不同的粒度：行、数据块、表\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;互联网应用中读事务比例远高于写事务，因此使用写时复制或者多版本并发控制技术来避免写事务阻塞读事务。\n\n## 事务\n事务是数据库操作的基本单位，因为他们具有ACID（原子性、一致性、隔离性、持久化）特性。\n* 原子性：使得事务一定全部完成或者一定全部失败，不允许存在中间状态被感知到。一个事务对同一数据项的多次读取结果一定是相同的（如果存在中间状态被感知到，则在读取的时候会读取到中间状态，导致多次读取的结果不一致）\n* 一致性：保证数据符合设定规则，有2个方面来保证。一方面通过数据库内部规则确保数据类型正确，数据的值在给定范围内等；另一方面通过应用程序保证数据的值符合当前场景需求。\n* 隔离性：事务的执行不是一步就完成的，因此要确保事务在执行过程中对外不可见。在并发情况下，一个事务在修改途中插入一个查询事务，这个查询事务是感知不到修改事务的中间状态，对他来说数据形式是原始数据，而不是执行过程中修改了一部分的更新事务中的数据。\n* 持久性：事务完成/失败后，对数据库的影响是永久性的。（成功的数据修改与失败的错误日志记录）\n<img src=\"/img/202102/009.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/010.png\" width=\"50%\" height=\"50%\">\n四种隔离级别会产生不同的读写异常\n<img src=\"/img/202102/011.png\" width=\"50%\" height=\"50%\">\n\n## 并发控制\n### 数据库锁\n数据库的锁分为两类：读锁、写锁\n\n通常只允许对一个元素加一个写锁，可以对一个元素加多个读锁。\n\n写事务通常会阻塞读事务。\n\n多个事务并发执行可能会出现死锁，解决办法有两种：\n* 给每个事务设置超时时间\n* 设置死锁检测，死锁的原因在于事务之间资源的互相依赖，检测到死锁后可以通过回滚其中某个事务来消除死锁\n### 写时复制：\n在执行写操作时复制一份索引树，并在该索引树上操作。\n<img src=\"/img/202102/012.png\" width=\"50%\" height=\"50%\">\n在整棵索引树中只是复制需要修改的部分结点，不会复制整棵索引树。第三步完成的时候旧的索引树中与复制出来的索引树相关的结点指针都指向新的被修改后的部分索引树。\n\n**操作顺序：**\n1. 从索引树A中获取到写操作锁涉及的结点B\n2. 复制B得到C\n3. 对C进行修改操作\n4. 提交后，原子性地将A中原本指向B的指针指向C\n\n为了避免内存浪费，需要每个结点都维护一个引用计数器，当计数器为0的时候，该结点被垃圾回收。但是：**写时复制操作成本高，且多个写操作的结点如果相交，则是互斥的。**\n<img src=\"/img/202102/013.png\" width=\"50%\" height=\"50%\">\n\n### 多版本并发控制（MVCC）：\n是除了写时复制之外另一个实现读事务不加锁的方案。\n\n为每一行数据维护多个版本，无论事务的执行时间多长，都为事务提供事务一开始一致的数据，即当事务开始的时候受影响的这部分数据就独立为一个全新的版本，其他任何事务的执行都无法干扰到这条分支。\n\nInnoDB维护了两个隐藏的列：行被修改的时间、行被删除的时间。这里的时间不是绝对的时间，而是与时间相对应的数据库系统版本号。\n\n每次执行事务的时候都会得到一个递增的版本号，那么事务在执行的时候只需要对比数据原始版本号与自身得到的最新的版本号进行比较然后根据不同的隔离级别来判断是否返回。\n<img src=\"/img/202102/014.png\" width=\"50%\" height=\"50%\">\n<img src=\"/img/202102/015.png\" width=\"50%\" height=\"50%\">\n但是这样就需要多余的存储开销，且需要定期清除过早的版本号。\n\n### 故障恢复：\n当事务执行到一半的时候系统故障，此时系统重启后需要将事务恢复到最初状体或继续执行下去。（要么commit要么rollback）\n\n数据库系统与其他分布式存储系统一般采用操作日志（有时也被称为提交日志，commit log）技术来实现故障恢复。\n\n**操作日志分类：**\n* 回滚日志（UNDO Log）：记录事务修改前的状态\n* 重做日志（REDO Log）：记录事务修改后的状态\n* 回滚/重做日志（UNDO/REDO Log）\n\n#### 操作日志：\n为了保证数据库的一致性而采用操作日志，将对数据库的操作持久化到磁盘。如果每执行一次操作就写入磁盘，那么写入的数据是随机写入，每条数据之间都是随机指针；而如果将操作先存入操作日志中，当数量达到一定大小之后/定期统一写入磁盘，那么这次写入磁盘的数据都将是顺序写入。\n\n> 在操作日志中的写入都是追加写，包括删除操作\n\n<img src=\"/img/202102/016.png\" width=\"50%\" height=\"50%\">\n\n事务开始时，先在回滚日志中记录数据的原始状态。\n\n在事务结束后，在重做日志中记录数据的完成状态，并且在回滚/重做日志中记录这个事务操作。\n\n在事务提交后，执行的是REDO日志中的记录，如果是回滚，则执行UNDO日志中的操作，即事务执行完成后写入REDO中，此时尚未提交，也就尚未持久化进磁盘。\n\n针对存储模型可以做的简化：\n<img src=\"/img/202102/017.png\" width=\"50%\" height=\"50%\">\n\n通过查看mysql的操作日志，可以看到，用户做的所有操作都会被原样记录。\n<img src=\"/img/202102/018.png\" width=\"50%\" height=\"50%\">\n\n#### 重做日志：\n流程如下：\n<img src=\"/img/202102/019.png\" width=\"50%\" height=\"50%\">\n若要进行修复操作，只需要从头到尾读取一遍REDO日志并将其应用到内存中即可。\n\n如果先应用到内存再持久化入磁盘，那么当在内存中修改完成后其他程序就可以立刻读取到相关修改，而此时磁盘还未记录该操作，如果此时系统重启，那么数据恢复后的结果是修改前的数据，但是其他程序已经读取并使用了修改后的数据，这样就造成了数据的不一致性。\n\n#### 优化手段：\n##### 成组提交\n如果每次执行事务后都立刻写入磁盘会导致系统吞吐量下降，因此系统往往有一个“是否立刻刷入磁盘”的选项，对于一致性要求高的系统可以将其打开。\n\n对于上述情况可以将事务对REDO的记录缓存在内存中，当满足一定条件后统一写入日志中，并在内存中体现数据的更改。这样牺牲了事务的写延时但是能够提高系统的吞吐量。但是这种做法会导致当系统宕机时缓存中还没有写入的事务操作丢失。\n\n> 说是先保存在内存中，实际上为了防止数据丢失，在每一次写入的时候都要记录到操作日志当中，操作日志与数据块不同。同时为了减少数据丢失的危害，在写入条件部分会特别严格。\n\n当达成以下任何一项条件后写入磁盘：\n<img src=\"/img/202102/020.png\" width=\"50%\" height=\"50%\">\n\n> 可以看到写入的条件是十分严格的，精确到毫秒级，可以最大程度地方式数据丢失。\n\n##### 检查点\n如果所有的数据都保存在内存中会有两个问题：\n<img src=\"/img/202102/021.png\" width=\"50%\" height=\"50%\">\n类似于索引文件，将内存中的数据结构保存为一个索引文件，系统重启后直接从索引文件构建索引即可，不需要扫描所有数据。\n\n检查点流程如下：\n<img src=\"/img/202102/022.png\" width=\"50%\" height=\"50%\">\n\n这里应该是如下流程：\n<img src=\"/img/202102/023.png\" width=\"50%\" height=\"50%\">\ncheckpoint保存的是当前内存中数据的状态，可能会有一些修改操作，但由于REDO日志存储的是修改后的结果，就算再执行这些修改操作，数据依旧是以REDO中的为准，不会出现多次执行后结果变化的问题。\n\n加法操作、追加操作不具有冥等性，因此在checkpoint的时候不应该保存这些操作的状态，为此有两种方式：\n<img src=\"/img/202102/024.png\" width=\"50%\" height=\"50%\">\n要么停止服务（进行the world）要么在状态完美的瞬间创建一个快照，持久化的就是这个快照。","tags":["存储"]},{"title":"分布式存储笔记2.1 单机存储系统","url":"/2021/02/21/分布式存储笔记2-1-单机存储系统/","content":"<hr>\n这是一篇在阅读《大规模分布式存储系统：原理解析与架构实战》时的阅读笔记，由于长时间碎片阅读的关系导致在做这种读书笔记的时候接近复制粘贴。虽然其中会有一小部分自己的想法但都十分零碎，希望后续能改进。\n<hr>\n\n## 单机存储引擎与单机存储系统：\n单机存储引擎就是哈希表、B树等数据结构在机械磁盘、SSD等持久化介质上的实现。单机存储系统就是单机存储引擎的一种封装，对外提供文件、键值、表格或关系模型。\n\n数据库将一个或多个操作组成一组，称作事务，事务必须满足原子性、一致性、隔离性以及持久性，简称ACID特性。\n\n### 网络拓扑：\n传统网络拓扑分为三层结构：接入层、汇聚层、核心层\n<img src=\"/img/202102/002.png\" width=\"50%\" height=\"50%\">\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样的问题在于，同一接入层之间的服务器之间的带宽为1GB，不同接入层之间的服务器之间的带宽小于1GB，而同一接入层往往放在同一个机架中，因此设计系统的时候需要考虑到服务器是否在一个机架内，减少跨机架拷贝大量数据。\n\n> 不同核心层之间的服务器进行通信需要经过接入层、汇聚层、核心层，而核心层、汇聚层服务器在同时处理多台接入层的设备，使得网络带宽资源被占用。\n\nhadoop的三个存储副本中，有两个都处于同一个机架内。\n\n> 即两个副本付出同一接入层下，保证了两个副本之间带宽为1Gb\n\n新型的一种网络拓扑结构是谷歌推出的扁平化拓扑结构，即三级CLOS网络，同一个集群内最多支持20480台服务器，且任何两台之间都有1Gb带宽。但是这需要投入更多的交换机，不过好处就是设计系统时不需要考虑底层网络拓扑，从而很方便地将整个集群做成一个计算资源池。\n### 常用硬件参数：\n<img src=\"/img/202102/003.png\" width=\"50%\" height=\"50%\">\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;存储系统的性能瓶颈主要在于磁盘的随机读写，设计存储引擎的时候需要根据磁盘的特性做出相应的处理，比如将随机写操作转化为顺序写，通过缓存你减少磁盘随机读操作。\n\n### 存储介质对比：\n<img src=\"/img/202102/004.png\" width=\"50%\" height=\"50%\">\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于SSD价格高，但是在随机读写方面性能好的特定，可以将SSD作为缓存使用。\n\n### 存储层次架构：\n不同机架之间的服务器互相访问需要有额外的网络传输协议与网络协议栈的开销。\n> 传统网络拓扑结构如果要保证跨层间服务器网络带宽最大，需要为上层服务器开通更大的带宽\n\n存储系统的性能主要包括两个维度：\n* 吞吐量（系统的吞吐能力指系统在某一段时间可以处理的请求总数，常用美妙处理的读操作数QPS或者写操作数TPS来衡量）\n* 访问延时（指从某个请求发出到接收到返回结果消耗的时间，通常用平均延时或者99.9%以上请求的最大延时来衡量）\n\n设计系统时要求能够在保证访问延时的基础上，通过最低的成本尽可能实现高的吞吐量。优先保证访问延时，又有余力的情况下提高吞吐量\n> 优先保证访问延时，又有余力的情况下提高吞吐量\n\n磁盘与SSD的访问延时差别很大，但是带宽差别不大，因此磁盘适合大块顺序访问的存储系统，SSD适合 随机访问较多或者对延时比较敏感的关键系统。（SSD就算读取出了大块数据，最终还是要等网络带宽将其传输出去。\n\n二者也可以组合成混合存储：热数据（频繁访问）存储到SSD中，冷数据（访问不频繁）存储到磁盘中。\n> 就算IO性能再强，也要等待网络将数据发送出去，对外来说服务器理论最大的吞吐量就是服务器的满速带宽。\n\n### 单机存储引擎：\n存储系统的核心是存储引擎，它直接决定了存储系统的性能与功能。\n\n存储系统的基本功能：增删改读\n\n读操作又分为：随机读取、顺序扫描\n\n#### 哈希存储引擎 - 键值存储系统：\n是哈希表的持久化实现，支持增删改查，其中的查询操作属于随机读取，不支持顺序扫描。\n\nBitcask是基于哈希表结构的键值存储系统，用于日志存储。\n\n因此它只支持追加操作。\n> 日志对时间顺序要求很高不允许随机写入，而且作为记录不允许修改\n\n由于日志会长时间连续不断地写入，因此日志文件需要在到达一定大小之后分块，否则将无法读取。\n> 单个文件过大无法打开\n\n为了保证日志写入的时间顺序，在任意时刻，只有一个文件是可写的，老的文件只读不写。这个文件被称为活跃数据文件，其他已经达到大小限制的文件称为老数据文件。\n##### 数据结构：\n<img src=\"/img/202102/005.png\" width=\"50%\" height=\"50%\">\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bitcask数据文件中的数据是一条一条的写入操作。每条数据项分别为主键（Key）、value内容（value），主键长度（key_sz）、value长度（value_sz）、时间戳（timestamp）以及crc校验值。\n\n数据删除不会物理删除数据，而是通过将value设定为一个特殊的值用于标识的逻辑删除。\n\n> 将删除的开销整合到垃圾回收当中\n\n内存中采用基于哈希表的索引数据结构，哈希表的作用是通过主键快速地定位到value的位置。（如果只需要获取数据，从索引中得到的信息可以直接从文件中获取。如果要获取到这条记录的详细信息，如：时间戳、crc等，就需要从value位置读取再解析。这样在索引部分冗余了value长度等信息，可以加快对内容本身的获取速度）\n\n系统中的记录删除或者更新后，原来的记录成为了垃圾数据。Bitcask定期会执行垃圾回收的合并操作。将所有老数据扫描一遍生成新的数据文件，由于旧数据不允许更新，因此对同一个Key的更新操作也是会新追加一条记录，因此在垃圾回收的时候，对于同一个Key的多条数据，以最新的一条数据为准，对已经删除的数据则直接抛弃。\n\n为了保证系统宕机时对索引的快速恢复，系统的索引也需要一个持久化的索引文件并定时更新索引。\nBitcask在进行合并的时候会产生一个索引文件，这个索引文件跟内存中的索引完全一样。\n\n#### B树存储引擎 - 关系数据库：\n是B树的持久化实现，支持单条记录的增删改查操作，还支持顺序扫描。也能够实现键值存储系统。\n<img src=\"/img/202102/006.png\" width=\"50%\" height=\"50%\">\n\nInnoDB中常用的是B+树。\n\n##### 缓冲区管理：\n缓冲区管理是在内存中分配的一个额外空间，与页面同等大小。磁盘块的内容可以传送到缓冲区中。常用的缓冲区替换策略有两种：\n1. LRU：\n\tLRU算法淘汰最长时间没有读或者写过的块。这种方法要求缓冲区管理器按照页面最后一次被访问的时间组成一个链表，每次淘汰链表的尾页。但是有一个问题：加入某一个查询做了一次全表扫描，将导致缓冲池中的大量页面被替换（全局查询的结果将整个链表全部替换），从而污染缓冲池。\n2. LIRS：\n\t现代数据库一般采用LIRS算法，即将缓冲池分为两级，数据首先进入第一级，如果数据在短时间内被访问两次或者以上，则称为热点数据进入第二级。每一级都是由LRU组成。\n\n#### LSM树存储引擎 - 分布式表格系统：\n支持增删改查（包括随机读取与顺序扫描）通过批量转储技术规避磁盘随机写入问题。\n\n将对数据的修改增量保持在内存中，达到指定大小限制后将这些修改操作批量写入磁盘，读取时需要合并磁盘中的历史数据和内存中最新的修改操作。\n\n该算法的优势在于有效地规避了磁盘随机写入问题，但读取时可能需要访问较多的磁盘文件。\n> 如果服务器突然宕机可能会丢失部分在内存中的数据\n\n##### LevelDB存储引擎：\n<img src=\"/img/202102/007.png\" width=\"50%\" height=\"50%\">\n\n该引擎主要包括：\n* 内存中：MemTable、不可变MemTable\n* 磁盘上：当前（Current）文件、清单（Manifest）文件、操作日志（Commit Log，又叫提交日志）、SSTable文件\n\n当应用写入一条记录时，LevelDB首先将修改操作写入到操作日志文件中，成功后再将修改操作应用到MemTable，这时候就完成了写入操作。\n> 这样当服务器宕机的时候也可以从操作日志中恢复MemTable数据，不会使得数据丢失\n> 为什么写了日志缺不写入数据块呢？因为日志属于追加写操作，对磁盘的开销小。而对数据块的操作会有增删改查这4个操作，这些操作的开销比追加写要大很多\n\n当MemTable占用的内存达到一个上限值后，需要将内存的数据转储到对外文件中（即持久化到磁盘）这时会先将使用中的MemTable冻结，后续的操作由一个新创建的MemTable接收，LevelDB将不可变MemTable中的数据排序后转储到磁盘，形成一个新的SSTable文件，这个操作称为Compaction。\n> 感觉Compaction之后应该也要将这个操作写入操作日志当中，因为宕机恢复的话一部分数据是会从操作日志恢复的，如果不做记录会将已经持久化的数据也恢复到内存中。不过这样看来问题也不大。\n\nSSTable文件是内存中的数据不断进行Compaction后形成的，且SSTable的数据是一种层级结构，第0层是Level 0。\n\nSSTable的数据是按照主键大小顺序排列的，因此一个SSTable的范围可以由两端的最大、最小主键所确定。而清单文件就记录了这些信息，包括属于哪个层级、文件名称、最小主键、最大主键。\n\n随着SSTable的产生，清单文件也会越来越大，必然会进行拆分并且设置出哪个清单文件是当前生效的，因此当前文件（Current）就是用来指出当前是哪个清单文件在生效。\n\n因此一次查询将会查询多个文件，对此LevelDB做了一个优化：查询时首先查询MemTable，如果没有结果则往不可变MemTable查询，如果还没有则从新往旧查询SSTable。\n##### 合并操作：\nLevelDB的Compaction操作有两种，分别为minor和major。Minor compaction指的是将内存中的MemTable持久化到磁盘中的操作，major Compaction指的是将磁盘中多个SSTable合并的操作。当某个层级下的SStable文件数目超过一定设置值后，LevelDB会将这个层级的SSTable文件与高一级的SSTable文件合并。Major compaction按照主键顺序依次迭代出所有SSTable文件记录，如果没有价值，则将其抛弃。\n\n> 这样的话这部分操作应该跟bitcask的垃圾回收是一样的，LevelDB中对数据的更新操作也不会直接修改数据块中的数据，而是在后面追加一条。删除数据也是在数据块中做一个标记表示删除。这样在major Compaction的时候可以回收大量的磁盘空间。\n> 补充1:具体的需要根据源码确认，目前只是猜测，这里这篇文章应该会有所收获：[LevelDB的Compaction](https://zhuanlan.zhihu.com/p/46718964)\n> 补充2:看来上面的猜测是正确的，major compaction所作的工作除了减少SSTable的文件数量外，还做了跟Bitcask一样的垃圾回收操作。\n> 从上文可知：\n> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Major compaction的目的是：均衡各个level的数据，保证 read 的性能；合并delete数据，释放磁盘空间，因为leveldb是采用的延迟（标记）删除；合并update的数据，例如put同一个key，新put的会替换旧put的，虽然数据做了update，但是update类似于delete，是采用的延迟（标记）update，实际的update是在compact中完成，并实现空间的释放。\n> PS：跟我上面的猜想一样\n\n#### 数据模型：\n存储系统的数据模型包括三类：文件、关系、键值\n关系模型描述能力强，产业链完整。但是新的键值模型更能满足当前大型系统需要，但是没有同一的业界标准。\n\n##### 文件模型：\n\t以系统以及目录树的形式组织文件。POSIX是应用程序访问文件系统的API标准，主要包括：\n* Open/Close：打开/关闭一个文件，获取文件描述符\n* Read/Write：读取一个文件或者往文件中写入数据\n* Opendir/Closedir：打开或关闭一个目录\n* Readdir：遍历目录\n\nPOSIX还定义了读写操作语义。他要求读写并发时能够保证操作的原子性，即读操作要么读到所有结果，要么什么都读不到；\n\nPOSIX适合单机系统，在分布式文件系统中，出于性能考虑往往不会严格遵守，NFS文件系统允许客户端缓存文件数据，多个客户端并发修改同一个文件时可能出现不一致的情况。但是会出现A、B同时修改了文件C并先后提交的情况，这样会导致A的修改被B的修改所覆盖。\n\n对象模型与文件系统类似，但是弱化了目录树的概念，对象模型要求对象一次性写入到系统中，只能删除整个对象，不允许修改一部分。\n就是平时使用的文件系统\n\n##### 关系模型：\n平时数据库的表结构就是关系模型\n每个关系都是一个表格，由多个元组（行）构成，每个元组包含多个属性（列）。关系名、属性名以及属性类型称作该关系的模式（schema）。\n数据库语言SQL用于描述查询以及修改操作。SQL还有个强大的特性是允许在WHERE、FROM、HAVING子句中使用子查询。\nSQL还有两个重要特征：索引、事务。\n索引用于减少SQL执行时扫描的数据量，提高读取性能；事务规定了各个数据库操作的语义，保证了多个操作并发执行时的ACID特性（原子性、一致性、隔离性、持久性）\n\n##### 键值模型：\n大量的NoSQL系统采用了键值模型，有点类似于HashTable，也称为Key-Value模型。每行记录由主键和值两部分组成。\n所有操作都是基于主键，包括：\n* Put：保存一个Key-Value对\n* Get：读取一个Key-Value对\n* Delete：删除一个Key-Value对\nK-V模型过于简单，使用场景有限，NoSQL系统中比较广泛采用的模型是表格模型。\n\n##### 表格模型：\n表格模型弱化了关系模型中的多表关联，支持基于单表的简单操作，典型的有BigTable、HBase。表格模型除了支持简单的基于主键的操作，还支持范围扫描，另外也支持基于列的操作：\n* Insert：插入一行数据，每行包含若干列\n* Delete：删除一行数据\n* Update：更新整行或者其中的某些列的数据\n* Get：读取整行或者其中某些列的数据\n* Scan：扫描一段范围的数据，根据主键确定扫描的范围，支持扫描部分列、支持按列过滤、排序、分组等\n\n### 数据压缩：\n数据压缩分为有损压缩和无损压缩。\n早期的压缩技术以Huffman编码为主，通过统计字符出现的频率计算最优前缀编码。\n1977年后则以LZ77系列压缩算法为主，通过在一个窗口内部找重复并维护数据字典。\n压缩算法的核心是找重复数据，列式存储技术通过把相同列的数据组织在一起。传统的OLAP数据库，如：Sybase IQ、Teradata、Bigtable、HBase等分布式表格系统都实现了列式存储。\n\n#### 压缩算法：\n压缩需要根据数据的特点选择或开发合适的算法，本质是查找数据的重复或者规律，用尽量少的字节表示。\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;存储系统在选择压缩算法的时候需要考虑压缩比和效率。\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;读操作需要先读取磁盘中的内容呢再解压缩，写操作需要先压缩再将压缩结果写入磁盘中，整个操作的延时包括压缩/解压缩和磁盘的读写。\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;压缩比越大，磁盘读写的数据量越小，而压缩/解压缩的时间也会越长，这里是一个权衡点。\n> igTable使用BMADiff以及Zippy两种压缩算法，牺牲一定的压缩比换取算法执行速度的大幅提升。\n\nHuffman编码/LZ系列压缩算法：自己查资料\n\n#### 列式存储：\n传统的行式数据库将完整的数据行存储在数据页中。如果查询时需要用到大量的列，这种方式在磁盘IO上比较高效。一般来说，OLTP（联机事务处理）应用适合采用这种方式。\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果一个应用需要查询大量的数据但是只涉及一两列的情况，行式数据库的开销是十分大的。\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;此时如果采用列式存储就可以有效优化这部分开销，但于此同时，系统常常查询单条记录的情况下，由于列式存储需要从不同行中查询一个对象的不同属性，他查询的开销是比行式存储大。因此可以根据系统具体的业务更换存储方式。\n\t\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;而且，由于同一列的数据重复率很高，因此，列式数据库压缩时有很大的优势。\n> Google 的BigTable列式数据库对网页库压缩可以达到15倍以上的压缩率\n\n同时，可以针对列式存储做专门的索引优化，比如性别（只有两个值：男、女），可以对这列建立位图索引：\n<img src=\"/img/202102/008.png\" width=\"50%\" height=\"50%\">\n100101:分别从左到右的第1、4、6为1表示数据的第1、4、6行为男\n011010:与上面相反，表示2、3、5行为女\n","tags":["存储"]},{"title":"分布式存储笔记1 分布式存储概述","url":"/2021/02/18/分布式存储笔记1-分布式存储概述/","content":"<hr>\n这是一篇在阅读《大规模分布式存储系统：原理解析与架构实战》时的阅读笔记，由于长时间碎片阅读的关系导致在做这种读书笔记的时候接近复制粘贴。虽然其中会有一小部分自己的想法但都十分零碎，希望后续能改进。\n<hr>\n\n## 分布式存储的概念：\n分布式存储系统是大量普通PC服务器通过英特网互联，对外作为一个整体提供存储服务。\n\n### 分布式存储的几个特征：\n* 可扩展：分布式存储系统可以扩展到几百台甚至几千台的集群规模，而且，随着集群规模的增长，系统整体性能表现为线性增长\n* 低成本：分布式存储系统的自动容错、自动负载均衡机制使其可以构建在普通PC机之上。另外线性扩展能力也使得增加、减少机器非常方便、可以实现自动运维\n* 高性能：无论是针对整个集群还是单台服务器，都要求分布式存储系统具备高性能\n* 易用：分布式存储系统需要能够提供易用的对外借口，另外，也要求具备完善的监控、运维工具，并能够方便地与其他系统集成，例如，从hadoop云计算系统导入数据\n\n主要挑战：数据、状态信息的持久化，要求在自动迁移、自动容错、并发读写的过程中保证数据的一致性。\n\n主要领域：分布式系统、数据库\n\n### 主要需求：\n* 数据分布：如何将数据分布到多台服务器才能保证数据分布均匀？数据分布到多台服务器后如何实现扩服务器读写操作？（数据平衡算法？）\n* 一致性：如何将数据的多个副本复制到脱台服务器，即使在异常情况下，也能够保证不同副本之间的数据一致性？（用paxos等一致性算法）\n* 容错：如何检测到服务器故障？（心跳检测）如何自动将出现故障的服务器上的数据和服务器迁移到集群中的其他服务器？\n* 负载均衡：新增服务器和集群正常运行过程中如何实现自动负载均衡？数据迁移的过程中如何保证不影响已有服务？（主副服务器模式，数据迁移过程中切换到副服务器）\n* 事务与并发控制：如何实现分布式事务？如何实现多版本并发控制？\n* 易用性：如何设计对外借口使得系统容易使用？如何设计监控系统并将系统的内部状态以方便的形式暴露给运维人员？\n* 压缩/解压缩：如何根据数据的特点设计合理的压缩/解压缩算法？如何平衡压缩算法节省的存储空间和消耗的CPU计算机资源\n\n### 面临的数据需求：\n* 非结构化数据：包括所有格式的办公文档、文本、图片、图像、音频和视频信息等\n* 结构化数据：一般存储在关系数据库中呢，可以用二维关系表结构来表示。结构化数据的模式（Schema，包括属性、数据类型以及数据之间的联系）和内容是分开的，数据的模式需要预先定义。\n* 半结构化数据：介于非结构化数据和结构化数据之间，HTML文档就属于半结构化数据。它一般是自描述的，与结构化数据最大的区别在于，半结构化数据的模式结构和内容混在一起，没有明显的区分，也不需要预先定义数据的模式结构。\n\n### 分布式存储的分类：\n* 分布式文件系统\n* 分布式键值（Key-Value）系统\n* 分布式表格系统\n* 分布式数据库\n\n#### 分布式文件系统：\n主要用于存储非结构化数据，这些数据以对象的形式组织。对象之间没有关联，这样的数据一般称为Blob（Binary Large Object， 二进制大对象）数据。\n\n总体上，分布式文件系统存储三种类型的数据：Blod对象、定长块、大文件。而这三者在存储系统内部又被按照数据块（chunk）来组织。一个数据块可以包含多个Blod对象，也可以由多个定长块组成，同时大文件也能拆分为多个数据块。\n<img src=\"/img/202102/001.png\" width=\"50%\" height=\"50%\">\n> Blod对象、定长块、大文件是逻辑上的概念，在存储系统中会转化为物理上的概念数据块（chunk）进行存储。对Blod对象、定长块、大文件的操作最终都映射为对数据块的操作\n\n#### 分布式键值系统：\n分布式键值系统用于存储关系简单的半结构化数据，他只提供基本主键的CRUD功能。从数据结构的角度看，分布式键值系统与传统的哈希表比较类似，不同的是，分布式键值系统支持将数据分布到集群中的多个存储节点。（一个主键对应的数据会被拆分到多个存储节点）\n分布式键值系统是分布式表格系统的一种简化实现，一般作用与缓存。\n一致性哈希是分布式键值系统中常用的数据分布技术。\n\n#### 分布式表格系统：\n分布式表格系统用于存储关系较为复杂的半结构化数据，与分布式键值系统相比，分布式表格系统不仅仅支持简单的CRUD操作，还支持扫描某个主键范围。\n分布式表格系统以表格为单位组织数据，每个表格包括很多行，通过主键标示一行，支持根据主键的CRUD功能以及范围查找功能。\n分布式表格系统借鉴了很多关系数据库的激素，例如事务。\n与分布式数据库相比，分布式表格系统主要支持针对单张表的操作，不支持一些特别复杂的操作，比如多表关联，多表连接，嵌套子查询等。\n在分布式表格系统中，同一个表格的多个数据行也不要求包含相同类型的列，适合半结构化数据。\n分布式表格系统是一种很好的权很，这类系统可以做到超大规模，而且支持较多的功能，但实现比较复杂，有一定的使用门槛。\n\n#### 分布式数据库：\n分布式数据库一般是从单机关系数据库扩展而来，用于存储结构化数据。分布式数据库采用二维表格组织数据，提供SQL关系查询语言，支持多表关联，嵌套子查询等复杂操作，并提供数据库事务以及并发控制。\n","tags":["存储"]},{"title":"Mysql索引小结","url":"/2021/01/31/Mysql索引小结/","content":"索引是帮助Mysql高效获取数据的数据结构。索引可以和数据文件放一起，也可以单独成为一个索引文件。索引通常是B+树结构。\n\n索引的优势和劣势：\n优势：\n\t• 可以提高数据检索效率，降低IO成本。\n\t• 通过索引列对数据进行排序，降低排序成本，降低CPU消耗。\n\t\t○ 对索引列进行order by速度会快很多，因为索引保存的是数据的地址，而单独对索引与数据地址进行排序的开销比对数据进行排序的开销要少很多。\n\t\t○ 覆盖索引，不需要回表查询。索引列会保存在单独的索引树中，如果要查询的数据在索引树中就存在，则不需要根据数据地址再查询一遍数据。\n劣势：\n\t• 索引会占用磁盘空间\n\t• 索引会降低表更新效率，更新数据的同时还要更新索引。\n\n#### 索引的分类：\n##### 单列索引：\n\t• 普通索引：Mysql中的基本索引类型，没有限制，允许空值与重复\n\t• 唯一索引：允许为空，但不允许重复\n\t• 主键索引：不允许为空，不允许重复\n##### 组合索引：\n\t• 在表的多个字段上创建索引\n\t• 组合索引的使用遵循最左匹配原则\n\t• 一般情况下建议使用组合索引代替单列索引（主键索引除外）\n##### 全文索引：\n\t• 只能在CHAR、VARCHAR、TEXT等字段使用\n\t• 只在MyISAM、InnoDB（5.6以后）才能使用\n\t• 优先级最高，不会执行其他索引\n##### 空间索引：\n\t• 待补充\n\n#### 索引的存储结构：\n\t• 索引是在存储引擎中实现的，因此不同的存储引擎会使用不同的索引\n\t• MyISAM、InnoDB采用的是B+树索引\n\t\n> B树和B+树的主要区别在于子节点是否存储数据，B+树只在叶子阶段存储数据，且叶子结点都在同一层，并且节点之间通过指针关联\n\n#### 非聚集索引（MyISAM）：\n\t• B+树叶子结点存储的是数据行（数据文件）的指针，数据与索引不在一起。\n\t• 非聚集索引包含主键索引和辅助索引都会存储指针的值\n<img src=\"/img/202101/002.png\" width=\"50%\" height=\"50%\">\n通过主键索引查询到叶子结点后，叶子结点中存储的数据是指向数据行的指针，因此会查询两次。索引文件存储在.mdi中，数据文件存储在.ibd中。\n在MyISAN中，主键索引和辅助索引的区别只在于主键索引是唯一的，结构都是一样。\n\n#### 聚集索引（InnoDB）：\n\t• 主键索引的叶子结点会存储数据行，即数据和索引是在一起的\n\t• 辅助索引只会存储主键值。如果要用辅助索引查询，则先根据辅助索引获取到主键索引，然后再根据主键索引获取到数据行。\n\t• 如果没有主键，则使用唯一索引建立主键。如果没有唯一索引，则会按照一定规则自动创建主键，类型为长整型。\n<img src=\"/img/202101/001.png\" width=\"50%\" height=\"50%\">\n辅助索引保存的是主键的值，即引用主键。因此通过辅助索引查询到主键索引之后还要再根据主键索引查询行数据。这种行为叫做回表查询。\n\n因为辅助索引树保存的数据是索引的列的数据（这部分数据是值，而不是地址），所以如果只是需要查询索引相关的列，则这部分行数据已经存在于辅助索引树中，就不需要回表查询。\n\n例如：table1中id是主键、name是辅助索引、age是一般字段。则他的辅助索引树中保存着id和name的信息。\n当：\n> Select * from table1 where name = 'Bob'    需要回表查询，因为*表示所有数据，但是辅助索引树中只有id和name\n\n\n> Select id,name from table1 where name = 'Bob'    此时不需要回表查询，因为id和name的数据都在辅助索引树中就已经存在。\n\n\nQ:为什么不建议用过长的字段作为主键?\n\nA:因为辅助索引引用的都是主键索引，过长的主键会使得辅助索引树过大。\n\nQ:哪些情况下需要创建索引？\n\t1. 主键自动建立唯一索引\n\t2. 频繁作为查询条件的字段应该创建索引\n\t3. 多表关联查询中，关联字段需要创建索引 on 的两边都是。\n\t4. 查询中排序的字段需要创建索引\n\t5. 频繁查找的字段，创建覆盖索引\n\t6. 查询中统计或者分组的字段应该创建索引 group by\n\nQ:哪些情况下不需要创建索引？\n\t1. 表记录太少\n\t2. 经常进行增删改操作的表\n\t3. 频繁更新的字段\n\t4. where 条件中使用频率不高的字段\n\n\n#### 组合索引\nmysql创建组合索引的规则是首先会对组合索引的最左边第一个字段进行排序，并在此基础在再为第二个索引字段进行排序，类似于order by col1,col2这样的规则。\n组合索引相当于将多个列建立成一个辅助索引树，因此比多列创建单列索引更加节省空间。\n两者的区别：\n\t• 多列建立一棵索引树更加节省空间\n\t• 多列分别建立索引更容易实现覆盖索引\n\n组合索引使用时遵循最左前缀原则：\n\t• like语句在使用时使用前缀匹配的场合下会使用索引 like 'a%'\n\t• 当where语句遇到>、<、like、between时中断索引，即当语句where a = 1 and b = 2 and c > 3 and d = 4时，索引在c > 3处结束，不会调用d的索引。此时需要将创建组合索引时的顺序改变即可：将(a,b,c,d)修改为(a,b,d,c)，这样在调用语句的时候会自动将d = 4放到c > 3之前。\n\n#### 索引失败：\nmysql提供了explain命令对select语句进行分析，并输出直接结果。\n\nexplain执行返回的字段说明：\n\t• id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符.\n\t• select_type: SELECT 查询的类型.\n\t• table: 查询的是哪个表\n\t• partitions: 匹配的分区\n\t• type: join 类型\n\t• possible_keys: 此次查询中可能选用的索引\n\t• key: 此次查询中确切使用到的索引.\n\t• ref: 哪个字段或常数与 key 一起被使用\n\t• rows: 显示此查询一共扫描了多少行. 这个是一个估计值.\n\t• filtered: 表示此查询条件所过滤的数据的百分比\n\t• extra: 额外的信息\n\n索引失败的几种情况：\n\t• 使用like的时候用后缀匹配，即 like '%a'，此时索引失效\n\t• or的前后没有同时使用索引，这里的索引只能是单列索引，如果or前后属于组合所以，则一样无法生效\n\t• 使用组合索引时没有使用第一列索引，导致索引失效。即组合索引是有顺序要求，他会在where条件中根据组合索引创建时的顺序重新排列查询条件，如果不存在第一列索引，则索引失效。\n\t• 数据类型出现隐式转换，如varchar不加单引号会自动转换为int型，使索引失效。\n\t• 在索引字段上使用了not，!=，<>。!=操作不会使用索引，它只会产生全盘扫描。优化方法：将其拆分为 key > 0 or key < 0\n\t• 对索引字段执行计算操作\n\t• 当全盘扫描比使用索引快时mysql会自动使用全盘扫描，此时索引失效。\n\n> 使用is null，is not null时，依旧会调用索引，mysql在选择是否使用索引时的一个依据就是全盘扫描和使用索引时的开销对比。\n\n","tags":["mysql"]},{"title":"游戏世界中的数学工具","url":"/2020/12/06/游戏世界中的数学工具/","content":"游戏是在计算机上实时模拟虚拟世界的数学模型。\n\n虽然在游戏中会用到几乎所有的数学分支，但最常用的只有两种：三维矢量与矩阵。\n\n## 点和矢量\n物体在三维世界中的三个要素：\n1. 位置（position）\n2. 定向（orientation）\n3. 比例（scale）\n\n通过连续地修改这三个属性来实现动画效果，将物体变换（transform）至屏幕空间使得物体渲染到屏幕上。在游戏中三维物体几乎都是以三角形组成，三角形的三个顶点（vertex）用点（point）来表示。\n\n### 坐标系\n常用的坐标系有三种：\n1. 笛卡尔坐标：由x、y、z三根轴组成\n2. 圆柱坐标：垂直高度h，从垂直轴发射的辐射轴r，偏航角（yaw）角度θ组成\n3. 球坐标：俯视角（pitch）、偏航角（yaw）、半径长度组成\n\n<img src=\"/img/202012/001.png\" width=\"50%\" height=\"50%\">\n\n> 坐标系选用的例子：\n> Q:若要让物体向漩涡一样绕着主角旋转时用什么坐标系？\n> A:圆柱坐标。要绘制漩涡动画，只需要简单地在θ上加上恒定角速率，在辐射轴r上加入少许向内的恒定线性速率，在h上加上向上的恒定线性速率，物体就会慢慢地旋转向上到角色中\n\n### 矢量\n矢量由三个标量（x、y、z）组成，即若要在三维空间中表示一个点，至少需要3个参数。\n> 矢量**v** = [x, y, z]\n\n#### 笛卡尔基矢量\n笛卡尔积单位矢量：在笛卡尔坐标系中，沿着三根轴并且模为1的矢量成为笛卡尔积单位矢量，分别表现为:\n1. **i** = [1, 0, 0]\n2. **j** = [0, 1, 0]\n3. **k** = [0, 0, 1]\n\n在笛卡尔坐标系中的任意点或矢量都能用3个标量与三个基矢量乘积之和表示标量。例如[5 3 -2] = 5**i** + 3**j** - 2**k**。\n\n#### 矢量运算\n\n##### 矢量与标量乘法 - 矢量的缩放\n矢量**a**与标量s相乘，等于**a**中的每个分量和s相乘:\n<img src=\"/img/202012/002.png\" width=\"50%\" height=\"50%\">\n矢量与标量相乘表示矢量方向不变，缩放矢量的模，乘以-1表示将矢量方向反转（头尾互换）。其中，s被称为**缩放因子**(scale factor)，其中，矢量的每个轴的缩放因子也会不同，因此将矢量缩放时每个轴的缩放因子是否相同，将其分为：统一缩放和非统一缩放。非统一缩放可以表示为矢量与缩放矢量的分量积,设矢量**a**、缩放矢量**s**,则a的分量积公式如下：\n<img src=\"/img/202012/003.png\" width=\"50%\" height=\"50%\">\n\n* 统一缩放：表现为标量s乘以矢量**a**。\n* 非统一缩放：表现为两个矢量的分量积，分量积不等于两个矢量相乘。这种运算方式又被称为阿达马积。\n\n##### 矢量的加法与减法\n矢量的相加等于将两个矢量首尾相连后剩下首尾相连所形成的新的矢量。\n<img src=\"/img/202012/004.png\" width=\"50%\" height=\"50%\">\n\n矢量的相减等同于矢量加上另一个矢量的反方向矢量。\n<img src=\"/img/202012/005.png\" width=\"50%\" height=\"50%\">\n\n二者表现如下：\n<img src=\"/img/202012/006.png\" width=\"50%\" height=\"50%\">\n\n矢量与点的加减运算如下：\n* 方向 + 方向 = 方向\n* 方向 - 方向 = 方向\n* 点 + 方向 = 点\n* 点 - 点 = 方向\n* 点 + 点 = **无意义**\n\n##### 模\n矢量的模等于矢量的各个标量的平方和开根号。\n<img src=\"/img/202012/007.png\" width=\"50%\" height=\"50%\">\n类似于勾股定理，在二维空间中，z轴为0，则可以更加直观的看到矢量模的计算：\n<img src=\"/img/202012/008.png\" width=\"50%\" height=\"50%\">\n\n> 我们在进行模的比较的时候通常可以用模的平方来比较，这样可以减少开销\n\n##### 矢量运算的实际应用\n设某人工智能的角色所在位置为P1，其速度为**v**，则可以找到他的下一帧位置P2，方法是把**v**以△t缩放，再加上P1。等式为P2 = P1 + **v**△t。这称为**显式欧拉法**。其中速度**v**恒定才有效。\n<img src=\"/img/202012/009.png\" width=\"50%\" height=\"50%\">\n\n##### 归一化与单位矢量\n单位矢量：模为1的矢量\n\n给定一个矢量**v**，其模为v=|**v**|,将其转化为方向相同的单位矢量**u**的过程如下：\n<img src=\"/img/202012/010.png\" width=\"50%\" height=\"50%\">\n这个过程称之为**归一化**\n\n##### 法矢量\n在三维世界中，一个平面可以由平面上的一点P以及一个垂直于该平面的矢量组成。这个矢量又被称为**法矢量**。\n> 法矢量不等于单位矢量，他的模不一定为1\n\n##### 点积和投影\n矢量之间可以相乘，这种相乘跟上面所描述的*分量积*完全不同。通常最常用的乘法有两种：\n* 点积：又被称为标量积或内积\n* 叉积：又被称为矢量积或外积\n\n两个矢量的点积的结果是一个标量，这个标量等于两个矢量的各个标量相乘的和：\n<img src=\"/img/202012/011.png\" width=\"50%\" height=\"50%\">\n\n点积也可以写成两个矢量的模相乘后再乘以两个矢量之间夹角的余弦：\n<img src=\"/img/202012/012.png\" width=\"50%\" height=\"50%\">\n\n点积符合交换律，且在加法上符合分配律。\n\n若**u**是单位矢量，则矢量**a**与矢量**u**的点积等于在**u**所在的直线上矢量**a**的投影。\n<img src=\"/img/202012/013.png\" width=\"50%\" height=\"50%\">\n\n若矢量与自身相乘，由于矢量的夹角θ为0°，所谓cosθ=1，得矢量与自身的点积为矢量模的平方\n<img src=\"/img/202012/014.png\" width=\"50%\" height=\"50%\">\n\n点积通常用于判断两个矢量是否共线或垂直，也可用来判断两个矢量是否大致在相同或相反方向：\n* 共线：**a**·**b**=|**a**||**b**|=ab。夹角θ为0，cosθ=1\n* 共线但是方向相反：**a**·**b**=-ab。夹角θ为180，cosθ=-1\n* 垂直：**a**·**b**=0，cosθ=0\n* 相同方向：**a**·**b** > 0(即cosθ > 0,夹角小于90°)\n* 相反方向：**a**·**b** < 0(即cosθ < 0,夹角大于90°)\n\n<img src=\"/img/202012/015.png\" width=\"50%\" height=\"50%\">\n\n##### 叉积\n两个矢量的叉积会产生一个新的矢量，新的矢量垂直于相乘的两个矢量所组成的平面，因此，叉积只存在与三维空间。\n<img src=\"/img/202012/016.png\" width=\"50%\" height=\"50%\">\n\n叉积的模等于两个相乘矢量的模乘以两个矢量夹角的正弦。所以当两个矢量共线时，他们的叉积为0。\n<img src=\"/img/202012/017.png\" width=\"50%\" height=\"50%\">\n\n若两条矢量分别是平行四边形的两条边，则两个矢量的叉积等于这个平行四边形的面积。\n<img src=\"/img/202012/018.png\" width=\"50%\" height=\"50%\">\n\n叉积的方向根据所选择的坐标系法则有关，左右法则和右手法则会得到不同方向的叉积。\n\n叉积不符合交换律，叉积的先后顺序影响最终结果。但是符合反交换律。\n<img src=\"/img/202012/019.png\" width=\"50%\" height=\"50%\">\n\n在加法上符合分配律\n<img src=\"/img/202012/020.png\" width=\"50%\" height=\"50%\">\n\n根据叉积的性质，可以得到笛卡尔积之间互相转换的公式：\n<img src=\"/img/202012/021.png\" width=\"50%\" height=\"50%\">\n\n#### 点和矢量的线性插值\n在游戏中，为了保证两个点之间移动时的顺滑，需要得到点到点之间的的中间点。为了得到这个中间点的计算称为**线性插值**，通常简写成LERP。其定义如下，设从点**A**到点**B**，其中的中间点**L**与**A**的距离是**A**到**B**的距离的β（0 ≤ β ≤ 1）。则：\n<img src=\"/img/202012/022.png\" width=\"50%\" height=\"50%\">\n从几何上看效果如下：\n<img src=\"/img/202012/023.png\" width=\"50%\" height=\"50%\">\n\n## 矩阵\n矩阵（matrix）由mxn个标量组成的长方形数组，在游戏世界中方便用于表示旋转（transformaction）、平移（translation）、缩放（scale）。\n\n3x3的矩阵表示纯旋转；4x4的矩阵表示旋转、平移、缩放。\n\n### 矩阵乘法\n当两个矩阵的内维相等的时候才能相乘，设**A**为m × p的矩阵，**B**为p × n的矩阵，那么称m × n的矩阵**C**为矩阵**A**与**B**的乘积，记作**C**=**A**·**B**。\n新的矩阵的各个标量计算如下：\n<img src=\"/img/202012/024.png\" width=\"50%\" height=\"50%\">\n\n矩阵的乘法先后顺序影响最终结果，不符合乘法交换律。矩阵的乘法有时又被称为**串接**。因为矩阵表示一次变换，矩阵的相乘表示将多个变换串接起来。\n\n### 矩阵表示点和矢量\n点和矢量都可以表示为行矩阵（1 × n）或列矩阵（n × 1）。其中n表示使用中的空间纬度，通常是2或3.例如矢量**v**=(3 4 -1)可以写成\n<img src=\"/img/202012/025.png\" width=\"50%\" height=\"50%\">\n或\n<img src=\"/img/202012/026.png\" width=\"50%\" height=\"50%\">\n\n两种矩阵方式的选择会影响矩阵相乘的次序。因为矩阵相乘的时候，两个矩阵的内维需要相等。所以：\n* 要把1 × n行矢量乘以n × n矩阵，矢量必须置于矩阵的左方<img src=\"/img/202012/027.png\" width=\"50%\" height=\"50%\">\n* 要把n × n矩阵乘以n × 1列矩阵，矢量必须位于矩阵的右方<img src=\"/img/202012/028.png\" width=\"50%\" height=\"50%\">\n\n### 单位矩阵\n单位矩阵与其他任何矩阵**M**相乘都等于**M**本身。其表现为对角线元素都是1，其他元素都是0。通常写作**I**。\n<img src=\"/img/202012/029.png\" width=\"50%\" height=\"50%\">\n\n### 逆矩阵\n设一个矩阵为**A**，则它的逆矩阵表示为**A⁻¹**,逆矩阵能还原矩阵的变换。所以矩阵与其逆矩阵相乘结果是单位矩阵。通常用高斯消去法或LU分解求得。矩阵串街后求逆等于反向串接各个矩阵的逆矩阵。\n<img src=\"/img/202012/030.png\" width=\"50%\" height=\"50%\">\n\n### 转置矩阵\n矩阵**M**的转置写作**Mᵀ**,转置矩阵就是以原来矩阵的对称轴做反射。和逆矩阵一样，矩阵串接后的转置矩阵等于反向串街各个矩阵的转置矩阵。\n<img src=\"/img/202012/031.png\" width=\"50%\" height=\"50%\">\n\n转置矩阵有一个重要的特点：\n> 纯旋转的矩阵他的逆矩阵与转置矩阵是相同的\n\n因此基于此，通常用转置矩阵代替逆矩阵，因为求转置矩阵的速度比求逆矩阵快。\n\n### 齐次坐标\n当点或矢量从三维(3 × 3)延伸至四维(4 × 4)的过程称为**齐次坐标**。因为4 × 4矩阵能够同时表示旋转、平移、缩放，因此在游戏中最常用的就是4 × 4矩阵。\n\n三维空间中，若一个矢量**r**绕z轴旋转ø°，则可以表示为：\n<img src=\"/img/202012/032.png\" width=\"50%\" height=\"50%\">\n但是3 × 3矩阵无法表示平移与缩放，而4 × 4可以\n<img src=\"/img/202012/033.png\" width=\"50%\" height=\"50%\">\n\n### 变换方向矢量\n矩阵同时携带旋转、平移、缩放这三个变换信息，当矩阵作用在点上时，三者都可以产生作用。但是当用矩阵变换一个方向矢量时要忽略**平移**效果。因为方向矢量并不会产生平移，而且一旦平移就会改变他的模，这不是我们想要看到的。\n\n在方向矢量与矩阵相乘是，把矢量的齐次坐标中的ω设置成0即可。\n<img src=\"/img/202012/034.png\" width=\"50%\" height=\"50%\">\n\n在将四维的齐次坐标转化为三维的非齐次坐标的时候通常是将x、y、z分别除以ω，因此当ω为0的时候会产生无穷大，因为在三维空间中的纯方向矢量在四维空间中表示一个无限远的点。\n<img src=\"/img/202012/035.png\" width=\"50%\" height=\"50%\">\n\n### 基础变换矩阵\n从上可以知道4 × 4矩阵可以表示旋转、平移与缩放。他们的分布如下：\n<img src=\"/img/202012/036.png\" width=\"50%\" height=\"50%\">\n\n* 左上角的3 × 3矩阵**U**代表旋转或缩放\n* 1 × 3平移矢量**t**\n* 3 × 1矢量**O** = [0 0 0]ᵀ\n* 右下角标量1\n\n从中可以看到，最右边一列的标量都是常量，并不会随着矩阵的功能而改变，因此为了节省空间，在计算机中可以用4 × 3矩阵代替。\n\n### 坐标空间\n确定物体的具体坐标之前需要确定参照物用于构建坐标系，在三维游戏世界，根据参照物的不同将其分为三个坐标空间：世界空间、模型空间、观察空间。三者的区别如下：\n* 世界空间：以游戏世界中的某点为原点，游戏世界中所有物体都可以通过世界空间表示，这个坐标将所有物体联系起来组成虚拟世界。是一个固定坐标。\n* 模型空间：基于游戏中对象的坐标空间，由游戏中对象的某点为原点与其自身质点所构成的坐标系，通常是笛卡尔坐标系。\n* 观察空间：又称摄像机空间，是固定在摄像机的坐标系，他的原点置于摄像机的焦点。\n\n### 基的变更\n上面描述的三者空间可以互相转化，即模型空间与观察空间可以转化为世界空间。这样当玩家角色与物体接触的时候通过基于同一个坐标系的数据进行判断是否产生碰撞。三个坐标构成层次关系，其中世界坐标是最底层的父坐标。\n\n把点或者矢量从坐标系**C**转移到坐标系**P**写作**M**ᴄ→ᴘ,设点在坐标系C中的点坐标为**P**ᴄ,在坐标系**P**中的坐标是**P**ᴘ。则他们的转化公式如下：\n<img src=\"/img/202012/037.png\" width=\"50%\" height=\"50%\">\n其中：\n* **i**ᴄ为子空间x轴的单位基矢量，这个矢量用父空间坐标表示\n* **j**ᴄ为子空间y轴的单位基矢量，这个矢量用父空间坐标表示\n* **k**ᴄ为子空间z轴的单位基矢量，这个矢量用父空间坐标表示\n* **t**ᴄ为子坐标系相对于父坐标系的平移\n\n例子如下：\n假设子空间绕z轴旋转角度ᵞ，没有平移，得到公式如下：\n<img src=\"/img/202012/038.png\" width=\"50%\" height=\"50%\">\n旋转示例如下：\n<img src=\"/img/202012/039.png\" width=\"50%\" height=\"50%\">\n\n在坐标空间的变换过程中有两种选择：变换坐标系或者变换矢量：\n<img src=\"/img/202012/040.png\" width=\"50%\" height=\"50%\">\n具体选择哪一种要看情况而定。\n\n## 四元数\n3 × 3矩阵并不是最理想的旋转表达形式，原因如下：\n1. 3 × 3矩阵有9个浮点数来旋转矢量，但实际上旋转只有三个自由度（偏航角、俯仰角、滚动角）\n2. 用矢量矩阵乘法来旋转矢量需要3个点积运算。\n3. 在计算机图形学中，表示两个矢量位置的变换通常需要顺滑的过度，因此需要计算两个位置中间的值，这用矩阵计算很麻烦。即不能完全实现游戏对象的变换。\n\n因此采用四元数来表示旋转，定义如下：\n> 单位长度的四元数能代表三维旋转\n\n即四元数中四个标量的平方和等于1的情况下都能表示三维旋转。\n\n### 单位四元数视为三维旋转\n四元数中有四个标量。\n<img src=\"/img/202012/042.png\" width=\"50%\" height=\"50%\">\n前三个标量组成的矢量**v**是旋转的单位轴乘以旋转半角的正弦。第四个标量qs是旋转半角的余弦。可以写成:\n<img src=\"/img/202012/041.png\" width=\"50%\" height=\"50%\">\n其中**a**为旋转轴方向的单位矢量，θ是旋转角度。旋转的方向遵守右手守则。从上面可以得到以下等式：\n<img src=\"/img/202012/043.png\" width=\"50%\" height=\"50%\">\n\n### 四元数运算\n\n#### 乘法\n乘法是四元数最常用的计算方法之一，给定两个四元数q和p，他们分别代表旋转**Q**和**P**，则qp代表两个旋转的合成旋转，即先旋转**Q**再旋转**P**。这种跟旋转相关的四元数乘法又叫做格拉斯曼积，定义的pq乘积如下：\n<img src=\"/img/202012/044.png\" width=\"50%\" height=\"50%\">\n结果分成矢量部分和标量部分，其中矢量部分的结果为四元数的x、y、z，标量部分是四元数的w。\n\n#### 共轭以及逆四元数\n四元素q的逆四元数写作q⁻¹,逆四元数和原四元数的乘积等于1.即qq⁻¹=（0**i** + 0**j** + 0**k** + 1）= 1.所以四元数[0 0 0 1]代表零旋转。\n\n四元数q的共轭写作qº（这里的º应该是*，我打不出来。）定义如下：\n<img src=\"/img/202012/045.png\" width=\"50%\" height=\"50%\">\n从公式中可以知道共轭是四元数矢量部分求反，但保持标量部分不变，有了这个定义，逆四元数又可以写成：\n<img src=\"/img/202012/046.png\" width=\"50%\" height=\"50%\">\n由于我们用于旋转的四元数都是单位长度，因此分母为1，化简如下：\n<img src=\"/img/202012/047.png\" width=\"50%\" height=\"50%\">\n所以四元数的逆四元数等于四元数的共轭，但是求共轭的速度快于求逆。因此通常可以用共轭代替求逆的步骤。同时这也比计算3 × 3的逆矩阵快，所以这一步可以用作性能的优化。\n\n多个四元数之积的逆四元数等于相反的逆四元数相乘，共轭同理。\n<img src=\"/img/202012/048.png\" width=\"50%\" height=\"50%\">\n\n### 用四元数旋转矢量\n用四元数旋转矢量，首先要把矢量转化为四元数形式。由于四元数比矢量多了一个标量，只要将第四个标量设置为0即可。给定矢量**v**,他的四元数形式表示为**v**ᶥ=[**v** 0]=[x y z 0]。\n\n要用四元数q旋转矢量**v**，需要先用q乘以**v**然后再乘以q的逆四元数。\n<img src=\"/img/202012/049.png\" width=\"50%\" height=\"50%\">\n因为旋转的四元数都是单位四元数，所以可以用四元数的共轭代替逆四元数：\n<img src=\"/img/202012/050.png\" width=\"50%\" height=\"50%\">\n\n> 在游戏中，各个模型空间相对于世界空间就可以用四元数表示，当要将模型空间内的坐标转化为世界空间的坐标时，只需要将其乘以模型空间定量的四元数即可\n\n#### 四元数的串接\n从上面的四元数用于矢量可以知道，四元数的串接类似于一层一层包裹矢量：\n<img src=\"/img/202012/051.png\" width=\"50%\" height=\"50%\">\n\n### 等价的四元数和矩阵\n任何三维旋转都可以从3 × 3矩阵表达方式和四元数表达方式之间自由变换。设q=[q**v** qs] = [x y z w]，则转化为矩阵表达**R**如下：\n<img src=\"/img/202012/052.png\" width=\"50%\" height=\"50%\">\n类似的，**R**也可以通过特定的计算得到四元数。下面是一段C/C++代码用于将矩阵转化为四元数:\n\n```C++\n#include \"math.h\"\n#include \"iostream\"\n\nvoid rotMatrixToQuternion(const float R[3][3], float q[4])\n{\n    float trace = R[0][0] + R[1][1] + R[2][2];\n    \n    //检测主轴\n    if (trace > 0.0f) {\n        float s = sqrt(trace + 1.0f);\n        q[3] = s * 0.5f;\n\n        float t = 0.5f / s;\n        q[0] = (R[2][1] - R[1][2]) * t;\n        q[1] = (R[0][2] - R[2][0]) * t;\n        q[2] = (R[1][0] - R[0][1]) * t;\n    } else {\n        //主轴为负\n        int i = 0;\n        if (R[1][1] > R[0][0]) i = 1;\n        if (R[2][2] > R[i][i]) i = 2;\n\n        static const int next[3] = {1, 2, 0};\n        int j = next[i];\n        int k = next[j];\n\n        float s = sqrt((R[i][i] - (R[j][j] + R[k][k])) + 1.0f);\n        q[i] = s * 0.5f;\n\n        float t;\n        if (s != 0.0f)  t = 0.5f / s;\n        else            t = s;\n\n        q[3] = (R[k][j] - R[j][k]) * t;\n        q[j] = (R[j][i] + R[i][j]) * t;\n        q[k] = (R[k][i] + R[i][k]) * t;\n    }\n}\n```\n\n### 旋转性的线性插值\n在两个旋转中间，为了保证物体变换表现的顺滑，需要获取到物体在变换时处于两个旋转中间的位置，这个点就叫做插值。\n\n虽然两个旋转矩阵之间也可以做插值，但是他们的计算开销远远大于四元数。\n\n最简单快捷的插值方法就是套用四维矢量的线性插值（LERP）至四元数。给定两个代表旋转A、B的四元数qᴀ、qʙ，可以找出旋转A到旋转B之间β百分点的中间旋转qʟᴇʀᴘ:\n<img src=\"/img/202012/053.png\" width=\"50%\" height=\"50%\">\n> 插值后的四元数需要再次归一，因为插值计算无法保证矢量长度。\n\n在图像中体现如下：\n<img src=\"/img/202012/054.png\" width=\"50%\" height=\"50%\">\n\n#### 球体中的插值\nLERP计算的缺点在于没有考虑四元数其实是四维**超球**上的点。LERP其实是沿着球体的弦进行插值，这样会导致：当β以恒定速率改变时，旋转动画并不是以恒定速率变换的，旋转会在两端慢，在中间骤然加快。为了解决这个问题产生了一个新的插值：**球面线性插值**（SLERP）。SLERP使用正弦和余弦在四维超球面的大圆上进行插值，而不是沿着弦上插值，这样，当β以恒定速率改变时，插值结果会以常速角速度变化。两者的区别如下：\n<img src=\"/img/202012/055.png\" width=\"50%\" height=\"50%\">\n\nSLERP公式如下：\n<img src=\"/img/202012/056.png\" width=\"50%\" height=\"50%\">\n其中wᴘ和wǫ取代（1-β）和β，这两个参数使用到了两个四元数之间的正弦与余弦夹角。\n<img src=\"/img/202012/057.png\" width=\"50%\" height=\"50%\">\n\n虽然SLERP比LERP更加完善，但同时计算插值的开销也更大，具体使用那种插值计算需要根据实际情况来看，在游戏中，优化也占很重要的一部分。\n\n## 各种旋转\n### 欧拉角\n欧拉角能表示旋转，由三个标量组成（偏航角、俯视角、滚动角）。\n\n优点：\n* 小巧，只由3个浮点数组成\n* 直观，容易把三个数值视觉化\n* 对围绕单轴的旋转容易插值\n\n缺点：\n* 对任意方向的旋转不方便插值\n* 会遭遇万向节死锁\n* 旋转次序影响最终结果\n* 依赖数据多，需要有x/y/z轴和前/左右/上方向上的映射\n\n### 3 x 3矩阵\n优点：\n* 不受万向节锁的影响，独一无二地表达任意旋转\n* 旋转可以通过矩阵乘法直接施加在矢量或点上\n* 市面上大多数CPU或GPU都针对矩阵乘法做了内建支持\n* 纯旋转的逆矩阵为转置矩阵，求解方便\n\n缺点：\n* 不直观，看见一个大数字表无法直观的将其想象在三维空间的变换\n* 不容易插值，计算繁琐\n* 占用空间大，需要占用9个存储空间\n\n### 轴角\n通过一个单位矢量定义旋转轴，一个标量定义旋转角表示旋转。类似于四元数表示法[旋转轴 旋转角]，写成[**a** θ]的形式。其中**a**是旋转轴、θ是旋转角。\n\n优点：\n* 表现直观，直接存在旋转轴与旋转角\n* 紧凑，只占用4个存储空间\n\n缺点：\n* 无法进行简单的插值\n* 轴角形式无法直接施加于点或矢量，需要将其先转化为四元数\n\n### 四元数\n与轴角的区别：旋转轴矢量长度为旋转半角的正弦，第四个分量是旋转半角的余弦。\n\n优点：\n* 四元数乘法能串接旋转，并把旋转直接施加于矢量和点\n* 可以轻易地用LERP和SLERP进行旋转插值\n* 存储空间小，只需要4个浮点数的存储空间\n\n### SQT变换\n4 x 4表示任意变换（旋转、平移、缩放），但是占用空间大，因此，将四元数加上平移矢量与缩放因子来实现任意仿射变换。他的体积比4 x 4矩阵小。统一缩放只需要8个存储空间，非统一缩放需要10个存储空间。\n> 因为统一缩放的时候缩放因子是一个标量，而非统一缩放的时候缩放因子是由三个标量组成的矢量\n\n优点：\n* 可以表示任意仿射变换\n* 空间比4 x 4矩阵小\n* 容易插值，各个部分可以采用不同的插值算法，平移矢量可以用LERP、四元数则可以矢量LERP或SLERP。\n\n### 其他\n其他还有**对偶四元数**、**旋转和自由度**等方式。\n\n","tags":["数学"]},{"title":"【剑指 offer】15.二进制中1的个数","url":"/2020/11/30/【剑指-offer】15-二进制中1的个数/","content":"来源：力扣（LeetCode）\n\n链接：https://leetcode-cn.com/problems/er-jin-zhi-zhong-1de-ge-shu-lcof\n\n### 题目描述\n请实现一个函数，输入一个整数（以二进制串形式），输出该数二进制表示中 1 的个数。例如，把 9 表示成二进制是 1001，有 2 位是 1。因此，如果输入 9，则该函数输出 2。\n\n示例 1：\n```bash\n输入：00000000000000000000000000001011\n输出：3\n解释：输入的二进制串 00000000000000000000000000001011 中，共有三位为 '1'。\n```\n\n示例 2：\n```bash\n输入：00000000000000000000000010000000\n输出：1\n解释：输入的二进制串 00000000000000000000000010000000 中，共有一位为 '1'。\n```\n\n示例 3：\n```bash\n输入：11111111111111111111111111111101\n输出：31\n解释：输入的二进制串 11111111111111111111111111111101 中，共有 31 位为 '1'。\n```\n\n提示：\n* 输入必须是长度为 32 的 二进制串 。\n\n### 我的解题\n#### 思路\n通过逐位比较来确定给定数字中出现的1的个数，这里我一开始使用了取模，实际上还有更快的位运算，不过这里有个小坑，即题目中给定的int需要看成无符号位，即当int为负数的时候最高位是1。因此需要在Java中通过>>>来达成数字的无符号移动。\n\n#### 结果\n```java\npublic class Solution {\n    // you need to treat n as an unsigned value\n    public int hammingWeight(int n) {\n        int size = 0;\n        while (n != 0) {\n            size += (n & 1);\n            n >>>= 1;\n        }\n        return size;\n    }\n}\n```\n### 最优解\n#### 思路\n有两种方法，一种就是上面的通过每一位的比较来得到数字中1的个数，但是还有一个更快的方法，即通过n&(n-1)这样的位运算。n-1在二进制中表示将n的最低位的1修改成0。与上面方法的区别就是，逐位计算循环次数固定是数字的位数，这种方法的循环次数则是数字中1的个数。设上一种方法的时间复杂度为O(N)、这种时间复杂度为O(M)，则N >= M.\n<img src=\"https://pic.leetcode-cn.com/9bc8ab7ba242888d5291770d35ef749ae76ee2f1a51d31d729324755fc4b1b1c-Picture10.png\" width=\"50%\" height=\"50%\">\n\n#### 解法\n```java\npublic class Solution {\n    // you need to treat n as an unsigned value\n    public int hammingWeight(int n) {\n        int size = 0;\n        while (n != 0) {\n            size += 1;\n            n = n & (n - 1);\n        }\n        return size;\n    }\n}\n```","tags":["算法"]},{"title":"【剑指 offer】14- II. 剪绳子 II","url":"/2020/11/18/【剑指-offer】14-II-剪绳子-II/","content":"来源：力扣（LeetCode）\n\n链接：https://leetcode-cn.com/problems/jian-sheng-zi-ii-lcof\n### 题目描述\n给你一根长度为 n 的绳子，请把绳子剪成整数长度的 m 段（m、n都是整数，n>1并且m>1），每段绳子的长度记为 k[0],k[1]...k[m - 1] 。请问 k[0]*k[1]*...*k[m - 1] 可能的最大乘积是多少？例如，当绳子的长度是8时，我们把它剪成长度分别为2、3、3的三段，此时得到的最大乘积是18。\n\n答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。\n\n示例 1：\n```bash\n输入: 2\n输出: 1\n解释: 2 = 1 + 1, 1 × 1 = 1\n```\n示例 2:\n```bash\n输入: 10\n输出: 36\n解释: 10 = 3 + 3 + 4, 3 × 3 × 4 = 36\n```\n\n提示：**2 <= n <= 1000**\n\n### 我的解题\n#### 思路\n这题根昨天的题目几乎一样，不过要注意的一点就是由于多了一个取模的条件，所以直接通过dp的max比较已经不行了。但是思路还是一样的。根据数学公式得出，数字n按照拆分的优先级分别是3、2、1，因此我们可以通过循环一个一个减去对应的数字然后保留计算结果，要注意的是，当结果已经小于等于4的时候需要特殊对待。\n* n = 4：直接结果与4相乘并退出循环呢\n* n < 3：结果与n相乘并退出循环\n\n#### 结果\n```java\nclass Solution {\n    public int cuttingRope(int n) {\n        if (n <= 3) {\n            return n - 1;\n        } else if (n == 4) {\n            return n;\n        }\n\n        int p = 1000000007;\n        long ans = 1L;\n        int a = 3;\n        while (n > 0) {\n            ans *= a;\n            ans %= p;\n            n -= 3;\n            if (n == 4 || n < 3) {\n                a = n;\n            }\n        }\n        return (int) ans;\n    }\n}\n```\n\n### 最优解\n#### 思路\n数学的推导过程与上一题一样，但是在最后需要考虑**大数求余**的问题。针对这个问题主要有两种解决思路：\n1. 循环求余\n2. 快速冥求余\n\n两种方法都是根据以下求余循环法则推导而成：\n> (xy)%p = (x%p)(y%p)%p\n\n##### 1.循环求余\n根据上述公式推导得：<br>\n<img src=\"/img/202011/009.png\" width=\"50%\" height=\"50%\"><br>\n我们可以通过寻汗操作n1、n2...na对p的余数，保证每轮的中间值都在int32的范围内。\n\n```python\n# 求 (x^a) % p —— 循环求余法\ndef remainder(x, a, p):\n    rem = 1\n    for _ in range(a):\n        rem = (rem * x) % p\n    return rem\n```\n##### 2.快速冥求余\n根据求余公式推导出：<br>\n<img src=\"/img/202011/010.png\" width=\"50%\" height=\"50%\"><br>\n当a为奇数时，a/2不是整数，因此将其分为两种情况（“//”表示向下取整的除法）\n<img src=\"/img/202011/011.png\" width=\"50%\" height=\"50%\"><br>\n利用以上公式，可通过循环操作每次把指数 aa 问题降低至指数 a//2 问题，只需循环 log_2(N) 次，因此可将复杂度降低至对数级别。封装方法代码如下所示。\n\n```python\n# 求 (x^a) % p —— 快速幂求余\ndef remainder(x, a, p):\n    rem = 1\n    while a > 0:\n        if a % 2: rem = (rem * x) % p\n        x = x ** 2 % p\n        a //= 2\n    return rem\n```\n\n#### 结果\n```java\nclass Solution {\n    public int cuttingRope(int n) {\n        if(n <= 3) return n - 1;\n        int b = n % 3, p = 1000000007;\n        long rem = 1, x = 3;\n        for(int a = n / 3 - 1; a > 0; a /= 2) {\n            if(a % 2 == 1) rem = (rem * x) % p;\n            x = (x * x) % p;\n        }\n        if(b == 0) return (int)(rem * 3 % p);\n        if(b == 1) return (int)(rem * 4 % p);\n        return (int)(rem * 6 % p);\n    }\n}\n```","tags":["算法"]},{"title":"【剑指 offer】14- I. 剪绳子","url":"/2020/11/17/【剑指-offer】14-I-剪绳子/","content":"来源：力扣（LeetCode）<br>\n链接：https://leetcode-cn.com/problems/jian-sheng-zi-lcof\n### 题目描述\n给你一根长度为 n 的绳子，请把绳子剪成整数长度的 m 段（m、n都是整数，n>1并且m>1），每段绳子的长度记为 k[0],k[1]...k[m-1] 。请问 k[0]\\*k[1]\\*...\\*k[m-1] 可能的最大乘积是多少？例如，当绳子的长度是8时，我们把它剪成长度分别为2、3、3的三段，此时得到的最大乘积是18。\n\n示例 1：\n\n```bash\n输入: 2\n输出: 1\n解释: 2 = 1 + 1, 1 × 1 = 1\n```\n\n示例 2:\n```bash\n输入: 10\n输出: 36\n解释: 10 = 3 + 3 + 4, 3 × 3 × 4 = 36\n```\n提示：\n> 2 <= n <= 58\n\n### 我的解题\n#### 思路\n第一眼就认为用动态规划求解：设将n长的绳子分成m份后每份的乘积为f(n, m)，且 1 < m <= n,但这样就很难得到状态转移方程，因此思路不通。\n\n后来用f(n)表示将n份绳子分成至少2份后各个结果最大的积。则f(0) = 0, f(1) = 1;后面我自己想状态转移方程就想不到了。所以还是直接看的答案。\n\n### 最优解\n#### 思路\n\n##### 动态规划\n对于的正整数 n，当 n≥2 时，可以拆分成至少两个正整数的和。令 k 是拆分出的第一个正整数，则剩下的部分是 n−k，n−k 可以不继续拆分，或者继续拆分成至少两个正整数的和。由于每个正整数对应的最大乘积取决于比它小的正整数对应的最大乘积，因此可以使用动态规划求解。\n\n* **dp数组的含义**： dp[i] 表示将正整数 i 拆分成至少两个正整数的和之后，这些正整数的最大乘积。\n* **边界条件**： 0 不是正整数，1 是最小的正整数，0 和 1 都不能拆分，因此 dp[0]=dp[1]=0。\n* **状态转移方程**：当 i≥2 时，假设对正整数 i 拆分出的第一个正整数是 j（1≤j<i），则有以下两种方案：\n    * 将 i 拆分成 j 和 i−j 的和，且 i−j 不再拆分成多个正整数，此时的乘积是 j×(i−j)；\n    * 将 i 拆分成 j 和 i−j 的和，且 i−j 继续拆分成多个正整数，此时的乘积是 j×dp[i−j]。\n\n因此，当 j 固定时，有 dp[i]=max(j×(i−j),j×dp[i−j])。由于 j 的取值范围是 1 到 i−1，需要遍历所有的 j 得到 dp[i] 的最大值，因此可以得到状态转移方程如下：<br>\n<img src=\"/img/202011/002.png\" width=\"50%\" height=\"50%\">\n\n##### 数学思想\n设将长度为 n 的绳子切为 a 段：<br>\n<img src=\"/img/202011/003.png\" width=\"50%\" height=\"50%\">\n\n本题等价于求解：<br>\n<img src=\"/img/202011/004.png\" width=\"50%\" height=\"50%\">\n\n以下公式为“算术几何均值不等式” ，等号当且仅当 n1 = n2 = ... = na 时候成立：<br>\n<img src=\"/img/202011/005.png\" width=\"50%\" height=\"50%\">\n\n> 推论一： 将绳子 以相等的长度等分为多段 ，得到的乘积最大。\n\n<img src=\"/img/202011/006.png\" width=\"70%\" height=\"70%\">\n<img src=\"/img/202011/007.png\" width=\"70%\" height=\"70%\">\n<img src=\"/img/202011/008.png\" width=\"50%\" height=\"50%\">\n\n#### 结果\n\n##### 动态规划\n```java\nclass Solution {\n    public int cuttingRope(int n) {\n        int[] dp = new int[n + 1];\n        dp[0] = 0;\n        dp[1] = 1;\n        for (int i = 2; i <= n; i++) {\n            for (int j = 1; j < i; j++) {\n                dp[i] = Math.max(dp[i], Math.max(j * (i - j), j * dp[i - j]));\n            }\n        }\n        return dp[n];\n    }\n}\n```\n\n##### 数学思想\n```java\nclass Solution {\n    public int cuttingRope(int n) {\n        if (n <= 3) {\n            return n - 1;\n        }\n        int a = n / 3;\n        int b = n % 3;\n        if (b == 0) {\n            return (int) Math.pow(3, a);\n        }\n        if (b == 1) {\n            return (int) Math.pow(3, a - 1) * 4;\n        }\n        return (int) Math.pow(3, a) * 2;\n    }\n}\n```","tags":["算法"]},{"title":"【剑指 offer】13. 机器人的运动范围","url":"/2020/11/16/【剑指-offer】13-机器人的运动范围/","content":"来源：力扣（LeetCode）\n链接：https://leetcode-cn.com/problems/ji-qi-ren-de-yun-dong-fan-wei-lcof\n### 题目描述\n地上有一个m行n列的方格，从坐标 [0,0] 到坐标 [m-1,n-1] 。一个机器人从坐标 [0, 0] 的格子开始移动，它每次可以向左、右、上、下移动一格（不能移动到方格外），也不能进入行坐标和列坐标的数位之和大于k的格子。例如，当k为18时，机器人能够进入方格 [35, 37] ，因为3+5+3+7=18。但它不能进入方格 [35, 38]，因为3+5+3+8=19。请问该机器人能够到达多少个格子？\n\n\n示例 1：\n\n```bash\n输入：m = 2, n = 3, k = 1\n输出：3\n```\n\n示例 2：\n```bash\n输入：m = 3, n = 1, k = 0\n输出：1\n```\n\n提示：\n\n> 1 <= n,m <= 100\n> 0 <= k <= 20\n\n### 我的解题\n#### 思路\n题目中给了一个限定条件*不能进入行坐标和列坐标的数位之和大于k的格子*，即从点（0，0）出发的机器人在这个条件内能都达到的所有方块数量，同时要注意，所有能够到达的方块都是和点（0，0）连续的，例如当k=2时候，点（100，100），光看k的值是满足的但是机器人无法到达这个点。\n\n这种涉及到连续路径查询，且只需要查询个数不需要查询具体某条路线的问题可以用广度优先搜索来完成。\n\n#### 结果\n```java\nclass Solution {\n    public int movingCount(int m, int n, int k) {\n        //广度优先搜索\n        Queue<int[]> queue = new LinkedList<>();\n        Set<String> used = new HashSet<>();\n        used.add(\"0,0\");\n        queue.add(new int[] {0, 0});\n        int[][] foots = {\n            {1, 0},\n            {-1, 0},\n            {0, 1},\n            {0, -1}\n        };\n        int count = 0;\n\n        while (!queue.isEmpty()) {\n            int[] num = queue.poll();\n            int mK = getK(num[0], num[1]);\n            if (mK > k) {\n                continue;\n            }\n\n            for (int[] foot : foots) {\n                int x = foot[0] + num[0];\n                int y = foot[1] + num[1];\n                if (x < 0 || y < 0 || x >= m || y >= n) {\n                    continue;\n                }\n                String key = x + \",\" + y;\n                if (used.contains(key)) {\n                    continue;\n                }\n                used.add(key);\n\n                if (getK(x, y) > k) {\n                    continue;\n                }\n                queue.add(new int[] {x, y});\n            }\n\n            count++;\n        }\n        return count;\n    }\n\n    private int getK(int i, int j) {\n        int sum = 0;\n        while (i > 0) {\n            int n = i % 10;\n            sum += n;\n            i /= 10;\n        }\n        while (j > 0) {\n            int n = j % 10;\n            sum += n;\n            j /= 10;\n        }\n        return sum;\n    }\n\n}\n```\n### 最优解\n#### 思路\n\n##### 思路一：广度优先搜索\n不过在\n```java\nint[][] foots = {\n    {1, 0},\n    {-1, 0},\n    {0, 1},\n    {0, -1}\n};\n```\n这一步可以用\n```java\nint[][] foots = {\n    {1, 0},\n    {0, 1}\n};\n```\n来替代，用于减少循环次数，因为机器人只会往右或下行走。\n\n##### 思路二：递推\n考虑到方法一提到搜索的方向只需要朝下或朝右，我们可以得出一种递推的求解方法。\n定义 vis[i][j] 为 (i, j) 坐标是否可达，如果可达返回 1，否则返回 0。\n首先 (i, j) 本身需要可以进入，因此需要先判断 i 和 j 的数位之和是否大于 k ，如果大于的话直接设置 vis[i][j] 为不可达即可。\n否则，前面提到搜索方向只需朝下或朝右，因此 (i, j) 的格子只会从 (i - 1, j) 或者 (i, j - 1) 两个格子走过来（不考虑边界条件），那么 vis[i][j] 是否可达的状态则可由如下公式计算得到：<br>\n> **vis[i][j]=vis[i−1][j] or vis[i][j−1]**\n\n即只要有一个格子可达，那么 (i, j) 这个格子就是可达的，因此我们只要遍历所有格子，递推计算出它们是否可达然后用变量 ans 记录可达的格子数量即可。\n初始条件 vis[i][j] = 1 ，递推计算的过程中注意边界的处理。\n\n#### 结果\n```java\nclass Solution {\n    public int movingCount(int m, int n, int k) {\n        if (k == 0) {\n            return 1;\n        }\n        boolean[][] vis = new boolean[m][n];\n        int ans = 1;\n        vis[0][0] = true;\n        for (int i = 0; i < m; ++i) {\n            for (int j = 0; j < n; ++j) {\n                if ((i == 0 && j == 0) || get(i) + get(j) > k) {\n                    continue;\n                }\n                // 边界判断\n                if (i - 1 >= 0) {\n                    vis[i][j] |= vis[i - 1][j];\n                }\n                if (j - 1 >= 0) {\n                    vis[i][j] |= vis[i][j - 1];\n                }\n                ans += vis[i][j] ? 1 : 0;\n            }\n        }\n        return ans;\n    }\n\n    private int get(int x) {\n        int res = 0;\n        while (x != 0) {\n            res += x % 10;\n            x /= 10;\n        }\n        return res;\n    }\n}\n```","tags":["算法"]},{"title":"【剑指 offer】12. 矩阵中的路径","url":"/2020/11/15/【剑指-offer】12-矩阵中的路径/","content":"链接：https://leetcode-cn.com/problems/ju-zhen-zhong-de-lu-jing-lcof\n著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。\n\n### 题目描述\n请设计一个函数，用来判断在一个矩阵中是否存在一条包含某字符串所有字符的路径。路径可以从矩阵中的任意一格开始，每一步可以在矩阵中向左、右、上、下移动一格。如果一条路径经过了矩阵的某一格，那么该路径不能再次进入该格子。例如，在下面的3×4的矩阵中包含一条字符串“bfce”的路径（路径中的字母用加粗标出）。\n\n```bash\n[[\"a\",\"b\",\"c\",\"e\"],\n[\"s\",\"f\",\"c\",\"s\"],\n[\"a\",\"d\",\"e\",\"e\"]]\n```\n\n但矩阵中不包含字符串“abfb”的路径，因为字符串的第一个字符b占据了矩阵中的第一行第二个格子之后，路径不能再次进入这个格子。\n\n \n\n示例 1：\n\n```bash\n输入：board = [[\"A\",\"B\",\"C\",\"E\"],[\"S\",\"F\",\"C\",\"S\"],[\"A\",\"D\",\"E\",\"E\"]], word = \"ABCCED\"\n输出：true\n```\n\n\n示例 2：\n```bash\n输入：board = [[\"a\",\"b\"],[\"c\",\"d\"]], word = \"abcd\"\n输出：false\n```\n\n提示：\n```bash\n1 <= board.length <= 200\n1 <= board[i].length <= 200\n```\n\n### 我的解题\n#### 思路\n首先想到的就是深度优先搜索，即遍历board，判断下标元素是否和word的首字符一致，如果一致则判断周围四个格子是否有字符与word的下一个字符一致。为了避免循环判断，采用一个数据结构记录已经走过的路程。\n\n#### 结果\n```java\n\nclass Solution {\n    public boolean exist(char[][] board, String word) {\n        char[] words = word.toCharArray();\n        int[][] used = new int[board.length][board[0].length];\n        for (int i = 0; i < board.length; i++) {\n            for (int j = 0; j < board[0].length; j++) {\n                if (board[i][j] != words[0]) {\n                    continue;\n                }\n                if (check(board, i, j, words, 0, used)) {\n                    return true;\n                }\n            }\n        }\n        return false;\n    }\n\n    private boolean check(char[][] board, int i, int j, char[] words, int wordIndex, int[][] used) {\n        if (i < 0 || i >= board.length || j < 0 || j >= board[0].length) {\n            if (wordIndex >= words.length) {\n                return true;\n            } else {\n                return false;\n            }\n        }\n        if (used[i][j] == 1) {\n            return false;\n        }\n        if (wordIndex >= words.length) {\n            return true;\n        }\n        if (board[i][j] != words[wordIndex]) {\n            return false;\n        }\n        used[i][j] = 1;\n        int[][] foots = {\n            {1, 0},\n            {-1, 0},\n            {0, 1},\n            {0, -1}\n        };\n        for (int[] foot : foots) {\n            int x = i + foot[0];\n            int y = j + foot[1];\n            if (check(board, x, y, words, wordIndex + 1, used)) {\n                return true;\n            }\n        }\n        used[i][j] = 0;\n        return false;\n    }\n}\n```\n### 最优解\n#### 思路\n本问题是典型的矩阵搜索问题，可使用 深度优先搜索（DFS）+ 剪枝 解决。\n\n* **深度优先搜索**： 可以理解为暴力法遍历矩阵中所有字符串可能性。DFS 通过递归，先朝一个方向搜到底，再回溯至上个节点，沿另一个方向搜索，以此类推。\n* **剪枝**： 在搜索中，遇到 这条路不可能和目标字符串匹配成功 的情况（例如：此矩阵元素和目标字符不同、此元素已被访问），则应立即返回，称之为 可行性剪枝 。\n<!-- ![]() -->\n<img src=\"/img/202011/001.png\" width=\"50%\" height=\"50%\">\n\n##### DFS 解析：\n\n* **递归参数**： 当前元素在矩阵 board 中的行列索引 i 和 j ，当前目标字符在 word 中的索引 k 。\n* **终止条件**：\n    1. 返回 falsefalse ： (1) 行或列索引越界 或 (2) 当前矩阵元素与目标字符不同 或 (3) 当前矩阵元素已访问过 （ (3) 可合并至 (2) ） 。\n    2. 返回 truetrue ： k = len(word) - 1 ，即字符串 word 已全部匹配。\n* **递推工作**：\n    1. 标记当前矩阵元素： 将 board[i][j] 修改为 空字符 '' ，代表此元素已访问过，防止之后搜索时重复访问。\n    2. 搜索下一单元格： 朝当前元素的 上、下、左、右 四个方向开启下层递归，使用 或 连接 （代表只需找到一条可行路径就直接返回，不再做后续 DFS ），并记录结果至 res 。\n    3. 还原当前矩阵元素： 将 board[i][j] 元素还原至初始值，即 word[k] 。\n* **返回值**： 返回布尔量 res ，代表是否搜索到目标字符串。\n\n> 使用空字符（Python: '' , Java/C++: '\\0' ）做标记是为了防止标记字符与矩阵原有字符重复。当存在重复时，此算法会将矩阵原有字符认作标记字符，从而出现错误。\n\n##### 复杂度分析：\n> M,N 分别为矩阵行列大小， K 为字符串 word 长度。\n\n* 时间复杂度 O(3^K * MN) : 最差情况下，需要遍历矩阵中长度为 KK 字符串的所有方案，时间复杂度为O(3^K).矩阵中共有 MN 个起点，时间复杂度为 O(MN) 。\n    * 方案数计算设字符串长度为 KK ，搜索中每个字符有上、下、左、右四个方向可以选择，舍弃回头（上个字符）的方向，剩下 3 种选择，因此方案数的复杂度为O(3^K) 。\n* 空间复杂度 O(K) ： 搜索过程中的递归深度不超过 K ，因此系统因函数调用累计使用的栈空间占用 O(K) （因为函数返回后，系统调用的栈空间会释放）。最坏情况下 K = K=MN ，递归深度为 MN ，此时系统栈使用 O(MN) 的额外空间。\n\n#### 结果\n```java\nclass Solution {\n    public boolean exist(char[][] board, String word) {\n        char[] words = word.toCharArray();\n        for(int i = 0; i < board.length; i++) {\n            for(int j = 0; j < board[0].length; j++) {\n                if(dfs(board, words, i, j, 0)) return true;\n            }\n        }\n        return false;\n    }\n    boolean dfs(char[][] board, char[] word, int i, int j, int k) {\n        if(i >= board.length || i < 0 || j >= board[0].length || j < 0 || board[i][j] != word[k]) return false;\n        if(k == word.length - 1) return true;\n        board[i][j] = '\\0';\n        boolean res = dfs(board, word, i + 1, j, k + 1) || dfs(board, word, i - 1, j, k + 1) || \n                      dfs(board, word, i, j + 1, k + 1) || dfs(board, word, i , j - 1, k + 1);\n        board[i][j] = word[k];\n        return res;\n    }\n}\n```","tags":["算法"]},{"title":"【剑指 offer】07. 重建二叉树","url":"/2020/11/11/【剑指-offer】07-重建二叉树/","content":"来源：力扣（LeetCode）\n链接：https://leetcode-cn.com/problems/zhong-jian-er-cha-shu-lcof\n### 题目描述\n输入某二叉树的前序遍历和中序遍历的结果，请重建该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。\n\n例如，给出\n\n> 前序遍历 preorder = [3,9,20,15,7]\n> 中序遍历 inorder = [9,3,15,20,7]\n返回如下的二叉树：\n\n```bash\n   3\n  / \\ \n 9  20 \n   /  \\ \n  15   7 \n```\n\n限制：\n\n> 0 <= 节点个数 <= 5000\n\n### 我的解题\n#### 思路\n首先确定两种遍历方式的区别：\n* 前序遍历：根节点->左节点->右节点\n* 中序遍历：左节点->根节点->右节点\n\n因此，在中序遍历中，在根节点之前被访问的节点都位于左子树，在根节点之后被访问的节点都位于右子树。同时前序遍历的数据顺序对于跟节点来说，等于如下结构【根节点】【所有左节点】【所有右节点】，因此，在通过跟节点从中序遍历中得到跟节点的左右字节点队列与个数后，能根据左右字节点的数量从前序遍历中分解出左节点队列和右节点队列，到了这步通过迭代即可遍历树。\n\n> 其实我只到两种遍历的区别，没有第一时间意识到通过宏观的角度将数组分成左右两个节点的队列，太久没有接触树的概念生疏了。\n\n#### 结果\n```java\n/**\n * Definition for a binary tree node.\n * public class TreeNode {\n *     int val;\n *     TreeNode left;\n *     TreeNode right;\n *     TreeNode(int x) { val = x; }\n * }\n */\nclass Solution {\n    public TreeNode buildTree(int[] preorder, int[] inorder) {\n        if (preorder == null || preorder.length == 0) {\n            return null;\n        }\n        Map<Integer, Integer> indexMap = new HashMap<Integer, Integer>();\n        int length = preorder.length;\n        for (int i = 0; i < length; i++) {\n            indexMap.put(inorder[i], i);\n        }\n        TreeNode root = buildTree(preorder, 0, length - 1, inorder, 0, length - 1, indexMap);\n        return root;\n    }\n\n    public TreeNode buildTree(int[] preorder, int preorderStart, int preorderEnd, int[] inorder, int inorderStart, int inorderEnd, Map<Integer, Integer> indexMap) {\n        if (preorderStart > preorderEnd) {\n            return null;\n        }\n        int rootVal = preorder[preorderStart];\n        TreeNode root = new TreeNode(rootVal);\n        if (preorderStart == preorderEnd) {\n            return root;\n        } else {\n            int rootIndex = indexMap.get(rootVal);\n            int leftNodes = rootIndex - inorderStart, rightNodes = inorderEnd - rootIndex;\n            TreeNode leftSubtree = buildTree(preorder, preorderStart + 1, preorderStart + leftNodes, inorder, inorderStart, rootIndex - 1, indexMap);\n            TreeNode rightSubtree = buildTree(preorder, preorderEnd - rightNodes + 1, preorderEnd, inorder, rootIndex + 1, inorderEnd, indexMap);\n            root.left = leftSubtree;\n            root.right = rightSubtree;\n            return root;\n        }\n    }\n}\n```\n ### 最优解\n #### 思路\n 第一个通过迭代的思路同上。因此这里介绍另一种方法：*迭代*。\n 例如要重建的是如下二叉树。\n\n```bash\n        3\n       / \\\n      9  20\n     /  /  \\\n    8  15   7\n   / \\\n  5  10\n /\n4\n```\n\n其前序遍历和中序遍历如下。\n\n>preorder = [3,9,8,5,4,10,20,15,7]\n>inorder = [4,5,8,10,9,3,15,20,7]\n\n前序遍历的第一个元素 3 是根节点，第二个元素 9 可能位于左子树或者右子树，需要通过中序遍历判断。\n\n中序遍历的第一个元素是 4 ，不是根节点 3，说明 9 位于左子树，因为根节点不是中序遍历中的第一个节点。同理，前序遍历的后几个元素 8、5、4 也都位于左子树，且每个节点都是其上一个节点的左子节点。\n\n前序遍历到元素 4，和中序遍历的第一个元素相等，说明前序遍历的下一个元素 10 位于右子树。那么 10 位于哪个元素的右子树？从前序遍历看，10 可能位于 4、5、8、9、3 这些元素中任何一个元素的右子树。从中序遍历看，10 在 8 的后面，因此 10 位于 8 的右子树。把前序遍历的顺序反转，则在 10 之前的元素是 4、5、8、9、3，其中 8 是最后一次相等的节点，因此前序遍历的下一个元素位于中序遍历中最后一次相等的节点的右子树。\n\n根据上述例子和分析，可以使用栈保存遍历过的节点。初始时令中序遍历的指针指向第一个元素，遍历前序遍历的数组，如果前序遍历的元素不等于中序遍历的指针指向的元素，则前序遍历的元素为上一个节点的左子节点。如果前序遍历的元素等于中序遍历的指针指向的元素，则正向遍历中序遍历的元素同时反向遍历前序遍历的元素，找到最后一次相等的元素，将前序遍历的下一个节点作为最后一次相等的元素的右子节点。其中，反向遍历前序遍历的元素可通过栈的弹出元素实现。\n\n* 使用前序遍历的第一个元素创建根节点。\n* 创建一个栈，将根节点压入栈内。\n* 初始化中序遍历下标为 0。\n* 遍历前序遍历的每个元素，判断其上一个元素（即栈顶元素）是否等于中序遍历下标指向的元素。\n    * 若上一个元素不等于中序遍历下标指向的元素，则将当前元素作为其上一个元素的左子节点，并将当前元素压入栈内。\n    * 若上一个元素等于中序遍历下标指向的元素，则从栈内弹出一个元素，同时令中序遍历下标指向下一个元素，之后继续判断栈顶元素是否等于中序遍历下标指向的元素，若相等则重复该操作，直至栈为空或者元素不相等。然后令当前元素为最后一个想等元素的右节点。\n* 遍历结束，返回根节点。\n\n#### 结果\n```java\n/**\n * Definition for a binary tree node.\n * public class TreeNode {\n *     int val;\n *     TreeNode left;\n *     TreeNode right;\n *     TreeNode(int x) { val = x; }\n * }\n */\nclass Solution {\n    public TreeNode buildTree(int[] preorder, int[] inorder) {\n        if (preorder == null || preorder.length == 0) {\n            return null;\n        }\n        TreeNode root = new TreeNode(preorder[0]);\n        int length = preorder.length;\n        Stack<TreeNode> stack = new Stack<TreeNode>();\n        stack.push(root);\n        int inorderIndex = 0;\n        for (int i = 1; i < length; i++) {\n            int preorderVal = preorder[i];\n            TreeNode node = stack.peek();\n            if (node.val != inorder[inorderIndex]) {\n                node.left = new TreeNode(preorderVal);\n                stack.push(node.left);\n            } else {\n                while (!stack.isEmpty() && stack.peek().val == inorder[inorderIndex]) {\n                    node = stack.pop();\n                    inorderIndex++;\n                }\n                node.right = new TreeNode(preorderVal);\n                stack.push(node.right);\n            }\n        }\n        return root;\n    }\n}\n```","tags":["算法"]},{"title":"【剑指-offer】05.替换空格","url":"/2020/11/09/【剑指-offer】05-替换空格/","content":"来源：力扣（LeetCode）\n链接：https://leetcode-cn.com/problems/ti-huan-kong-ge-lcof\n### 题目描述\n请实现一个函数，把字符串 s 中的每个空格替换成\"%20\"。\n\n示例 1：\n\n> 输入：s = \"We are happy.\"\n> 输出：\"We%20are%20happy.\"\n\n限制：\n> 0 <= s 的长度 <= 10000\n\n### 我的解题\n#### 思路\n有两种方法：\n1. 调用replace库函数直接替换\n2. 遍历字符串，用if判断字符是否是空格，如果是则替换\n\n#### 结果\n我这里使用方法2\n```java\nclass Solution {\n    public String replaceSpace(String s) {\n        StringBuilder sb = new StringBuilder();\n        for (char c : s.toCharArray()) {\n            if (c == ' ') {\n                sb.append(\"%20\");\n            } else {\n                sb.append(c);\n            }\n        }\n        return sb.toString();\n    }\n}\n```\n\n ### 最优解\n #### 思路\n 如果想把这道题目做到极致，就不要只用额外的辅助空间了！\n当然这只是针对C++的情况下，因为在C++中，字符数组是可以在原有的基础上扩充的。\n\n首先扩充数组到每个空格替换成\"%20\"之后的大小。然后从后向前替换空格，也就是双指针法。\n\n为什么不从前往后扩充呢？如果从前往后扩充的话时间复杂度就是O(n^2)了。因为每次添加元素都要将添加元素之后的所有元素向后移动。\n\n其实很多数组填充类的问题，都可以先预先给数组扩容带填充后的大小，然后在从后向前进行操作。这么做有两个好处：\n1. 不用申请新数组。\n2. 从后向前填充元素，避免了从前先后填充元素要来的 每次添加元素都要将添加元素之后的所有元素向后移动。\n\n#### 结果\n```C++\npublic:\n    string replaceSpace(string s) {\n        int count = 0; // 统计空格的个数\n        int sOldSize = s.size();\n        for (int i = 0; i < s.size(); i++) {\n            if (s[i] == ' ') {\n                count++;\n            }\n        }\n        // 扩充字符串s的大小，也就是每个空格替换成\"%20\"之后的大小\n        s.resize(s.size() + count * 2);\n        int sNewSize = s.size();\n        // 从后先前将空格替换为\"%20\"\n        for (int i = sNewSize - 1, j = sOldSize - 1; j < i; i--, j--) {\n            if (s[j] != ' ') {\n                s[i] = s[j];\n            } else {\n                s[i] = '0';\n                s[i - 1] = '2';\n                s[i - 2] = '%';\n                i -= 2;\n            }\n        }\n        return s;\n    }\n};\n```","tags":["算法"]},{"title":"【剑指 offer】03.数组中重复的数字","url":"/2020/11/08/【剑指-offer】03-数组中重复的数字/","content":"来源：力扣（LeetCode）\n链接：https://leetcode-cn.com/problems/shu-zu-zhong-zhong-fu-de-shu-zi-lcof\n### 题目描述\n找出数组中重复的数字。\n\n\n在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。\n\n示例 1：\n> 输入：\n> [2, 3, 1, 0, 2, 5, 3]\n> 输出：2 或 3 \n> 输入：\n> [2, 3, 1, 0, 2, 5, 3]\n> 输出：2 或 3 \n \n\n限制：\n\n> 2 <= n <= 100000\n\n### 我的解题\n#### 思路\n首先，其中的数字大小限定在0～n-1的范围内，既然给定了大小，那么直接创建对应长度的数组，即*int[] list = new int[nums.length]*，然后遍历数组nums，取出结果n,并将n作为下标在list数组中+1，如果结果大于1则表示当前n重复出现。\n\n这里其实就应用了空间换时间的策略，通过创建对应length的数组来加快取值过程，当然也可以使用哈希，那么我们就需要创建Set，为了加快速度，可以在创建对象的时候传入初始容量length。\n\n#### 结果\n```java\nclass Solution {\n    public int findRepeatNumber(int[] nums) {\n        int[] list = new int[nums.length];\n        for (int i = 0; i < nums.length; i++) {\n            int n = nums[i];\n            list[n]++;\n            if (list[n] > 1) {\n                return n;\n            }\n        }\n        return -1;\n    }\n}\n```\n ### 最优解\n #### 思路\n 由于数字大小的范围是0～n-1，刚好数数组的下标对应，我们可以通过某些操作将值与下标对应，一旦某个索引的值不是一个，则找到了重复的数组，即发生了哈希碰撞。\n #### 结果\n```java\nclass Solution {\n    public int findRepeatNumber(int[] nums) {\n        //设索引初始值为 i = 0\n        int i = 0;\n        //遍历整个数组 nums \n        while(i < nums.length) {\n            //索引 i 的值为 i,无需执行交换操作，查看下一位\n            if(nums[i] == i) {\n                i++;\n                continue;\n            }\n            //索引 nums[i] 处的值也为 nums[i]，即找到一组相同值，返回 nums[i] 即可\n            if(nums[nums[i]] == nums[i]) return nums[i];\n            //执行交换操作，目的是为了使索引与值一一对应，即索引 0 的值为 0，索引 1 的值为 1\n            int tmp = nums[i];\n            nums[i] = nums[tmp];\n            nums[tmp] = tmp;\n        }\n        //如果遍历整个数组都没有找到相同的值，返回 -1\n        return -1;\n    }\n}\n```\n### 复杂度分析\n遍历数组需要O(n)的时间。\n\n在代码中的*continue*，这表示在while的一次循环中里只有这次循环将 索引(i) 与 索引值(num[i]) 匹配到了，才会执行下一次循环。\n\n在每一次的循环过程中，索引(i) 与 索引值(num[i]) 匹配到后，在后续的循环过程中不会操作它们，所以虽然一开始的循环过程中，执行的交换操作较多，但在后续的循环过程中根本不需要再执行操作了。\n\n根据均摊复杂度分析 ，总的时间复杂度为 O(N) ，N 为数组的长度。","tags":["算法"]}]